---
title: "How to Use GPU Node for SLURM"
author: "Gwnaghee Kim"
date: 2022-03-15T14:54:35+09:00
draft: false
---

# How to use GPU node for SLURM

## Step 1. Export your conda setting

conda í™˜ê²½ì„ ë™ì¼í•˜ê²Œ ë§ì¶°ì£¼ê¸° ìœ„í•´ localì—ì„œ ìƒì„±ëœ ê°€ìƒí™˜ê²½ìœ¼ë¡œë¶€í„° í™˜ê²½ì„¤ì • íŒŒì¼ì„ ë§Œë“¤ê³ , ì„œë²„ì—ì„œ conda ê°€ìƒí™˜ê²½ì„ ë§Œë“¤ ë•Œ ì‚¬ìš©í•œë‹¤. 

```bash
# export conda setting

conda activate [YOUR ENV NAME]
conda env export -n [ENV NAME] -f [FILENAME].yml --no-builds # ì´ëŸ¬ë©´ ì¡°ê¸ˆì€ í•´ê²°ë˜ê¸´ í•¨

# create environment from file

conda create --name [YOUR ENV NAME] python = [VESTION] # same env name in yml file
conda env create -f [FILENAME].yml

conda env create -p [prefix path] -f [filename].yml
```

**â€”no-builds** ì˜µì…˜ì€ ì„œë¡œ ë‹¤ë¥¸ OSì—ì„œ conda ê°€ìƒí™˜ê²½ íŒŒì¼ ë‚´ íŒ¨í‚¤ì§€ë“¤ì˜ ë²„ì „ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ê²ƒì´ë‹¤.  ë‹¤ë§Œ ê²½ìš°ì— ë”°ë¼ ì™„ì „íˆ ë¬¸ì œë¥¼ ì˜ˆë°©í•˜ì§€ëŠ” ëª»í•˜ê¸° ë•Œë¬¸ì— ì‚¬ìš©ìë“¤ì´ ì§ì ‘ env íŒŒì¼ì„ ìˆ˜ì •í•˜ëŠ” ìƒí™©ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ì´ëŸ° ê²½ìš° **ResolvePackageNotFound** ì•„ë˜ì˜ íŒ¨í‚¤ì§€ë“¤ì„ env íŒŒì¼ì—ì„œ ì‚­ì œí•´ì£¼ë©´ ë¬¸ì œê°€ í•´ê²°ëœë‹¤.

```bash
conda env create -f test.yml
Collecting package metadata: done
Solving environment: failed

# yml íŒŒì¼ì—ì„œ ì•„ë˜ì— ë“±ì¥í•˜ëŠ” íŒ¨í‚¤ì§€ë“¤ì„ ì§€ì›Œì£¼ë©´ ëœë‹¤.
ResolvePackageNotFound: 
  - libgfortran==3.0.1=h93005f0_2 # --no-buildsëŠ” íŒ¨í‚¤ì§€ ë²„ì „ ì˜†ì˜ ë¹Œë“œ ì •ë³´ë¥¼ ì œê±°í•œë‹¤.
  - pyzmq==17.0.0=py36h1de35cc_1
  - python==3.6.6=h4a56312_1003
  - prompt_toolkit==1.0.15=py36haeda067_0
  - libiconv==1.15=h1de35cc_1004
  - sqlite==3.25.3=ha441bb4_0
  - six==1.11.0=py36h0e22d5e_1
  - cryptography==2.3.1=py36hdbc3d79_1000
  - openssl==1.0.2p=h1de35cc_1002
  - libxml2==2.9.8=hf14e9c8_1005
  - libcxxabi==4.0.1=hebd6815_0
  - matplotlib==2.2.3=py36h0e0179f_0
  - ptyprocess==0.5.2=py36he6521c3_0
```

## Step 2. make env file and upload file to userâ€™s workspace

ë¡œì»¬ì—ì„œ ë§Œë“¤ì–´ì§„ env íŒŒì¼ì„ ì„œë²„ë¡œ ì˜®ê¸¸ ë•ŒëŠ” **scp**ë¥¼ ì‚¬ìš©í•œë‹¤. ê°„ë‹¨í•œ ì‚¬ìš©ë²•ì€ ì•„ë˜ì™€ ê°™ë‹¤.

```bash
# scp ì‚¬ìš©ë²•
# File upload
scp [FILEPATH] ghk@[IP address]:~/ # upload from local, ~/ means home directory
# File download
scp ghk@[IP address]:[FILEPATH] ./ # scp [server file path] [local save path]

# directory ì „ì²´ ë‹¤ìš´, ì—…ë¡œë“œ í•  ë•ŒëŠ” -r ì˜µì…˜ì„ ì‚¬ìš©í•œë‹¤.
```

Windows ì‚¬ìš©ìë¼ë©´ **[WinSCP](https://winscp.net/eng/download.php)** ë¼ëŠ” ì´ë¦„ì˜ í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©í•˜ë©´ ë¡œì»¬ê³¼ ì„œë²„ ê°„ íŒŒì¼ ì „ì†¡ì„ ë³´ë‹¤ ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤. 

<aside>
ğŸ’¡ env fileì„ ì´ìš©í•œ conda í™˜ê²½ ì„¤ì •ì€ ë¡œì»¬ê³¼ ì„œë²„ ì‘ì—… í™˜ê²½ì„ ë™ì¼í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ë‹¤. ê·¸ëŸ¬ë‚˜ conda í™˜ê²½ ì„¤ì • ê³¼ì •ì´ ë„ˆë¬´ ë²ˆê±°ë¡­ë‹¤ë©´ requirements.txtë¥¼ ë§Œë“¤ì–´ íŒ¨í‚¤ì§€ ë²„ì „ë§Œ ê´€ë¦¬í•´ë„ ì¶©ëŒì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤.

</aside>

```bash
conda install --force-reinstall -y -q -c conda-forge --file requirements.txt

# --force-reinstall : Install the package even if it already exists.
# -y : Yes, do not ask for confirmation.
# -q : Quiet, do not display progress bar.
# -c : Channels, additional channels to search for packages
# conda-forge is recommended
```

## Step 3. make SLRUM batch script and run code in server

ì•ì„  ë‹¨ê³„ì—ì„œ condaí™˜ê²½ì´ ì˜ ë§Œë“¤ì–´ì¡Œë‹¤ë©´ í•´ë‹¹ ê°€ìƒí™˜ê²½ì„ activateí•˜ì—¬ ì½”ë“œë¥¼ ëŒë¦¬ëŠ” SLURM batch scriptë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë‹¤. ì‚¬ìš©ìë“¤ì˜ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ TensorFlow ê³µì‹ í˜ì´ì§€ì— ê²Œì‹œëœ [ì´ˆë³´ììš© íŠœí† ë¦¬ì–¼](https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ko) ì½”ë“œë¥¼ SLURMì„ í†µí•´ ì‹¤í–‰ì‹œí‚¤ëŠ” ì˜ˆì œë¥¼ ê³µìœ í•œë‹¤. ë¨¼ì €, íŠœí† ë¦¬ì–¼ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

```python
# tensor.py

import tensorflow as tf

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)

model.evaluate(x_test,  y_test, verbose=2)
```

```bash
#!/bin/bash
#
#SBATCH --job-name=gpu-tensor-test
#SBATCH --mem=4gb
#SBATCH --nodelist=gpu-compute
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --gres=gpu:1
#SBATCH --time=00:20:00
#SBATCH --account=ghk
#SBATCH --partition=all
#SBATCH --output=/mnt/nas/users/ghk/code/gputest.log

CONDA_BIN_PATH=/opt/miniconda/bin
ENV_NAME=tensor
ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME

## $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH
## $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8 tensorflow pandas numpy

source $CONDA_BIN_PATH/activate $ENV_PATH
## pip uninstall keras
## pip install keras==2.6.0
python /mnt/nas/users/ghk/code/tensor.py
```

- **â€”job-name**: ìˆ˜í–‰í•  ì‘ì—…ì˜ ì´ë¦„
- **â€”mem**: memory limit
- **â€”nodelist**: ì‘ì—…í•  ë…¸ë“œì˜ ì´ë¦„
- **â€”ntasks**: ì‘ì—…ì˜ ìˆ˜
- **â€”cpus-per-task**: ê° ì‘ì—…ì—ì„œ ì‚¬ìš©í•  cpu ì½”ì–´ì˜ ìˆ˜
- **â€”gres=gpu** : ì‘ì—…ì—ì„œ ì‚¬ìš©í•  gpuì˜ ê°œìˆ˜, gpu-compute ë…¸ë“œì—ëŠ” ì´ 2ê°œì˜ gpuê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤.
- **â€”time**: ì‘ì—… ì œí•œì‹œê°„
- **â€”accoun**t: í•´ë‹¹ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê³„ì •ì˜ ì´ë¦„
- **â€”partition**: group of nodes with specific characteristics
- **â€”output**: ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ log

ì œì‹œí•œ ëŒ€ë¡œ python íŒŒì¼ê³¼ batch script íŒŒì¼ì´ ì˜ ë§Œë“¤ì–´ì¡Œë‹¤ë©´ **sbatch** ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì—¬ ê³„ì‚°ì„ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤.

```bash
sbatch tensor.sh
smap -i 1 # ì‘ì—… í˜„í™©ì„ 1ì´ˆë§ˆë‹¤ ê°±ì‹ í•˜ì—¬ ë³´ì—¬ì¤€ë‹¤. ctrl+cë¡œ escape í•  ìˆ˜ ìˆë‹¤.
```

```bash
ghk@proxy:~/code$ cat gputest.log
2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/5
1875/1875 [==============================] - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140
Epoch 2/5
1875/1875 [==============================] - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575
Epoch 3/5
1875/1875 [==============================] - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675
Epoch 4/5
1875/1875 [==============================] - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739
Epoch 5/5
1875/1875 [==============================] - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762
313/313 - 4s - loss: 0.0782 - accuracy: 0.9779
[0.078231580555439, 0.9779000282287598]
```

SLURM batch scriptë¥¼ ì‚¬ìš©ìë“¤ì´ ë³´ë‹¤ í¸í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ [SLURM Job Configurator](https://hpc.stat.yonsei.ac.kr/tools/job-configurator.html) ë¥¼ ìƒˆë¡­ê²Œ ì‘ì„±í•˜ì˜€ë‹¤. ì‚¬ìš©ìë“¤ì€ gpu ì˜µì…˜ì„ ì²´í¬í•˜ê±°ë‚˜ í•´ì œí•˜ì—¬ gpu-compute node ì‚¬ìš© ì—¬ë¶€ë¥¼ ê²°ì •í•  ìˆ˜ ìˆë‹¤. í•´ë‹¹ë˜ëŠ” ì˜µì…˜ì„ ì²´í¬í•˜ê³  **Print** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì†ì‰½ê²Œ batch scriptë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.

## ë” ì•Œì•„ë³´ê¸°

[Submitting a slurm job script](https://ubccr.freshdesk.com/support/solutions/articles/5000688140-submitting-a-slurm-job-script)

[SLRUM Job Examples](https://doc.zih.tu-dresden.de/jobs_and_resources/slurm_examples/)

[TensorFlow on the HPC Clusters](https://researchcomputing.princeton.edu/support/knowledge-base/tensorflow)