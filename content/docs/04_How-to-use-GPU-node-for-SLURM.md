---
title: "4. GPU node ì‚¬ìš©ë²•(Python)"
author: "Gwnaghee Kim, Jongmin Mun"
date: 2022-03-14T14:54:35+09:00
draft: false
---

# 4. GPU nodeì—ì„œ Python ì½”ë“œ ì‹¤í–‰í•˜ê¸°
2ë²ˆ ë¬¸ì„œ(CPU node ì‚¬ìš©ë²•(Python))ë¥¼ ë¨¼ì € ìˆ™ì§€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” 2ë²ˆ ë¬¸ì„œì˜ Step 1, 2, 3 ì´í›„ì˜ ë‚´ìš©ë§Œì„ ë‹¤ë£¹ë‹ˆë‹¤.

`gpu-compute` nodeì—ì„œëŠ” `Python`ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
## Step 4. Export your conda setting

### ë²„ì „ ê´€ë¦¬
ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ë•Œì—ëŠ” ë²„ì „ ê´€ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤. 
- GPU ë“œë¼ì´ë²„ ë²„ì „(`418.67`)
- Python ë²„ì „
- CUDA ë²„ì „([í˜¸í™˜ì„± í‘œ](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html))
- cuDNN, ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬(`tensorflow`, `pytorch`) ë²„ì „(í˜¸í™˜ì„± í‘œ: [tensorflow](https://www.tensorflow.org/install/source#gpu), [pytorch](https://pytorch.org/get-started/previous-versions/))

ì´ë“¤ì˜ ë²„ì „ ê°„ í˜¸í™˜ì´ ë˜ëŠ” ì¡°í•©ì„ ìˆ™ì§€í•˜ê³  ì´ì— ë”°ë¼ conda environmentë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. `gpu-compute` nodeì˜ GPU ë“œë¼ì´ë²„ ë²„ì „ì€ `418.67`ìœ¼ë¡œ ê³ ì •ë˜ì–´ ìˆì§€ë§Œ, ë‚˜ë¨¸ì§€ ìš”ì†Œë“¤ì˜ ë²„ì „ì€ conda environmentë§ˆë‹¤ ë‹¤ë¥´ê²Œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¨, `Python` ë²„ì „ì˜ ê²½ìš° `gpu-compute` nodeì—ëŠ” conda version 4.6.14ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ 3.8ê¹Œì§€ë§Œ ì§€ì›í•©ë‹ˆë‹¤.

GPU ë“œë¼ì´ë²„ ë²„ì „(`418.67`)ì— ë§ëŠ” Python ë²„ì „ê³¼ ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ ì •í•œ ë‹¤ìŒ conda create ëª…ë ¹ì–´ì—ì„œ ë²„ì „ì„ ëª…ì‹œí•´ ì£¼ë©´ ì•Œì•„ì„œ CUDAì™€ cuDNN ë²„ì „ì„ ë§ì¶° ì¤ë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œëŠ” ì´ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì´ ë¬¸ì„œì—ì„œ ì‚¬ìš©í•˜ëŠ” ë²„ì „ì€ `tensorflow-gpu-2.2.0`ì…ë‹ˆë‹¤.

### 1. localì—ì„œ conda environment ìƒì„±
[ë¬¸ì„œ 2](https://hpc.stat.yonsei.ac.kr/docs/how-to-use-cpu-node_python/)ì˜ step 4ì˜ ë‚´ìš©ì— ë”°ë¼ localì—ì„œ conda environmentë¥¼ ìƒì„±í•©ë‹ˆë‹¤. **conda list**ë¡œ CUDA, cudnn ë²„ì „ì„ í™•ì¸í•©ë‹ˆë‹¤.

### 2. gpu-compute nodeì—ì„œ ë™ì¼í•œ conda environment êµ¬ì¶•
ë‘ ê°€ì§€ ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.
#### 2.1. ì¤‘ìš” íŒ¨í‚¤ì§€ì˜ ë²„ì „ë§Œ ë§ì¶”ê¸°
[ë¬¸ì„œ 2](https://hpc.stat.yonsei.ac.kr/docs/how-to-use-cpu-node_python/)ì—ì„œ í•œ ê²ƒì²˜ëŸ¼ tensorflow ë“±ì˜ ë²„ì „ë§Œ ë™ì¼í•˜ê²Œ í•˜ì—¬ `gpu-compute` nodeì—ì„œ `conda create`ë¡œ conda environmentë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì´ ë°©ë²•ì€ [ë¬¸ì„œ 2](https://hpc.stat.yonsei.ac.kr/docs/how-to-use-cpu-node_python/)ì˜ ì•ˆë‚´ë¥¼ ë”°ë¼ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì„¤ëª…ì„ ìƒëµí•˜ê³  sbatch scriptë§Œ ì œì‹œí•©ë‹ˆë‹¤.
- Slurm job configuratorì—ì„œ `Using GPU`ì— ì²´í¬í•œë‹¤ëŠ” ì ë§Œ ë‹¤ë¦…ë‹ˆë‹¤.
- ì´ ë¬¸ì„œì—ì„œ ì‚¬ìš©í•˜ëŠ” ë²„ì „ì€ `tensorflow-gpu-2.2.0`ì…ë‹ˆë‹¤.

```bash
#!/bin/bash
#SBATCH --job-name=testEnvGPU
#SBATCH --nodes=1
#SBATCH --mem=4gb
#SBATCH --partition=all
#SBATCH --nodelist=gpu-compute
#SBATCH --output=testEnvGPU.log
#SBATCH --error=testEnvGPU.err
CONDA_BIN_PATH=/opt/miniconda/bin
ENV_NAME=testEnvGPU #localì—ì„œì™€ ê°™ì€ ì´ë¦„ìœ¼ë¡œ ì…ë ¥
ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME
$CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH
$CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.7
source $CONDA_BIN_PATH/activate $ENV_PATH
conda install -y tensorflow-gpu=2.2.0
```

cudatoolkit, cudnn ë“±ì´ ìš©ëŸ‰ì´ ì»¤ì„œ ì‹œê°„ì´ ì¡°ê¸ˆ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.

#### 2.2. local environment exportí•˜ê¸°

Localì—ì„œ ìƒì„±ëœ ê°€ìƒí™˜ê²½ìœ¼ë¡œë¶€í„° í™˜ê²½ì„¤ì • `yml` íŒŒì¼ì„ ë§Œë“¤ê³ , ì´ë¥¼ ì´ìš©í•´ `gpu-compute` nodeì—ì„œ conda environmentë¥¼ ìƒì„±í•˜ì—¬ conda í™˜ê²½ì„ ë™ì¼í•˜ê²Œ ë§ì¶œ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ê²Œ ê°€ì¥ ì´ìƒì ì¸ ë°©ë²•ì´ì§€ë§Œ, local OSê°€ linuxê°€ ì•„ë‹ ê²½ìš° ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œëŠ” ì´ ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. 

Localì—ì„œ ì•„ë˜ ì»¤ë§¨ë“œë¡œ `yml` íŒŒì¼ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
```bash
# export conda setting
conda activate [YOUR ENV NAME]
conda env export -n [ENV NAME] -f [FILENAME].yml --no-builds # ì´ëŸ¬ë©´ ë¬¸ì œê°€ í•´ê²°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```

`yml` íŒŒì¼ì„ í´ëŸ¬ìŠ¤í„° ë‚´ user home directoryë¡œ ì˜®ê¸°ê³  ì•„ë˜ ì»¤ë§¨ë“œë¥¼ slurm job scriptì— ì¶”ê°€í•˜ê³  sbatchë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ ë•Œ Slurm job configuratorì—ì„œ `Using GPU`ì— ì²´í¬í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
# create environment from file

conda create --name [YOUR ENV NAME] python = [VESTION] # same env name in yml file
conda env create -f [FILENAME].yml

conda env create -p [prefix path] -f [filename].yml
```

**â€”no-builds** ì˜µì…˜ì€ ì„œë¡œ ë‹¤ë¥¸ OSì—ì„œ conda environment ë‚´ íŒ¨í‚¤ì§€ë“¤ì˜ ë²„ì „ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤. ì´ ì˜µì…˜ë§Œìœ¼ë¡œ ë¬¸ì œê°€ í•´ê²°ë˜ê¸°ë„ í•˜ì§€ë§Œ, í•´ê²°ë˜ì§€ ì•Šìœ¼ë©´ userê°€ ì§ì ‘ `yml` íŒŒì¼ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì—ëŸ¬ ë©”ì‹œì§€ì— **ResolvePackageNotFound**ë¼ëŠ” ë¬¸êµ¬ê°€ ë‚˜ì˜¤ëŠ”ë°, ì´ ë¬¸êµ¬ ì•„ë˜ì˜ íŒ¨í‚¤ì§€ë“¤ì„ `yml` íŒŒì¼ì—ì„œ ì‚­ì œí•´ì£¼ë©´ ë¬¸ì œê°€ í•´ê²°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
conda env create -f test.yml
Collecting package metadata: done
Solving environment: failed

# yml íŒŒì¼ì—ì„œ ì•„ë˜ì— ë“±ì¥í•˜ëŠ” íŒ¨í‚¤ì§€ë“¤ì„ ì§€ì›Œì¤ë‹ˆë‹¤.
ResolvePackageNotFound: 
  - libgfortran==3.0.1=h93005f0_2 # --no-builds ì˜µì…˜ì„ ì“°ë©´ íŒ¨í‚¤ì§€ ë²„ì „ ì˜†ì˜ ë¹Œë“œ ì •ë³´ê°€ ë‚˜ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤.
  - pyzmq==17.0.0=py36h1de35cc_1
  - python==3.6.6=h4a56312_1003
  - prompt_toolkit==1.0.15=py36haeda067_0
  - libiconv==1.15=h1de35cc_1004
  - sqlite==3.25.3=ha441bb4_0
  - six==1.11.0=py36h0e22d5e_1
  - cryptography==2.3.1=py36hdbc3d79_1000
  - openssl==1.0.2p=h1de35cc_1002
  - libxml2==2.9.8=hf14e9c8_1005
  - libcxxabi==4.0.1=hebd6815_0
  - matplotlib==2.2.3=py36h0e0179f_0
  - ptyprocess==0.5.2=py36he6521c3_0
```

<aside>
ğŸ’¡ `yml` fileì„ ì´ìš©í•œ conda í™˜ê²½ ì„¤ì •ì€ ë¡œì»¬ê³¼ ì„œë²„ ì‘ì—… í™˜ê²½ì„ ë™ì¼í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ì§€ë§Œ, conda í™˜ê²½ ì„¤ì • ê³¼ì •ì´ ë„ˆë¬´ ë²ˆê±°ë¡­ë‹¤ë©´ requirements.txtë¥¼ ë§Œë“¤ì–´ íŒ¨í‚¤ì§€ ë²„ì „ë§Œ ê´€ë¦¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
</aside>

```bash
conda install --force-reinstall -y -q -c conda-forge --file requirements.txt

# --force-reinstall : Install the package even if it already exists.
# -y : Yes, do not ask for confirmation.
# -q : Quiet, do not display progress bar.
# -c : Channels, additional channels to search for packages
# conda-forge is recommended
```


## Step 5. Slrum batch script ì‘ì„±í•˜ì—¬ ì„œë²„ì— ì œì¶œí•˜ê¸°

### 1. Python ì½”ë“œ ì‘ì„±
ì´ì œ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰í•  Python ì½”ë“œë¥¼ localì—ì„œ ì‘ì„±í•©ë‹ˆë‹¤. ë¨¼ì € localì—ì„œ ì½”ë“œê°€ ì˜¤ë¥˜ ì—†ì´ ëŒì•„ê°€ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ê·¸ í›„ í´ëŸ¬ìŠ¤í„°ì˜ user home directoryì— ì˜®ê¸°ê±°ë‚˜, `Visual Studio Code`ë‚´ì—ì„œ ì‘ì„±í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.

ì•„ë˜ëŠ” TensorFlow ê³µì‹ í˜ì´ì§€ì— ê²Œì‹œëœ [ì´ˆë³´ììš© ë¬¸ì„œ](https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ko) ì½”ë“œì…ë‹ˆë‹¤. Batch scriptë¥¼ ì‘ì„±í•  ë•ŒëŠ” ì•Œê³ ë¦¬ì¦˜ì˜ outputì´ ìë™ìœ¼ë¡œ ì €ì¥ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ íŒŒì¼ë¡œ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì½”ë“œë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì•„ë˜ ì½”ë“œì—ëŠ” ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì½”ë“œëŠ” ì—†ì§€ë§Œ, `tensorflow`ê°€ í•™ìŠµ ê³¼ì •ì„ ì½˜ì†”ì— ì¶œë ¥í•˜ê¸° ë•Œë¬¸ì— ì´ë¥¼ ë¡œê·¸ íŒŒì¼ì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ `tensor.py`ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ user home directoryì— ì €ì¥í•©ë‹ˆë‹¤.


```python
# tensor.py

import tensorflow as tf

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)

model.evaluate(x_test,  y_test, verbose=2)
```

### 2. í˜„ì¬ í´ëŸ¬ìŠ¤í„° ìì› ì‚¬ìš©ëŸ‰ í™•ì¸
`gpu-compute`ì˜ ì—¬ìœ  cpu ì½”ì–´ ê°œìˆ˜ì™€ RAMì€ ë¬¸ì„œ2ì— ìˆëŠ” ë°©ë²•ì„ í†µí•´ í™•ì¸í•©ë‹ˆë‹¤. 
GPUì˜ ê²½ìš° í•œ userê°€ í•˜ë‚˜ì˜ GPUë§Œì„ ì‚¬ìš©í•˜ë„ë¡ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ `gpu-compute` nodeëŠ” ìµœëŒ€ 2ëª…ì˜ userê°€ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **squeue** ì»¤ë§¨ë“œë¥¼ í†µí•´ `gpu-compute` nodeì—ì„œ ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ì‹¤í–‰ ëŒ€ê¸° ì¤‘ì¸ jobì˜ ê°œìˆ˜ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.


### 3. Slurm batch script ì‘ì„±
ì•ì„  ë‹¨ê³„ì—ì„œ ë§Œë“  í•´ë‹¹ conda environmentë¥¼ activateí•˜ê³  ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” Slurm batch scriptë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° ì†Œê°œ í˜ì´ì§€ì˜ [slurm job configurator](https://hpc.stat.yonsei.ac.kr/tools/job-configurator.html)ë¥¼ ì‚¬ìš©í•˜ë©´ scriptë¥¼ ì‰½ê²Œ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

![slurm_config](/img/slurm_config.png)
- Conda activateì— ì²´í¬í•©ë‹ˆë‹¤.
- Using GPUì— ì²´í¬í•©ë‹ˆë‹¤.
- ë¹ˆì¹¸ë“¤ì„ ì±„ì›ë‹ˆë‹¤.
- Scriptë€ì— **python xxx.py**ë¼ê³  ì‘ì„±í•©ë‹ˆë‹¤. ì´ëŠ” home directoryì— ìˆëŠ” **xxx.py** íŒŒì¼ì„ Pythonìœ¼ë¡œ ì‹¤í–‰í•˜ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.
- **Print & Copy** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë‚´ìš©ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë©ë‹ˆë‹¤. 

ì´ ë¬¸ì„œì—ì„œ ì‚¬ìš©í•œ Slurm batch scriptì˜ ë‚´ìš©ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```bash
#!/bin/bash 
#
#SBATCH --job-name=tensor
#SBATCH --partition=all
#SBATCH --account=mjm
#SBATCH --mem=16gb
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=00:30:00
#SBATCH --output=/mnt/nas/users/mjm/tensor.log
#SBATCH --error=/mnt/nas/users/mjm/tensor.err
#SBATCH --gres=gpu:1
#SBATCH --nodelist=gpu-compute

CONDA_BIN_PATH=/opt/miniconda/bin
ENV_NAME=testEnvGPU
ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME
source $CONDA_BIN_PATH/activate $ENV_PATH

python tensor.py
```

`tensor.job`ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ì˜ user home directoryì— ì €ì¥í•©ë‹ˆë‹¤.
  
sbatchì— ëŒ€í•œ ë” ìì„¸í•œ ì •ë³´ëŠ” [Slurm ê³µì‹ ì›¹í˜ì´ì§€](https://slurm.schedmd.com/sbatch.html)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

### 4. Slurm batch script ì‹¤í–‰
Conda environmentë¥¼ ë§Œë“¤ ë•Œì²˜ëŸ¼, **sbatch** ì»¤ë§¨ë“œë¥¼ í†µí•´ jobì„ ì œì¶œí•©ë‹ˆë‹¤. í• ë‹¹ë˜ëŠ” job ë²ˆí˜¸ëŠ” ë‚˜ì¤‘ì— squeueë¥¼ í†µí•´ ì •ë³´ë¥¼ í™•ì¸í•˜ê±°ë‚˜ jobì„ ì·¨ì†Œí•  ë•Œ ì´ìš©ë˜ë¯€ë¡œ ê¸°ë¡í•´ ë†“ì•„ì•¼ í•©ë‹ˆë‹¤.

í„°ë¯¸ë„ì„ ì—¬ëŸ¬ ê°œ ë„ìš´ ë‹¤ìŒ **smap -i**ë¡œ ì‘ì—… í˜„í™©ì„ í™•ì¸í•˜ê³ , **cat xxx.log**ì´ë‚˜ **tail -f xxx.err**ìœ¼ë¡œ ì½˜ì†” ì¶œë ¥ì´ë‚˜ errorë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

```bash
sbatch tensor.job
smap -i 1 # ì‘ì—… í˜„í™©ì„ 1ì´ˆë§ˆë‹¤ ê°±ì‹ í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. ctrl+cë¡œ escape í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
cat tensor.log
tail -f tensor.err
```

ë¡œê·¸ íŒŒì¼ì— ì½˜ì†” ì•„ì›ƒí’‹ì´ ê¸°ë¡ë©ë‹ˆë‹¤.
```bash
2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/5
1875/1875 [==============================] - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140
Epoch 2/5
1875/1875 [==============================] - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575
Epoch 3/5
1875/1875 [==============================] - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675
Epoch 4/5
1875/1875 [==============================] - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739
Epoch 5/5
1875/1875 [==============================] - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762
313/313 - 4s - loss: 0.0782 - accuracy: 0.9779
[0.078231580555439, 0.9779000282287598]
```


## ë” ì•Œì•„ë³´ê¸°

[Submitting a slurm job script](https://ubccr.freshdesk.com/support/solutions/articles/5000688140-submitting-a-slurm-job-script)

[SLRUM Job Examples](https://doc.zih.tu-dresden.de/jobs_and_resources/slurm_examples/)

[TensorFlow on the HPC Clusters](https://researchcomputing.princeton.edu/support/knowledge-base/tensorflow)
