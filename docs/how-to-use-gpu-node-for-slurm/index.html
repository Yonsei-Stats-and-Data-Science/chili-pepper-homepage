<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>4. GPU node 사용법(Python) | Chili Pepper</title>
<meta name="keywords" content="" />
<meta name="description" content="4. GPU node 사용법(Python) 2번 문서(CPU node 사용법(Python))를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.
GPU-compute node에서는 Python만 사용 가능합니다.
Step 4. Export your conda setting 버전 관리 딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.
 GPU 드라이버 버전(418.67) Python 버전 CUDA 버전(호환성 표) cuDNN, 딥러닝 라이브러리(tensorflow, pytorch) 버전(호환성 표: tensorflow, pytorch)  이들의 버전 간 호환이 되는 조합을 숙지하고 이에 따라 conda environment를 만들어야 합니다.">
<meta name="author" content="Gwnaghee Kim, Jongmin Mun">
<link rel="canonical" href="https://hpc.stat.yonsei.ac.kr/docs/how-to-use-gpu-node-for-slurm/" />
<meta name="google-site-verification" content="XYZabc" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css" integrity="sha256-yIlj/i15RiAA/Q&#43;xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://hpc.stat.yonsei.ac.kr/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hpc.stat.yonsei.ac.kr/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hpc.stat.yonsei.ac.kr/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hpc.stat.yonsei.ac.kr/apple-touch-icon.png">
<link rel="mask-icon" href="https://hpc.stat.yonsei.ac.kr/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.91.2" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="4. GPU node 사용법(Python)" />
<meta property="og:description" content="4. GPU node 사용법(Python) 2번 문서(CPU node 사용법(Python))를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.
GPU-compute node에서는 Python만 사용 가능합니다.
Step 4. Export your conda setting 버전 관리 딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.
 GPU 드라이버 버전(418.67) Python 버전 CUDA 버전(호환성 표) cuDNN, 딥러닝 라이브러리(tensorflow, pytorch) 버전(호환성 표: tensorflow, pytorch)  이들의 버전 간 호환이 되는 조합을 숙지하고 이에 따라 conda environment를 만들어야 합니다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hpc.stat.yonsei.ac.kr/docs/how-to-use-gpu-node-for-slurm/" /><meta property="article:section" content="docs" />
<meta property="article:published_time" content="2022-03-17T14:54:35&#43;09:00" />
<meta property="article:modified_time" content="2022-03-17T14:54:35&#43;09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="4. GPU node 사용법(Python)"/>
<meta name="twitter:description" content="4. GPU node 사용법(Python) 2번 문서(CPU node 사용법(Python))를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.
GPU-compute node에서는 Python만 사용 가능합니다.
Step 4. Export your conda setting 버전 관리 딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.
 GPU 드라이버 버전(418.67) Python 버전 CUDA 버전(호환성 표) cuDNN, 딥러닝 라이브러리(tensorflow, pytorch) 버전(호환성 표: tensorflow, pytorch)  이들의 버전 간 호환이 되는 조합을 숙지하고 이에 따라 conda environment를 만들어야 합니다."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Docs",
      "item": "https://hpc.stat.yonsei.ac.kr/docs/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "4. GPU node 사용법(Python)",
      "item": "https://hpc.stat.yonsei.ac.kr/docs/how-to-use-gpu-node-for-slurm/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "4. GPU node 사용법(Python)",
  "name": "4. GPU node 사용법(Python)",
  "description": "4. GPU node 사용법(Python) 2번 문서(CPU node 사용법(Python))를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.\nGPU-compute node에서는 Python만 사용 가능합니다.\nStep 4. Export your conda setting 버전 관리 딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.\n GPU 드라이버 버전(418.67) Python 버전 CUDA 버전(호환성 표) cuDNN, 딥러닝 라이브러리(tensorflow, pytorch) 버전(호환성 표: tensorflow, pytorch)  이들의 버전 간 호환이 되는 조합을 숙지하고 이에 따라 conda environment를 만들어야 합니다.",
  "keywords": [
    
  ],
  "articleBody": "4. GPU node 사용법(Python) 2번 문서(CPU node 사용법(Python))를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.\nGPU-compute node에서는 Python만 사용 가능합니다.\nStep 4. Export your conda setting 버전 관리 딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.\n GPU 드라이버 버전(418.67) Python 버전 CUDA 버전(호환성 표) cuDNN, 딥러닝 라이브러리(tensorflow, pytorch) 버전(호환성 표: tensorflow, pytorch)  이들의 버전 간 호환이 되는 조합을 숙지하고 이에 따라 conda environment를 만들어야 합니다. GPU-compute node의 GPU 드라이버 버전은 418.67으로 고정되어 있지만, 나머지 버전은 conda environment마다 다르게 설정할 수 있습니다. 단, Python 버전의 경우 gpu-compute node에는 conda version 4.6.14가 설치되어 있으므로 3.8까지만 지원합니다.\nGPU 드라이버 버전(418.67)에 맞는 Python 버전과 딥러닝 라이브러리 버전을 정한 다음 conda create 명령어에서 버전을 명시해 주면 알아서 CUDA와 cuDNN 버전을 맞춰 줍니다. 이 튜토리얼에서는 이 방법을 사용합니다.\n이 튜토리얼에서 사용하는 버전은 tensorflow-gpu-2.2.0입니다.\n1. local에서 conda environment 생성 1  conda create -n testEnvGPU python=3.7   성공적으로 생성되면 아래와 같은 결과가 나옵니다.\n1 2 3 4 5 6 7 8 9 10 11  Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate testEnv # # To deactivate an active environment, use # # $ conda deactivate   아래 커맨드를 통해 virtual environment가 제대로 생성되었는지 확인합니다.\n1  conda info --env   1 2 3 4  # conda environments: # base * /opt/miniconda3 testEnvGPU /opt/miniconda3/envs/testEnvGPU   Virtual environment에 진입한 뒤 패키지를 설치합니다.\n pip로 설치되는 패키지들은 conda로 설치된 패키지에 대한 정보를 모르기 때문에 의존성 충돌이 발생할 수 있으므로 conda만을 사용해서 설치하실 것을 권장합니다. anaconda 웹사이트에서 패키지명을 검색해서 linux-64를 지원하는 버전이 어디까지인지를 확인하고 설치하는 것을 추천합니다. 이 사이트는 설치 커맨드도 제공합니다. 여러 패키지를 설치할 경우 한 커맨드 내에 명시하면 conda가 자동으로 dependency 충돌을 검사해 줍니다. 패키지 버전을 명시할 때는 **=**를 사용합니다.  1 2 3 4  conda activate testEnvGPU #For example, conda install -c anaconda tensorflow-gpu=2.2.0 cudatoolkit cudnn matplotlib scikit-learn pandas numpy   아래 명령어로 cudatoolkit, cudnn 버전을 확인하여 batch\n1  conda list   2. GPU-compute node에서 동일한 conda environment 구축 2.1. 중요 패키지의 버전만 맞추기 2번 문서(CPU node 사용법(Python))에서 한 것처럼 tensorflow 등의 버전만 동일하게 하여 GPU-compute node에서 conda create로 conda environment를 만들 수 있습니다.\n 이 방법은 2번 문서의 안내를 따라 진행하면 됩니다. 따라서 설명을 생략하고 sbatch script만 제시합니다. Slurm job configurator에서 Using GPU에 체크한다는 점만 다릅니다. 이 튜토리얼에서 사용하는 버전은 tensorflow-gpu-2.2.0입니다.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #!/bin/bash #SBATCH --job-name=conda-env-create #SBATCH --nodes=1 #SBATCH --mem=4gb #SBATCH --partition=all #SBATCH --nodelist=gpu-compute #SBATCH --output=testEnvGPU.log #SBATCH --error=testEnvGPU.err CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnvGPU #local에서와 같은 이름으로 입력 ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.7 source $CONDA_BIN_PATH/activate $ENV_PATH conda install tensorflow-gpu=2.2.0   2.2. local environment export하기 Local에서 생성된 가상환경으로부터 환경설정 yml 파일을 만들고, 이를 이용해 GPU-compute node에서 conda environment를 생성하여 conda 환경을 동일하게 맞출 수도 있습니다. 이게 가장 이상적인 방법이지만, local OS가 linux가 아닐 경우 문제가 발생할 수 있습니다. 이 문서에서는 이 방법을 설명합니다.\nLocal에서 아래 커맨드로 yml 파일을 추출합니다.\n1 2 3  # export conda setting conda activate [YOUR ENV NAME] conda env export -n [ENV NAME] -f [FILENAME].yml --no-builds # 이러면 문제가 해결될 수 있습니다.   yml 파일을 클러스터 내 user home directory로 옮기고 아래 커맨드를 slurm job script에 추가하고 sbatch로 실행합니다. 이 때 Slurm job configurator에서 Using GPU에 체크해야 합니다.\n1 2 3 4 5 6  # create environment from file conda create --name [YOUR ENV NAME] python = [VESTION] # same env name in yml file conda env create -f [FILENAME].yml conda env create -p [prefix path] -f [filename].yml   —no-builds 옵션은 서로 다른 OS에서 conda environment 내 패키지들의 버전 충돌을 방지하기 위한 것입니다. 이 옵션만으로 문제가 해결되기도 하지만, 해결되지 않으면 user가 직접 yml 파일을 수정해야 합니다. 에러 메시지에 ResolvePackageNotFound라는 문구가 나오는데, 이 문구 아래의 패키지들을 yml 파일에서 삭제해주면 문제가 해결될 수 있습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  conda env create -f test.yml Collecting package metadata: done Solving environment: failed # yml 파일에서 아래에 등장하는 패키지들을 지워줍니다. ResolvePackageNotFound: - libgfortran==3.0.1=h93005f0_2 # --no-builds 옵션을 쓰면 패키지 버전 옆의 빌드 정보가 나오지 않습니다. - pyzmq==17.0.0=py36h1de35cc_1 - python==3.6.6=h4a56312_1003 - prompt_toolkit==1.0.15=py36haeda067_0 - libiconv==1.15=h1de35cc_1004 - sqlite==3.25.3=ha441bb4_0 - six==1.11.0=py36h0e22d5e_1 - cryptography==2.3.1=py36hdbc3d79_1000 - openssl==1.0.2p=h1de35cc_1002 - libxml2==2.9.8=hf14e9c8_1005 - libcxxabi==4.0.1=hebd6815_0 - matplotlib==2.2.3=py36h0e0179f_0 - ptyprocess==0.5.2=py36he6521c3_0    💡 `yml` file을 이용한 conda 환경 설정은 로컬과 서버 작업 환경을 동일하게 설정할 수 있는 신뢰할 수 있는 방법이지만, conda 환경 설정 과정이 너무 번거롭다면 requirements.txt를 만들어 패키지 버전만 관리할 수도 있습니다.  1 2 3 4 5 6 7  conda install --force-reinstall -y -q -c conda-forge --file requirements.txt # --force-reinstall : Install the package even if it already exists. # -y : Yes, do not ask for confirmation. # -q : Quiet, do not display progress bar. # -c : Channels, additional channels to search for packages # conda-forge is recommended   Step 5. Slrum batch script 작성하여 서버에 제출하기 1. Python 코드 작성 이제 클러스터에서 실행할 Python 코드를 local에서 작성합니다. 먼저 local에서 코드가 오류 없이 돌아가는지 확인합니다. 그 후 클러스터의 user home directory에 옮기거나, Visual Studio Code내에서 작성하여 저장합니다.\n아래는 TensorFlow 공식 페이지에 게시된 초보자용 튜토리얼 코드입니다. Batch script를 작성할 때는 알고리즘의 output이 자동으로 저장되지 않으므로 파일로 결과를 저장하는 코드를 포함하는 것이 좋습니다. 아래 코드에는 결과를 저장하는 코드는 없지만, **model.evaluate(x_test, y_test, verbose=2)**가 결과를 콘솔에 출력하기 때문에 로그 파일에서 결과를 볼 수 있습니다. 아래 코드를 tensor.py라는 이름으로 user home directory에 저장합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # tensor.py import tensorflow as tf mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation='softmax') ]) model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) model.fit(x_train, y_train, epochs=5) model.evaluate(x_test, y_test, verbose=2)   2. 현재 클러스터 자원 사용량 확인 아래 커맨드를 통해 cpu-compute 노드의 cpu와 RAM 사용 현황을 볼 수 있습니다.\n1  sinfo -o \"%n %e %m %a %c %C\"   아래와 같은 결과가 나옵니다.\n1 2 3  HOSTNAMES FREE_MEM MEMORY AVAIL CPUS CPUS(A/I/O/T) cpu-compute 105589 128916 up 32 0/32/0/32 gpu-compute 53318 80532 up 16 0/16/0/16    CPUS의 A/I/O/T는 allocated/idle/other/total을 의미합니다. 자신의 job이 바로 실행되기를 원한다면, Slurm batch script를 작성할 때  RAM 용량을 FREE_MEM보다 적게 설정해야 합니다. CPU 코어 개수를 CPUS idle보다 적게 설정해야 합니다.   현재 가용 자원보다 더 많은 자원을 요구하는 script를 작성하면, job이 바로 실행되지 않습니다. 대기 상태에 있다가 다른 사용자들의 job이 끝나고 자원이 반환되면 job이 실행됩니다.  3. Slurm batch script 작성 앞선 단계에서 만든 해당 conda environment를 activate하고 코드를 실행하는 Slurm batch script를 작성합니다. 클러스터 소개 페이지의 slurm job configurator를 사용하면 script를 쉽게 작성할 수 있습니다.\n Conda activate에 체크합니다. Using GPU에 체크합니다. 빈칸들을 채웁니다. Script란에 python xxx.py라고 작성합니다. 이는 home directory에 있는 xxx.py 파일을 Python으로 실행하라는 의미입니다. Print \u0026 Copy 버튼을 누르면 내용이 클립보드에 복사됩니다.  이 문서에서 사용한 Slurm batch script의 내용은 아래와 같습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/bin/bash # #SBATCH --job-name=tensor #SBATCH --partition=all #SBATCH --account=mjm #SBATCH --mem=16gb #SBATCH --ntasks=1 #SBATCH --cpus-per-task=8 #SBATCH --time=00:30:00 #SBATCH --output=/mnt/nas/users/mjm/tensor.log #SBATCH --error=/mnt/nas/users/mjm/tensor.err #SBATCH --gres=gpu:1 #SBATCH --nodelist=gpu-compute CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnvGPU ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME source $CONDA_BIN_PATH/activate $ENV_PATH python tensor.py   tensor.job이라는 이름으로 클러스터의 user home directory에 저장합니다.\nsbatch에 대한 더 자세한 정보는 Slurm 공식 웹페이지를 참조하세요.\n4. Slurm batch script 실행 Conda environment를 만들 때처럼, sbatch 커맨드를 통해 job을 제출합니다. 할당되는 job 번호는 나중에 job 정보를 확인하거나 job을 취소할 때 이용되므로 기록해 놓아야 합니다.\nsqueue나 smap -i로 작업 현황을 확인하고, cat xxx.log이나 tail -f xxx.err으로 콘솔 출력이나 error를 확인합니다.\n1 2 3 4  sbatch tensor.job smap -i 1 # 작업 현황을 1초마다 갱신하여 보여줍니다. ctrl+c로 escape 할 수 있습니다. cat tensor.log tail -f tensor.err   로그 파일에 콘솔 아웃풋이 기록됩니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. 2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2) Epoch 1/5 1875/1875 [==============================] - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140 Epoch 2/5 1875/1875 [==============================] - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575 Epoch 3/5 1875/1875 [==============================] - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675 Epoch 4/5 1875/1875 [==============================] - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739 Epoch 5/5 1875/1875 [==============================] - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762 313/313 - 4s - loss: 0.0782 - accuracy: 0.9779 [0.078231580555439, 0.9779000282287598]   더 알아보기 Submitting a slurm job script\nSLRUM Job Examples\nTensorFlow on the HPC Clusters\n",
  "wordCount" : "1431",
  "inLanguage": "en",
  "datePublished": "2022-03-17T14:54:35+09:00",
  "dateModified": "2022-03-17T14:54:35+09:00",
  "author":{
    "@type": "Person",
    "name": "Gwnaghee Kim, Jongmin Mun"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hpc.stat.yonsei.ac.kr/docs/how-to-use-gpu-node-for-slurm/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Chili Pepper",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hpc.stat.yonsei.ac.kr/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hpc.stat.yonsei.ac.kr" accesskey="h" title="Chili Pepper (Alt + H)">Chili Pepper</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hpc.stat.yonsei.ac.kr/docs/" title="Docs">
                    <span>Docs</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://hpc.stat.yonsei.ac.kr">Home</a>&nbsp;»&nbsp;<a href="https://hpc.stat.yonsei.ac.kr/docs/">Docs</a></div>
    <h1 class="post-title">
      4. GPU node 사용법(Python)
    </h1>
    <div class="post-meta"><span title='2022-03-17 14:54:35 +0900 +0900'>March 17, 2022</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Gwnaghee Kim, Jongmin Mun

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#4-gpu-node-%ec%82%ac%ec%9a%a9%eb%b2%95python" aria-label="4. GPU node 사용법(Python)">4. GPU node 사용법(Python)</a><ul>
                        
                <li>
                    <a href="#step-4-export-your-conda-setting" aria-label="Step 4. Export your conda setting">Step 4. Export your conda setting</a><ul>
                        
                <li>
                    <a href="#%eb%b2%84%ec%a0%84-%ea%b4%80%eb%a6%ac" aria-label="버전 관리">버전 관리</a></li>
                <li>
                    <a href="#1-local%ec%97%90%ec%84%9c-conda-environment-%ec%83%9d%ec%84%b1" aria-label="1. local에서 conda environment 생성">1. local에서 conda environment 생성</a></li>
                <li>
                    <a href="#2-gpu-compute-node%ec%97%90%ec%84%9c-%eb%8f%99%ec%9d%bc%ed%95%9c-conda-environment-%ea%b5%ac%ec%b6%95" aria-label="2. GPU-compute node에서 동일한 conda environment 구축">2. GPU-compute node에서 동일한 conda environment 구축</a><ul>
                        
                <li>
                    <a href="#21-%ec%a4%91%ec%9a%94-%ed%8c%a8%ed%82%a4%ec%a7%80%ec%9d%98-%eb%b2%84%ec%a0%84%eb%a7%8c-%eb%a7%9e%ec%b6%94%ea%b8%b0" aria-label="2.1. 중요 패키지의 버전만 맞추기">2.1. 중요 패키지의 버전만 맞추기</a></li>
                <li>
                    <a href="#22-local-environment-export%ed%95%98%ea%b8%b0" aria-label="2.2. local environment export하기">2.2. local environment export하기</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#step-5-slrum-batch-script-%ec%9e%91%ec%84%b1%ed%95%98%ec%97%ac-%ec%84%9c%eb%b2%84%ec%97%90-%ec%a0%9c%ec%b6%9c%ed%95%98%ea%b8%b0" aria-label="Step 5. Slrum batch script 작성하여 서버에 제출하기">Step 5. Slrum batch script 작성하여 서버에 제출하기</a><ul>
                        
                <li>
                    <a href="#1-python-%ec%bd%94%eb%93%9c-%ec%9e%91%ec%84%b1" aria-label="1. Python 코드 작성">1. Python 코드 작성</a></li>
                <li>
                    <a href="#2-%ed%98%84%ec%9e%ac-%ed%81%b4%eb%9f%ac%ec%8a%a4%ed%84%b0-%ec%9e%90%ec%9b%90-%ec%82%ac%ec%9a%a9%eb%9f%89-%ed%99%95%ec%9d%b8" aria-label="2. 현재 클러스터 자원 사용량 확인">2. 현재 클러스터 자원 사용량 확인</a></li>
                <li>
                    <a href="#3-slurm-batch-script-%ec%9e%91%ec%84%b1" aria-label="3. Slurm batch script 작성">3. Slurm batch script 작성</a></li>
                <li>
                    <a href="#4-slurm-batch-script-%ec%8b%a4%ed%96%89" aria-label="4. Slurm batch script 실행">4. Slurm batch script 실행</a></li></ul>
                </li>
                <li>
                    <a href="#%eb%8d%94-%ec%95%8c%ec%95%84%eb%b3%b4%ea%b8%b0" aria-label="더 알아보기">더 알아보기</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="4-gpu-node-사용법python">4. GPU node 사용법(Python)<a hidden class="anchor" aria-hidden="true" href="#4-gpu-node-사용법python">#</a></h1>
<p>2번 문서(CPU node 사용법(Python))를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.</p>
<p><code>GPU-compute</code> node에서는 <code>Python</code>만 사용 가능합니다.</p>
<h2 id="step-4-export-your-conda-setting">Step 4. Export your conda setting<a hidden class="anchor" aria-hidden="true" href="#step-4-export-your-conda-setting">#</a></h2>
<h3 id="버전-관리">버전 관리<a hidden class="anchor" aria-hidden="true" href="#버전-관리">#</a></h3>
<p>딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.</p>
<ul>
<li>GPU 드라이버 버전(<code>418.67</code>)</li>
<li>Python 버전</li>
<li>CUDA 버전(<a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html">호환성 표</a>)</li>
<li>cuDNN, 딥러닝 라이브러리(<code>tensorflow</code>, <code>pytorch</code>) 버전(호환성 표: <a href="https://www.tensorflow.org/install/source#gpu">tensorflow</a>, <a href="https://pytorch.org/get-started/previous-versions/">pytorch</a>)</li>
</ul>
<p>이들의 버전 간 호환이 되는 조합을 숙지하고 이에 따라 conda environment를 만들어야 합니다. <code>GPU-compute</code> node의 GPU 드라이버 버전은 <code>418.67</code>으로 고정되어 있지만, 나머지 버전은 conda environment마다 다르게 설정할 수 있습니다. 단, <code>Python</code> 버전의 경우 <code>gpu-compute</code> node에는 conda version 4.6.14가 설치되어 있으므로 3.8까지만 지원합니다.</p>
<p>GPU 드라이버 버전(<code>418.67</code>)에 맞는 Python 버전과 딥러닝 라이브러리 버전을 정한 다음 conda create 명령어에서 버전을 명시해 주면 알아서 CUDA와 cuDNN 버전을 맞춰 줍니다. 이 튜토리얼에서는 이 방법을 사용합니다.</p>
<p>이 튜토리얼에서 사용하는 버전은 <code>tensorflow-gpu-2.2.0</code>입니다.</p>
<h3 id="1-local에서-conda-environment-생성">1. local에서 conda environment 생성<a hidden class="anchor" aria-hidden="true" href="#1-local에서-conda-environment-생성">#</a></h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">conda create -n testEnvGPU <span class="nv">python</span><span class="o">=</span>3.7
</code></pre></td></tr></table>
</div>
</div><p>성공적으로 생성되면 아래와 같은 결과가 나옵니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-text" data-lang="text">Preparing transaction: done
Verifying transaction: done
Executing transaction: done
#
# To activate this environment, use
#
#     $ conda activate testEnv
#
# To deactivate an active environment, use
#
#     $ conda deactivate
</code></pre></td></tr></table>
</div>
</div><p>아래 커맨드를 통해 virtual environment가 제대로 생성되었는지 확인합니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">conda info --env
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2">2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3">3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4">4</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-text" data-lang="text"># conda environments:
#
base                  *  /opt/miniconda3
testEnvGPU               /opt/miniconda3/envs/testEnvGPU
</code></pre></td></tr></table>
</div>
</div><p>Virtual environment에 진입한 뒤 패키지를 설치합니다.</p>
<ul>
<li>pip로 설치되는 패키지들은 conda로 설치된 패키지에 대한 정보를 모르기 때문에 의존성 충돌이 발생할 수 있으므로 conda만을 사용해서 설치하실 것을 권장합니다.</li>
<li><a href="https://anaconda.org/anaconda/scikit-learn">anaconda 웹사이트</a>에서 패키지명을 검색해서 linux-64를 지원하는 버전이 어디까지인지를 확인하고 설치하는 것을 추천합니다. 이 사이트는 설치 커맨드도 제공합니다.</li>
<li>여러 패키지를 설치할 경우 한 커맨드 내에 명시하면 conda가 자동으로 dependency 충돌을 검사해 줍니다.</li>
<li>패키지 버전을 명시할 때는 **=**를 사용합니다.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2">2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3">3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4">4</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">conda activate testEnvGPU

<span class="c1">#For example,</span>
conda install -c anaconda tensorflow-gpu<span class="o">=</span>2.2.0 cudatoolkit cudnn matplotlib scikit-learn pandas numpy
</code></pre></td></tr></table>
</div>
</div><p>아래 명령어로 cudatoolkit, cudnn 버전을 확인하여 batch</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">conda list
</code></pre></td></tr></table>
</div>
</div><h3 id="2-gpu-compute-node에서-동일한-conda-environment-구축">2. GPU-compute node에서 동일한 conda environment 구축<a hidden class="anchor" aria-hidden="true" href="#2-gpu-compute-node에서-동일한-conda-environment-구축">#</a></h3>
<h4 id="21-중요-패키지의-버전만-맞추기">2.1. 중요 패키지의 버전만 맞추기<a hidden class="anchor" aria-hidden="true" href="#21-중요-패키지의-버전만-맞추기">#</a></h4>
<p>2번 문서(CPU node 사용법(Python))에서 한 것처럼 tensorflow 등의 버전만 동일하게 하여 <code>GPU-compute</code> node에서 <code>conda create</code>로 conda environment를 만들 수 있습니다.</p>
<ul>
<li>이 방법은 2번 문서의 안내를 따라 진행하면 됩니다. 따라서 설명을 생략하고 sbatch script만 제시합니다.</li>
<li>Slurm job configurator에서 <code>Using GPU</code>에 체크한다는 점만 다릅니다.</li>
<li>이 튜토리얼에서 사용하는 버전은 <code>tensorflow-gpu-2.2.0</code>입니다.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span><span class="lnt" id="12"><a style="outline: none; text-decoration:none; color:inherit" href="#12">12</a>
</span><span class="lnt" id="13"><a style="outline: none; text-decoration:none; color:inherit" href="#13">13</a>
</span><span class="lnt" id="14"><a style="outline: none; text-decoration:none; color:inherit" href="#14">14</a>
</span><span class="lnt" id="15"><a style="outline: none; text-decoration:none; color:inherit" href="#15">15</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">   <span class="c1">#!/bin/bash</span>
   <span class="c1">#SBATCH --job-name=conda-env-create</span>
   <span class="c1">#SBATCH --nodes=1</span>
   <span class="c1">#SBATCH --mem=4gb</span>
   <span class="c1">#SBATCH --partition=all</span>
   <span class="c1">#SBATCH --nodelist=gpu-compute</span>
   <span class="c1">#SBATCH --output=testEnvGPU.log</span>
   <span class="c1">#SBATCH --error=testEnvGPU.err</span>
   <span class="nv">CONDA_BIN_PATH</span><span class="o">=</span>/opt/miniconda/bin
   <span class="nv">ENV_NAME</span><span class="o">=</span>testEnvGPU <span class="c1">#local에서와 같은 이름으로 입력</span>
   <span class="nv">ENV_PATH</span><span class="o">=</span>/mnt/nas/users/<span class="k">$(</span>whoami<span class="k">)</span>/.conda/envs/<span class="nv">$ENV_NAME</span>
   <span class="nv">$CONDA_BIN_PATH</span>/conda env remove --prefix <span class="nv">$ENV_PATH</span>
   <span class="nv">$CONDA_BIN_PATH</span>/conda create -y --prefix <span class="nv">$ENV_PATH</span> <span class="nv">python</span><span class="o">=</span>3.7
   <span class="nb">source</span> <span class="nv">$CONDA_BIN_PATH</span>/activate <span class="nv">$ENV_PATH</span>
   conda install tensorflow-gpu<span class="o">=</span>2.2.0
</code></pre></td></tr></table>
</div>
</div><h4 id="22-local-environment-export하기">2.2. local environment export하기<a hidden class="anchor" aria-hidden="true" href="#22-local-environment-export하기">#</a></h4>
<p>Local에서 생성된 가상환경으로부터 환경설정 <code>yml</code> 파일을 만들고, 이를 이용해 <code>GPU-compute</code> node에서 conda environment를 생성하여 conda 환경을 동일하게 맞출 수도 있습니다. 이게 가장 이상적인 방법이지만, local OS가 linux가 아닐 경우 문제가 발생할 수 있습니다. 이 문서에서는 이 방법을 설명합니다.</p>
<p>Local에서 아래 커맨드로 <code>yml</code> 파일을 추출합니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2">2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3">3</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># export conda setting</span>
conda activate <span class="o">[</span>YOUR ENV NAME<span class="o">]</span>
conda env <span class="nb">export</span> -n <span class="o">[</span>ENV NAME<span class="o">]</span> -f <span class="o">[</span>FILENAME<span class="o">]</span>.yml --no-builds <span class="c1"># 이러면 문제가 해결될 수 있습니다.</span>
</code></pre></td></tr></table>
</div>
</div><p><code>yml</code> 파일을 클러스터 내 user home directory로 옮기고 아래 커맨드를 slurm job script에 추가하고 sbatch로 실행합니다. 이 때 Slurm job configurator에서 <code>Using GPU</code>에 체크해야 합니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2">2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3">3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4">4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5">5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6">6</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># create environment from file</span>

conda create --name <span class="o">[</span>YOUR ENV NAME<span class="o">]</span> <span class="nv">python</span> <span class="o">=</span> <span class="o">[</span>VESTION<span class="o">]</span> <span class="c1"># same env name in yml file</span>
conda env create -f <span class="o">[</span>FILENAME<span class="o">]</span>.yml

conda env create -p <span class="o">[</span>prefix path<span class="o">]</span> -f <span class="o">[</span>filename<span class="o">]</span>.yml
</code></pre></td></tr></table>
</div>
</div><p><strong>—no-builds</strong> 옵션은 서로 다른 OS에서 conda environment 내 패키지들의 버전 충돌을 방지하기 위한 것입니다. 이 옵션만으로 문제가 해결되기도 하지만, 해결되지 않으면 user가 직접 <code>yml</code> 파일을 수정해야 합니다. 에러 메시지에 <strong>ResolvePackageNotFound</strong>라는 문구가 나오는데, 이 문구 아래의 패키지들을 <code>yml</code> 파일에서 삭제해주면 문제가 해결될 수 있습니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span><span class="lnt" id="12"><a style="outline: none; text-decoration:none; color:inherit" href="#12">12</a>
</span><span class="lnt" id="13"><a style="outline: none; text-decoration:none; color:inherit" href="#13">13</a>
</span><span class="lnt" id="14"><a style="outline: none; text-decoration:none; color:inherit" href="#14">14</a>
</span><span class="lnt" id="15"><a style="outline: none; text-decoration:none; color:inherit" href="#15">15</a>
</span><span class="lnt" id="16"><a style="outline: none; text-decoration:none; color:inherit" href="#16">16</a>
</span><span class="lnt" id="17"><a style="outline: none; text-decoration:none; color:inherit" href="#17">17</a>
</span><span class="lnt" id="18"><a style="outline: none; text-decoration:none; color:inherit" href="#18">18</a>
</span><span class="lnt" id="19"><a style="outline: none; text-decoration:none; color:inherit" href="#19">19</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">conda env create -f test.yml
Collecting package metadata: <span class="k">done</span>
Solving environment: failed

<span class="c1"># yml 파일에서 아래에 등장하는 패키지들을 지워줍니다.</span>
ResolvePackageNotFound: 
  - <span class="nv">libgfortran</span><span class="o">==</span>3.0.1<span class="o">=</span>h93005f0_2 <span class="c1"># --no-builds 옵션을 쓰면 패키지 버전 옆의 빌드 정보가 나오지 않습니다.</span>
  - <span class="nv">pyzmq</span><span class="o">==</span>17.0.0<span class="o">=</span>py36h1de35cc_1
  - <span class="nv">python</span><span class="o">==</span>3.6.6<span class="o">=</span>h4a56312_1003
  - <span class="nv">prompt_toolkit</span><span class="o">==</span>1.0.15<span class="o">=</span>py36haeda067_0
  - <span class="nv">libiconv</span><span class="o">==</span>1.15<span class="o">=</span>h1de35cc_1004
  - <span class="nv">sqlite</span><span class="o">==</span>3.25.3<span class="o">=</span>ha441bb4_0
  - <span class="nv">six</span><span class="o">==</span>1.11.0<span class="o">=</span>py36h0e22d5e_1
  - <span class="nv">cryptography</span><span class="o">==</span>2.3.1<span class="o">=</span>py36hdbc3d79_1000
  - <span class="nv">openssl</span><span class="o">==</span>1.0.2p<span class="o">=</span>h1de35cc_1002
  - <span class="nv">libxml2</span><span class="o">==</span>2.9.8<span class="o">=</span>hf14e9c8_1005
  - <span class="nv">libcxxabi</span><span class="o">==</span>4.0.1<span class="o">=</span>hebd6815_0
  - <span class="nv">matplotlib</span><span class="o">==</span>2.2.3<span class="o">=</span>py36h0e0179f_0
  - <span class="nv">ptyprocess</span><span class="o">==</span>0.5.2<span class="o">=</span>py36he6521c3_0
</code></pre></td></tr></table>
</div>
</div><aside>
💡 `yml` file을 이용한 conda 환경 설정은 로컬과 서버 작업 환경을 동일하게 설정할 수 있는 신뢰할 수 있는 방법이지만, conda 환경 설정 과정이 너무 번거롭다면 requirements.txt를 만들어 패키지 버전만 관리할 수도 있습니다.
</aside>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2">2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3">3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4">4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5">5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6">6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7">7</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">conda install --force-reinstall -y -q -c conda-forge --file requirements.txt

<span class="c1"># --force-reinstall : Install the package even if it already exists.</span>
<span class="c1"># -y : Yes, do not ask for confirmation.</span>
<span class="c1"># -q : Quiet, do not display progress bar.</span>
<span class="c1"># -c : Channels, additional channels to search for packages</span>
<span class="c1"># conda-forge is recommended</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="step-5-slrum-batch-script-작성하여-서버에-제출하기">Step 5. Slrum batch script 작성하여 서버에 제출하기<a hidden class="anchor" aria-hidden="true" href="#step-5-slrum-batch-script-작성하여-서버에-제출하기">#</a></h2>
<h3 id="1-python-코드-작성">1. Python 코드 작성<a hidden class="anchor" aria-hidden="true" href="#1-python-코드-작성">#</a></h3>
<p>이제 클러스터에서 실행할 Python 코드를 local에서 작성합니다. 먼저 local에서 코드가 오류 없이 돌아가는지 확인합니다. 그 후 클러스터의 user home directory에 옮기거나, <code>Visual Studio Code</code>내에서 작성하여 저장합니다.</p>
<p>아래는 TensorFlow 공식 페이지에 게시된 <a href="https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ko">초보자용 튜토리얼</a> 코드입니다. Batch script를 작성할 때는 알고리즘의 output이 자동으로 저장되지 않으므로 파일로 결과를 저장하는 코드를 포함하는 것이 좋습니다. 아래 코드에는 결과를 저장하는 코드는 없지만, **model.evaluate(x_test,  y_test, verbose=2)**가 결과를 콘솔에 출력하기 때문에 로그 파일에서 결과를 볼 수 있습니다. 아래 코드를 <code>tensor.py</code>라는 이름으로 user home directory에 저장합니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span><span class="lnt" id="12"><a style="outline: none; text-decoration:none; color:inherit" href="#12">12</a>
</span><span class="lnt" id="13"><a style="outline: none; text-decoration:none; color:inherit" href="#13">13</a>
</span><span class="lnt" id="14"><a style="outline: none; text-decoration:none; color:inherit" href="#14">14</a>
</span><span class="lnt" id="15"><a style="outline: none; text-decoration:none; color:inherit" href="#15">15</a>
</span><span class="lnt" id="16"><a style="outline: none; text-decoration:none; color:inherit" href="#16">16</a>
</span><span class="lnt" id="17"><a style="outline: none; text-decoration:none; color:inherit" href="#17">17</a>
</span><span class="lnt" id="18"><a style="outline: none; text-decoration:none; color:inherit" href="#18">18</a>
</span><span class="lnt" id="19"><a style="outline: none; text-decoration:none; color:inherit" href="#19">19</a>
</span><span class="lnt" id="20"><a style="outline: none; text-decoration:none; color:inherit" href="#20">20</a>
</span><span class="lnt" id="21"><a style="outline: none; text-decoration:none; color:inherit" href="#21">21</a>
</span><span class="lnt" id="22"><a style="outline: none; text-decoration:none; color:inherit" href="#22">22</a>
</span><span class="lnt" id="23"><a style="outline: none; text-decoration:none; color:inherit" href="#23">23</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># tensor.py</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span>  <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="2-현재-클러스터-자원-사용량-확인">2. 현재 클러스터 자원 사용량 확인<a hidden class="anchor" aria-hidden="true" href="#2-현재-클러스터-자원-사용량-확인">#</a></h3>
<p>아래 커맨드를 통해 <code>cpu-compute</code> 노드의 cpu와 RAM 사용 현황을 볼 수 있습니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">sinfo -o <span class="s2">&#34;%n %e %m %a %c %C&#34;</span>
</code></pre></td></tr></table>
</div>
</div><p>아래와 같은 결과가 나옵니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2">2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3">3</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">HOSTNAMES FREE_MEM MEMORY AVAIL CPUS CPUS(A/I/O/T)
cpu-compute 105589 128916 up 32 0/32/0/32
gpu-compute 53318 80532 up 16 0/16/0/16
</code></pre></td></tr></table>
</div>
</div><ul>
<li>CPUS의 A/I/O/T는 allocated/idle/other/total을 의미합니다.</li>
<li>자신의 job이 바로 실행되기를 원한다면, Slurm batch script를 작성할 때
<ul>
<li>RAM 용량을 FREE_MEM보다 적게 설정해야 합니다.</li>
<li>CPU 코어 개수를 CPUS idle보다 적게 설정해야 합니다.</li>
</ul>
</li>
<li>현재 가용 자원보다 더 많은 자원을 요구하는 script를 작성하면, job이 바로 실행되지 않습니다. 대기 상태에 있다가 다른 사용자들의 job이 끝나고 자원이 반환되면 job이 실행됩니다.</li>
</ul>
<h3 id="3-slurm-batch-script-작성">3. Slurm batch script 작성<a hidden class="anchor" aria-hidden="true" href="#3-slurm-batch-script-작성">#</a></h3>
<p>앞선 단계에서 만든 해당 conda environment를 activate하고 코드를 실행하는 Slurm batch script를 작성합니다. 클러스터 소개 페이지의 <a href="https://hpc.stat.yonsei.ac.kr/tools/job-configurator.html">slurm job configurator</a>를 사용하면 script를 쉽게 작성할 수 있습니다.</p>
<p><img loading="lazy" src="/img/slurm_config.png" alt="slurm_config"  />
</p>
<ul>
<li>Conda activate에 체크합니다.</li>
<li>Using GPU에 체크합니다.</li>
<li>빈칸들을 채웁니다.</li>
<li>Script란에 <strong>python xxx.py</strong>라고 작성합니다. 이는 home directory에 있는 <strong>xxx.py</strong> 파일을 Python으로 실행하라는 의미입니다.</li>
<li><strong>Print &amp; Copy</strong> 버튼을 누르면 내용이 클립보드에 복사됩니다.</li>
</ul>
<p>이 문서에서 사용한 Slurm batch script의 내용은 아래와 같습니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span><span class="lnt" id="12"><a style="outline: none; text-decoration:none; color:inherit" href="#12">12</a>
</span><span class="lnt" id="13"><a style="outline: none; text-decoration:none; color:inherit" href="#13">13</a>
</span><span class="lnt" id="14"><a style="outline: none; text-decoration:none; color:inherit" href="#14">14</a>
</span><span class="lnt" id="15"><a style="outline: none; text-decoration:none; color:inherit" href="#15">15</a>
</span><span class="lnt" id="16"><a style="outline: none; text-decoration:none; color:inherit" href="#16">16</a>
</span><span class="lnt" id="17"><a style="outline: none; text-decoration:none; color:inherit" href="#17">17</a>
</span><span class="lnt" id="18"><a style="outline: none; text-decoration:none; color:inherit" href="#18">18</a>
</span><span class="lnt" id="19"><a style="outline: none; text-decoration:none; color:inherit" href="#19">19</a>
</span><span class="lnt" id="20"><a style="outline: none; text-decoration:none; color:inherit" href="#20">20</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="cp">#!/bin/bash 
</span><span class="cp"></span><span class="c1">#</span>
<span class="c1">#SBATCH --job-name=tensor</span>
<span class="c1">#SBATCH --partition=all</span>
<span class="c1">#SBATCH --account=mjm</span>
<span class="c1">#SBATCH --mem=16gb</span>
<span class="c1">#SBATCH --ntasks=1</span>
<span class="c1">#SBATCH --cpus-per-task=8</span>
<span class="c1">#SBATCH --time=00:30:00</span>
<span class="c1">#SBATCH --output=/mnt/nas/users/mjm/tensor.log</span>
<span class="c1">#SBATCH --error=/mnt/nas/users/mjm/tensor.err</span>
<span class="c1">#SBATCH --gres=gpu:1</span>
<span class="c1">#SBATCH --nodelist=gpu-compute</span>

<span class="nv">CONDA_BIN_PATH</span><span class="o">=</span>/opt/miniconda/bin
<span class="nv">ENV_NAME</span><span class="o">=</span>testEnvGPU
<span class="nv">ENV_PATH</span><span class="o">=</span>/mnt/nas/users/<span class="k">$(</span>whoami<span class="k">)</span>/.conda/envs/<span class="nv">$ENV_NAME</span>
<span class="nb">source</span> <span class="nv">$CONDA_BIN_PATH</span>/activate <span class="nv">$ENV_PATH</span>

python tensor.py
</code></pre></td></tr></table>
</div>
</div><p><code>tensor.job</code>이라는 이름으로 클러스터의 user home directory에 저장합니다.</p>
<p>sbatch에 대한 더 자세한 정보는 <a href="https://slurm.schedmd.com/sbatch.html">Slurm 공식 웹페이지</a>를 참조하세요.</p>
<h3 id="4-slurm-batch-script-실행">4. Slurm batch script 실행<a hidden class="anchor" aria-hidden="true" href="#4-slurm-batch-script-실행">#</a></h3>
<p>Conda environment를 만들 때처럼, <strong>sbatch</strong> 커맨드를 통해 job을 제출합니다. 할당되는 job 번호는 나중에 job 정보를 확인하거나 job을 취소할 때 이용되므로 기록해 놓아야 합니다.</p>
<p><strong>squeue</strong>나 <strong>smap -i</strong>로 작업 현황을 확인하고, <strong>cat xxx.log</strong>이나 <strong>tail -f xxx.err</strong>으로 콘솔 출력이나 error를 확인합니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2">2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3">3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4">4</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">sbatch tensor.job
smap -i <span class="m">1</span> <span class="c1"># 작업 현황을 1초마다 갱신하여 보여줍니다. ctrl+c로 escape 할 수 있습니다.</span>
cat tensor.log
tail -f tensor.err
</code></pre></td></tr></table>
</div>
</div><p>로그 파일에 콘솔 아웃풋이 기록됩니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span><span class="lnt" id="12"><a style="outline: none; text-decoration:none; color:inherit" href="#12">12</a>
</span><span class="lnt" id="13"><a style="outline: none; text-decoration:none; color:inherit" href="#13">13</a>
</span><span class="lnt" id="14"><a style="outline: none; text-decoration:none; color:inherit" href="#14">14</a>
</span><span class="lnt" id="15"><a style="outline: none; text-decoration:none; color:inherit" href="#15">15</a>
</span><span class="lnt" id="16"><a style="outline: none; text-decoration:none; color:inherit" href="#16">16</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142<span class="o">]</span> This TensorFlow binary is optimized with oneAPI Deep Neural Network Library <span class="o">(</span>oneDNN<span class="o">)</span> to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To <span class="nb">enable</span> them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146<span class="o">]</span> Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads <span class="k">for</span> best performance.
2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185<span class="o">]</span> None of the MLIR Optimization Passes are enabled <span class="o">(</span>registered 2<span class="o">)</span>
Epoch 1/5
1875/1875 <span class="o">[==============================]</span> - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140
Epoch 2/5
1875/1875 <span class="o">[==============================]</span> - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575
Epoch 3/5
1875/1875 <span class="o">[==============================]</span> - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675
Epoch 4/5
1875/1875 <span class="o">[==============================]</span> - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739
Epoch 5/5
1875/1875 <span class="o">[==============================]</span> - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762
313/313 - 4s - loss: 0.0782 - accuracy: 0.9779
<span class="o">[</span>0.078231580555439, 0.9779000282287598<span class="o">]</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="더-알아보기">더 알아보기<a hidden class="anchor" aria-hidden="true" href="#더-알아보기">#</a></h2>
<p><a href="https://ubccr.freshdesk.com/support/solutions/articles/5000688140-submitting-a-slurm-job-script">Submitting a slurm job script</a></p>
<p><a href="https://doc.zih.tu-dresden.de/jobs_and_resources/slurm_examples/">SLRUM Job Examples</a></p>
<p><a href="https://researchcomputing.princeton.edu/support/knowledge-base/tensorflow">TensorFlow on the HPC Clusters</a></p>


  </div>

  <footer class="post-footer">
<nav class="paginav">
  <a class="next" href="https://hpc.stat.yonsei.ac.kr/docs/how-to-use-cpu-node_r/">
    <span class="title">Next Page »</span>
    <br>
    <span>3. CPU node 사용법(R)</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <p align="center">
        <a href="http://bk21-bigdata.yonsei.ac.kr/bbs/page.php?hid=equipment">
        <img width='70%' src='https://hpc.stat.yonsei.ac.kr/images/logo.svg' alt='Yonsei BK logo'>
        </a>
        <br>
    </p>
    <span>&copy; 2022 <a href="https://hpc.stat.yonsei.ac.kr">Chili Pepper</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
