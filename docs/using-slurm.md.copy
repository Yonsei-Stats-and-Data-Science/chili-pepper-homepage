---
title: "How do I use the Chili Pepper Cluster?"
author: "Dongook Son"
date: 2022-02-21T12:12:53+09:00
draft: false
---

## Intro

This documentation will go over the basics of using the Chili Pepper cluster. Please go through this documentation step-by-step. Contact the server administrator via [email](mailto:jm.moon@yonsei.ac.kr) or use the Q&A channel in the [Slack Group](https://yonseidatasci-jnw9112.slack.com).




## Step 3 - Writing a `SBATCH` script for SLURM.

From the homepage the [SLURM batch scripting tool](https://hpc.stat.yonsei.ac.kr/tools/job-configurator.html) is available. Let's look at the sample script(`/mnt/nas/users/dummyuser/test_script.sh`) created by using the tool. The first-half(line 1 ~ 11) of the script consists of directives and parameters for the `slurm` job. Each user can set the number of nodes, the time for the job to occupy the number of nodes, the location for the output logfile. There are more options available for submitting a job. Additional resources for `SBATCH` arguments can be found [here](https://slurm.schedmd.com/sbatch.html).

```bash
#!/bin/bash
# The interpreter used to execute the script

#“#SBATCH” directives that convey submission options:

#SBATCH --job-name=conda-env-create
#SBATCH --nodes=1
#SBATCH --time=15:00
#SBATCH --account=dummyuser
#SBATCH --partition=all
#SBATCH --output=/mnt/nas/users/dummyuser/conda.log

# The application(s) to execute along with its input arguments and options:

CONDA_BIN_PATH=/opt/miniconda/bin
ENV_NAME=myenv
ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME
$CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH
$CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8 pandas numpy scikit-learn
source $CONDA_BIN_PATH/activate $ENV_PATH && pip freeze
```

From line 15 to the end of the script are actual bash commands for the node to execute. 
- Line 15~16  creates two local variables(`ENV_NAME` and `ENV_PATH`). In the above script a conda environment named `myenv` will be created under `/mnt/nas/users/dummyuser/.conda/envs/myenv`. 
- Line 18 will remove the environment in `ENV_PATH` if it is present. 
- Line 19 will create a conda environment in `ENV_PATH` thanks to the `-y(--yes)` flag. This environment will have a Python interpreter of version `3.8` along with listed packages(`pandas, numpy and scikit-learn`).
- Line 20 will activate the conda environment in `ENV_PATH` and then sequentially run a `pip freeze` to the `stdout`. Note that the `stdout` is saved in the log file from line 11(`/mnt/nas/users/dummyuser/conda.log`).

To actually run a data science job, the only thing you have to do is to change the required packages for your environment, modify the `pip freeze` into `python your_script_to_run.py`.

## Step 4 - Submitting the script

The submission of the script from the above is very simple.

```bash
sbatch test_script.sh
```

You can check the current job queue with the following command.

```bash
squeue
```

When you want to cancel the job you have submitted, get the `JOBID` from the `squeue` command and use the `scancel` command in the following fashion. Suppose the `JOBID` is `23`.

```bash
scancel 23
```

Note that ordinary users cannot cancel jobs that belong to other users, but the administrator can.
