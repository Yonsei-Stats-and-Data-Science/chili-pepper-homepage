<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>4. GPU node 사용법(Python) | Chili Pepper</title>
<meta name="keywords" content="" />
<meta name="description" content="4. GPU node에서 tensorflow 코드 실행하기 2번 문서를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.
gpu-compute node에서는 Python만 사용 가능합니다.
Step 4. Setting up a conda environment conda environment를 새로 만들면서 cudatoolkit, tensorflow, torch를 설치합니다.
주의:
  각 사용자의 conda environment에 tensorflow, torch 뿐 아니라 cudatoolkit도 따로 설치됩니다.
  gpu-compute node와 cpu-compute node는 서로 다른 컴퓨터이므로 한쪽에서 만든 conda environment는 다른 쪽에서 사용할 수 없습니다.">
<meta name="author" content="Gwnaghee Kim, Jongmin Mun">
<link rel="canonical" href="https://hpc.stat.yonsei.ac.kr/docs/04_how-to-use-gpu-node-for-slurm-copy/" />
<meta name="google-site-verification" content="XYZabc" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css" integrity="sha256-yIlj/i15RiAA/Q&#43;xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://hpc.stat.yonsei.ac.kr/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hpc.stat.yonsei.ac.kr/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hpc.stat.yonsei.ac.kr/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hpc.stat.yonsei.ac.kr/apple-touch-icon.png">
<link rel="mask-icon" href="https://hpc.stat.yonsei.ac.kr/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.91.2" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="4. GPU node 사용법(Python)" />
<meta property="og:description" content="4. GPU node에서 tensorflow 코드 실행하기 2번 문서를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.
gpu-compute node에서는 Python만 사용 가능합니다.
Step 4. Setting up a conda environment conda environment를 새로 만들면서 cudatoolkit, tensorflow, torch를 설치합니다.
주의:
  각 사용자의 conda environment에 tensorflow, torch 뿐 아니라 cudatoolkit도 따로 설치됩니다.
  gpu-compute node와 cpu-compute node는 서로 다른 컴퓨터이므로 한쪽에서 만든 conda environment는 다른 쪽에서 사용할 수 없습니다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hpc.stat.yonsei.ac.kr/docs/04_how-to-use-gpu-node-for-slurm-copy/" /><meta property="article:section" content="docs" />
<meta property="article:published_time" content="2022-03-05T14:14:35&#43;09:00" />
<meta property="article:modified_time" content="2022-03-05T14:14:35&#43;09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="4. GPU node 사용법(Python)"/>
<meta name="twitter:description" content="4. GPU node에서 tensorflow 코드 실행하기 2번 문서를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.
gpu-compute node에서는 Python만 사용 가능합니다.
Step 4. Setting up a conda environment conda environment를 새로 만들면서 cudatoolkit, tensorflow, torch를 설치합니다.
주의:
  각 사용자의 conda environment에 tensorflow, torch 뿐 아니라 cudatoolkit도 따로 설치됩니다.
  gpu-compute node와 cpu-compute node는 서로 다른 컴퓨터이므로 한쪽에서 만든 conda environment는 다른 쪽에서 사용할 수 없습니다."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Docs",
      "item": "https://hpc.stat.yonsei.ac.kr/docs/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "4. GPU node 사용법(Python)",
      "item": "https://hpc.stat.yonsei.ac.kr/docs/04_how-to-use-gpu-node-for-slurm-copy/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "4. GPU node 사용법(Python)",
  "name": "4. GPU node 사용법(Python)",
  "description": "4. GPU node에서 tensorflow 코드 실행하기 2번 문서를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.\ngpu-compute node에서는 Python만 사용 가능합니다.\nStep 4. Setting up a conda environment conda environment를 새로 만들면서 cudatoolkit, tensorflow, torch를 설치합니다.\n주의:\n  각 사용자의 conda environment에 tensorflow, torch 뿐 아니라 cudatoolkit도 따로 설치됩니다.\n  gpu-compute node와 cpu-compute node는 서로 다른 컴퓨터이므로 한쪽에서 만든 conda environment는 다른 쪽에서 사용할 수 없습니다.",
  "keywords": [
    
  ],
  "articleBody": "4. GPU node에서 tensorflow 코드 실행하기 2번 문서를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.\ngpu-compute node에서는 Python만 사용 가능합니다.\nStep 4. Setting up a conda environment conda environment를 새로 만들면서 cudatoolkit, tensorflow, torch를 설치합니다.\n주의:\n  각 사용자의 conda environment에 tensorflow, torch 뿐 아니라 cudatoolkit도 따로 설치됩니다.\n  gpu-compute node와 cpu-compute node는 서로 다른 컴퓨터이므로 한쪽에서 만든 conda environment는 다른 쪽에서 사용할 수 없습니다.\n  우리 컴퓨터의 gpu와 호환이 검증된 tensorflow-gpu==2.2.0, torch==1.7.1 cudatoolkit=11.0를 설치할 것을 권장합니다. 아래 설명은 다른 버전을 사용하고자 할 경우에만 필요합니다.\n설명: 버전 관리 딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.\n GPU 드라이버 버전(515.48.07) Python 버전 CUDA 버전(호환성 표) cuDNN, 딥러닝 라이브러리(tensorflow, pytorch) 버전(호환성 표: tensorflow, pytorch)  이 네 가지 요소의 버전이 서로 호환이 되는 조합으로 conda environment를 생성해야 합니다. gpu-compute node의 GPU 드라이버 버전은 515.48.07으로 고정되어 있지만, 나머지 요소들의 버전은 conda environment마다 다르게 설정할 수 있습니다. 단, Python 버전의 경우 gpu-compute node에는 conda version 4.6.14가 설치되어 있으므로 3.8까지만 지원합니다.\nConda를 이용해 버전을 쉽게 맞출 수 있습니다. 이 문서에서는 이 방법을 사용합니다.\n 주어진 GPU 드라이버 버전(515.48.07)에 맞게 Python 버전과 딥러닝 라이브러리 버전을 정합니다. conda install 명령어에서 버전을 명시해 주면 알아서 CUDA와 cuDNN 버전을 맞춰 줍니다.  Conda environment 생성 이제 2번 문서의 안내를 따라 진행하면 됩니다. 따라서 설명을 생략하고 sbatch script만 제시합니다.\n Slurm job configurator에서 Using GPU에 체크한다는 점만 다릅니다.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #!/bin/bash #SBATCH --job-name=testEnvGPU #SBATCH --nodes=1 #SBATCH --mem=4gb #SBATCH --partition=all #SBATCH --time=99:59:59 #SBATCH --nodelist=gpu-compute #SBATCH --output=testEnvGPU.log #SBATCH --error=testEnvGPU.err CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnvGPU ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8.13 source $CONDA_BIN_PATH/activate $ENV_PATH conda install -y tensorflow=2.3.0 pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=10.1 -c pytorch   cudatoolkit, cudnn 등이 용량이 커서 시간이 조금 오래 걸립니다.\nStep 5. job script 제출 1. Python 코드 작성 이제 클러스터에서 실행할 Python 코드를 local이나 Jupyter에서 작성하고 오류 없이 돌아가는지 확인합니다. 그 후 클러스터의 user home directory에 옮기거나, Visual Studio Code내에서 작성하여 저장합니다.\n아래는 TensorFlow 공식 페이지에 게시된 초보자용 문서 코드입니다. Batch script를 작성할 때는 알고리즘의 output이 자동으로 저장되지 않으므로 파일로 결과를 저장하는 코드를 포함하는 것이 좋습니다. 아래 코드에는 결과를 저장하는 코드는 없지만, tensorflow가 학습 과정을 콘솔에 출력하기 때문에 이를 로그 파일에서 볼 수 있습니다. 아래 코드를 tensor.py라는 이름으로 user home directory에 저장합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # tensor.py import tensorflow as tf mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation='softmax') ]) model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) model.fit(x_train, y_train, epochs=5) model.evaluate(x_test, y_test, verbose=2)   2. 현재 클러스터 자원 사용량 확인 gpu-compute의 여유 cpu 코어 개수와 RAM은 문서22번 문서에 있는 방법을 통해 확인합니다. GPU의 경우 한 user가 하나의 GPU만을 사용하도록 되어 있습니다. 따라서 gpu-compute node는 최대 2명의 user가 사용할 수 있습니다. squeue 커맨드를 통해 gpu-compute node에서 실행 중이거나 실행 대기 중인 job의 개수를 파악합니다.\n3. Slurm batch script 작성 앞선 단계에서 만든 해당 conda environment를 activate하고 코드를 실행하는 Slurm batch script를 작성합니다. 클러스터 소개 페이지의 slurm job configurator를 사용하면 script를 쉽게 작성할 수 있습니다.\n Conda activate에 체크합니다. Using GPU에 체크합니다. 빈칸들을 채웁니다. Script란에 python xxx.py라고 작성합니다. 이는 home directory에 있는 xxx.py 파일을 Python으로 실행하라는 의미입니다. Print \u0026 Copy 버튼을 누르면 내용이 클립보드에 복사됩니다.  이 문서에서 사용한 Slurm batch script의 내용은 아래와 같습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/bin/bash # #SBATCH --job-name=tensor #SBATCH --partition=all #SBATCH --account=mjm #SBATCH --mem=16gb #SBATCH --ntasks=1 #SBATCH --cpus-per-task=8 #SBATCH --time=00:30:00 #SBATCH --output=/mnt/nas/users/mjm/tensor.log #SBATCH --error=/mnt/nas/users/mjm/tensor.err #SBATCH --gres=gpu:1 #SBATCH --nodelist=gpu-compute CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnvGPU ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME source $CONDA_BIN_PATH/activate $ENV_PATH python tensor.py   tensor.job이라는 이름으로 클러스터의 user home directory에 저장합니다.\nsbatch에 대한 더 자세한 정보는 Slurm 공식 웹페이지를 참조하세요.\n4. Slurm batch script 실행 Conda environment를 만들 때처럼, sbatch 커맨드를 통해 job을 제출합니다. 할당되는 job 번호는 나중에 squeue를 통해 정보를 확인하거나 job을 취소할 때 이용되므로 기록해 놓아야 합니다.\n터미널을 여러 개 띄운 다음 smap -i로 작업 현황을 확인하고, cat xxx.log이나 tail -f xxx.err으로 콘솔 출력이나 error를 확인합니다.\n1 2 3 4  sbatch tensor.job smap -i 1 # 작업 현황을 1초마다 갱신하여 보여줍니다. ctrl+c로 escape 할 수 있습니다. cat tensor.log tail -f tensor.err   로그 파일에 콘솔 아웃풋이 기록됩니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. 2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2) Epoch 1/5 1875/1875 [==============================] - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140 Epoch 2/5 1875/1875 [==============================] - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575 Epoch 3/5 1875/1875 [==============================] - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675 Epoch 4/5 1875/1875 [==============================] - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739 Epoch 5/5 1875/1875 [==============================] - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762 313/313 - 4s - loss: 0.0782 - accuracy: 0.9779 [0.078231580555439, 0.9779000282287598]   더 알아보기 Submitting a slurm job script\nSLRUM Job Examples\nTensorFlow on the HPC Clusters\n",
  "wordCount" : "884",
  "inLanguage": "en",
  "datePublished": "2022-03-05T14:14:35+09:00",
  "dateModified": "2022-03-05T14:14:35+09:00",
  "author":{
    "@type": "Person",
    "name": "Gwnaghee Kim, Jongmin Mun"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hpc.stat.yonsei.ac.kr/docs/04_how-to-use-gpu-node-for-slurm-copy/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Chili Pepper",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hpc.stat.yonsei.ac.kr/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hpc.stat.yonsei.ac.kr" accesskey="h" title="Chili Pepper (Alt + H)">Chili Pepper</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hpc.stat.yonsei.ac.kr/docs/" title="Docs">
                    <span>Docs</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://hpc.stat.yonsei.ac.kr">Home</a>&nbsp;»&nbsp;<a href="https://hpc.stat.yonsei.ac.kr/docs/">Docs</a></div>
    <h1 class="post-title">
      4. GPU node 사용법(Python)
    </h1>
    <div class="post-meta"><span title='2022-03-05 14:14:35 +0900 +0900'>March 5, 2022</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Gwnaghee Kim, Jongmin Mun

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#4-gpu-node%ec%97%90%ec%84%9c-tensorflow-%ec%bd%94%eb%93%9c-%ec%8b%a4%ed%96%89%ed%95%98%ea%b8%b0" aria-label="4. GPU node에서 tensorflow 코드 실행하기">4. GPU node에서 tensorflow 코드 실행하기</a><ul>
                        
                <li>
                    <a href="#step-4-setting-up-a-conda-environment" aria-label="Step 4. Setting up a conda environment">Step 4. Setting up a conda environment</a><ul>
                        
                <li>
                    <a href="#%ec%84%a4%eb%aa%85-%eb%b2%84%ec%a0%84-%ea%b4%80%eb%a6%ac" aria-label="설명: 버전 관리">설명: 버전 관리</a></li>
                <li>
                    <a href="#conda-environment-%ec%83%9d%ec%84%b1" aria-label="Conda environment 생성">Conda environment 생성</a></li></ul>
                </li>
                <li>
                    <a href="#step-5-job-script-%ec%a0%9c%ec%b6%9c" aria-label="Step 5. job script 제출">Step 5. job script 제출</a><ul>
                        
                <li>
                    <a href="#1-python-%ec%bd%94%eb%93%9c-%ec%9e%91%ec%84%b1" aria-label="1. Python 코드 작성">1. Python 코드 작성</a></li>
                <li>
                    <a href="#2-%ed%98%84%ec%9e%ac-%ed%81%b4%eb%9f%ac%ec%8a%a4%ed%84%b0-%ec%9e%90%ec%9b%90-%ec%82%ac%ec%9a%a9%eb%9f%89-%ed%99%95%ec%9d%b8" aria-label="2. 현재 클러스터 자원 사용량 확인">2. 현재 클러스터 자원 사용량 확인</a></li>
                <li>
                    <a href="#3-slurm-batch-script-%ec%9e%91%ec%84%b1" aria-label="3. Slurm batch script 작성">3. Slurm batch script 작성</a></li>
                <li>
                    <a href="#4-slurm-batch-script-%ec%8b%a4%ed%96%89" aria-label="4. Slurm batch script 실행">4. Slurm batch script 실행</a></li></ul>
                </li>
                <li>
                    <a href="#%eb%8d%94-%ec%95%8c%ec%95%84%eb%b3%b4%ea%b8%b0" aria-label="더 알아보기">더 알아보기</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="4-gpu-node에서-tensorflow-코드-실행하기">4. GPU node에서 tensorflow 코드 실행하기<a hidden class="anchor" aria-hidden="true" href="#4-gpu-node에서-tensorflow-코드-실행하기">#</a></h1>
<p><a href="https://hpc.stat.yonsei.ac.kr/docs/02_how-to-use-cpu-node_python/">2번 문서</a>를 먼저 숙지하시기 바랍니다. 이 문서는 <a href="https://hpc.stat.yonsei.ac.kr/docs/02_how-to-use-cpu-node_python/">2번 문서</a>의 Step 1, 2, 3 이후의 내용만을 다룹니다.</p>
<p><code>gpu-compute</code> node에서는 <code>Python</code>만 사용 가능합니다.</p>
<h2 id="step-4-setting-up-a-conda-environment">Step 4. Setting up a conda environment<a hidden class="anchor" aria-hidden="true" href="#step-4-setting-up-a-conda-environment">#</a></h2>
<p>conda environment를 새로 만들면서 <code>cudatoolkit</code>, <code>tensorflow</code>, <code>torch</code>를 설치합니다.</p>
<p>주의:</p>
<ul>
<li>
<p>각 사용자의 conda environment에 <code>tensorflow</code>, <code>torch</code> 뿐 아니라 <code>cudatoolkit</code>도 따로 설치됩니다.</p>
</li>
<li>
<p><code>gpu-compute</code> node와 <code>cpu-compute</code> node는 서로 다른 컴퓨터이므로 한쪽에서 만든 conda environment는 다른 쪽에서 사용할 수 없습니다.</p>
</li>
</ul>
<p>우리 컴퓨터의 gpu와 호환이 검증된 <code>tensorflow-gpu==2.2.0</code>, <code>torch==1.7.1</code> <code>cudatoolkit=11.0</code>를 설치할 것을 권장합니다. 아래 설명은 다른 버전을 사용하고자 할 경우에만 필요합니다.</p>
<h3 id="설명-버전-관리">설명: 버전 관리<a hidden class="anchor" aria-hidden="true" href="#설명-버전-관리">#</a></h3>
<p>딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.</p>
<ul>
<li>GPU 드라이버 버전(<code>515.48.07</code>)</li>
<li>Python 버전</li>
<li>CUDA 버전(<a href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html">호환성 표</a>)</li>
<li>cuDNN, 딥러닝 라이브러리(<code>tensorflow</code>, <code>pytorch</code>) 버전(호환성 표: <a href="https://www.tensorflow.org/install/source#gpu">tensorflow</a>, <a href="https://pytorch.org/get-started/previous-versions/">pytorch</a>)</li>
</ul>
<p>이 네 가지 요소의 버전이 서로 호환이 되는 조합으로 conda environment를 생성해야 합니다. <code>gpu-compute</code> node의 GPU 드라이버 버전은 <code>515.48.07</code>으로 고정되어 있지만, 나머지 요소들의 버전은 conda environment마다 다르게 설정할 수 있습니다. 단, <code>Python</code> 버전의 경우 <code>gpu-compute</code> node에는 conda version 4.6.14가 설치되어 있으므로 3.8까지만 지원합니다.</p>
<p>Conda를 이용해 버전을 쉽게 맞출 수 있습니다. 이 문서에서는 이 방법을 사용합니다.</p>
<ol>
<li>주어진 GPU 드라이버 버전(<code>515.48.07</code>)에 맞게 Python 버전과 딥러닝 라이브러리 버전을 정합니다.</li>
<li>conda install 명령어에서 버전을 명시해 주면 알아서 CUDA와 cuDNN 버전을 맞춰 줍니다.</li>
</ol>
<h3 id="conda-environment-생성">Conda environment 생성<a hidden class="anchor" aria-hidden="true" href="#conda-environment-생성">#</a></h3>
<p>이제 <a href="https://hpc.stat.yonsei.ac.kr/docs/02_how-to-use-cpu-node_python/">2번 문서</a>의 안내를 따라 진행하면 됩니다. 따라서 설명을 생략하고 sbatch script만 제시합니다.</p>
<ul>
<li>Slurm job configurator에서 <code>Using GPU</code>에 체크한다는 점만 다릅니다.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span><span class="lnt" id="12"><a style="outline: none; text-decoration:none; color:inherit" href="#12">12</a>
</span><span class="lnt" id="13"><a style="outline: none; text-decoration:none; color:inherit" href="#13">13</a>
</span><span class="lnt" id="14"><a style="outline: none; text-decoration:none; color:inherit" href="#14">14</a>
</span><span class="lnt" id="15"><a style="outline: none; text-decoration:none; color:inherit" href="#15">15</a>
</span><span class="lnt" id="16"><a style="outline: none; text-decoration:none; color:inherit" href="#16">16</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="cp">#!/bin/bash
</span><span class="cp"></span><span class="c1">#SBATCH --job-name=testEnvGPU</span>
<span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --mem=4gb</span>
<span class="c1">#SBATCH --partition=all</span>
<span class="c1">#SBATCH --time=99:59:59</span>
<span class="c1">#SBATCH --nodelist=gpu-compute</span>
<span class="c1">#SBATCH --output=testEnvGPU.log</span>
<span class="c1">#SBATCH --error=testEnvGPU.err</span>
<span class="nv">CONDA_BIN_PATH</span><span class="o">=</span>/opt/miniconda/bin
<span class="nv">ENV_NAME</span><span class="o">=</span>testEnvGPU
<span class="nv">ENV_PATH</span><span class="o">=</span>/mnt/nas/users/<span class="k">$(</span>whoami<span class="k">)</span>/.conda/envs/<span class="nv">$ENV_NAME</span>
<span class="nv">$CONDA_BIN_PATH</span>/conda env remove --prefix <span class="nv">$ENV_PATH</span>
<span class="nv">$CONDA_BIN_PATH</span>/conda create -y --prefix <span class="nv">$ENV_PATH</span> <span class="nv">python</span><span class="o">=</span>3.8.13
<span class="nb">source</span> <span class="nv">$CONDA_BIN_PATH</span>/activate <span class="nv">$ENV_PATH</span>
conda install -y <span class="nv">tensorflow</span><span class="o">=</span>2.3.0 <span class="nv">pytorch</span><span class="o">==</span>1.7.1 <span class="nv">torchvision</span><span class="o">==</span>0.8.2 <span class="nv">torchaudio</span><span class="o">==</span>0.7.2 <span class="nv">cudatoolkit</span><span class="o">=</span>10.1 -c pytorch 
</code></pre></td></tr></table>
</div>
</div><p>cudatoolkit, cudnn 등이 용량이 커서 시간이 조금 오래 걸립니다.</p>
<h2 id="step-5-job-script-제출">Step 5. job script 제출<a hidden class="anchor" aria-hidden="true" href="#step-5-job-script-제출">#</a></h2>
<h3 id="1-python-코드-작성">1. Python 코드 작성<a hidden class="anchor" aria-hidden="true" href="#1-python-코드-작성">#</a></h3>
<p>이제 클러스터에서 실행할 Python 코드를 local이나 Jupyter에서 작성하고 오류 없이 돌아가는지 확인합니다. 그 후 클러스터의 user home directory에 옮기거나, <code>Visual Studio Code</code>내에서 작성하여 저장합니다.</p>
<p>아래는 TensorFlow 공식 페이지에 게시된 <a href="https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ko">초보자용 문서</a> 코드입니다. Batch script를 작성할 때는 알고리즘의 output이 자동으로 저장되지 않으므로 파일로 결과를 저장하는 코드를 포함하는 것이 좋습니다. 아래 코드에는 결과를 저장하는 코드는 없지만, <code>tensorflow</code>가 학습 과정을 콘솔에 출력하기 때문에 이를 로그 파일에서 볼 수 있습니다. 아래 코드를 <code>tensor.py</code>라는 이름으로 user home directory에 저장합니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span><span class="lnt" id="12"><a style="outline: none; text-decoration:none; color:inherit" href="#12">12</a>
</span><span class="lnt" id="13"><a style="outline: none; text-decoration:none; color:inherit" href="#13">13</a>
</span><span class="lnt" id="14"><a style="outline: none; text-decoration:none; color:inherit" href="#14">14</a>
</span><span class="lnt" id="15"><a style="outline: none; text-decoration:none; color:inherit" href="#15">15</a>
</span><span class="lnt" id="16"><a style="outline: none; text-decoration:none; color:inherit" href="#16">16</a>
</span><span class="lnt" id="17"><a style="outline: none; text-decoration:none; color:inherit" href="#17">17</a>
</span><span class="lnt" id="18"><a style="outline: none; text-decoration:none; color:inherit" href="#18">18</a>
</span><span class="lnt" id="19"><a style="outline: none; text-decoration:none; color:inherit" href="#19">19</a>
</span><span class="lnt" id="20"><a style="outline: none; text-decoration:none; color:inherit" href="#20">20</a>
</span><span class="lnt" id="21"><a style="outline: none; text-decoration:none; color:inherit" href="#21">21</a>
</span><span class="lnt" id="22"><a style="outline: none; text-decoration:none; color:inherit" href="#22">22</a>
</span><span class="lnt" id="23"><a style="outline: none; text-decoration:none; color:inherit" href="#23">23</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># tensor.py</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span>  <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="2-현재-클러스터-자원-사용량-확인">2. 현재 클러스터 자원 사용량 확인<a hidden class="anchor" aria-hidden="true" href="#2-현재-클러스터-자원-사용량-확인">#</a></h3>
<p><code>gpu-compute</code>의 여유 cpu 코어 개수와 RAM은 문서2<a href="https://hpc.stat.yonsei.ac.kr/docs/02_how-to-use-cpu-node_python/">2번 문서</a>에 있는 방법을 통해 확인합니다.
GPU의 경우 한 user가 하나의 GPU만을 사용하도록 되어 있습니다. 따라서 <code>gpu-compute</code> node는 최대 2명의 user가 사용할 수 있습니다. <strong>squeue</strong> 커맨드를 통해 <code>gpu-compute</code> node에서 실행 중이거나 실행 대기 중인 job의 개수를 파악합니다.</p>
<h3 id="3-slurm-batch-script-작성">3. Slurm batch script 작성<a hidden class="anchor" aria-hidden="true" href="#3-slurm-batch-script-작성">#</a></h3>
<p>앞선 단계에서 만든 해당 conda environment를 activate하고 코드를 실행하는 Slurm batch script를 작성합니다. 클러스터 소개 페이지의 <a href="https://hpc.stat.yonsei.ac.kr/tools/job-configurator.html">slurm job configurator</a>를 사용하면 script를 쉽게 작성할 수 있습니다.</p>
<p><img loading="lazy" src="/img/slurm_config.png" alt="slurm_config"  />
</p>
<ul>
<li>Conda activate에 체크합니다.</li>
<li>Using GPU에 체크합니다.</li>
<li>빈칸들을 채웁니다.</li>
<li>Script란에 <strong>python xxx.py</strong>라고 작성합니다. 이는 home directory에 있는 <strong>xxx.py</strong> 파일을 Python으로 실행하라는 의미입니다.</li>
<li><strong>Print &amp; Copy</strong> 버튼을 누르면 내용이 클립보드에 복사됩니다.</li>
</ul>
<p>이 문서에서 사용한 Slurm batch script의 내용은 아래와 같습니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span><span class="lnt" id="12"><a style="outline: none; text-decoration:none; color:inherit" href="#12">12</a>
</span><span class="lnt" id="13"><a style="outline: none; text-decoration:none; color:inherit" href="#13">13</a>
</span><span class="lnt" id="14"><a style="outline: none; text-decoration:none; color:inherit" href="#14">14</a>
</span><span class="lnt" id="15"><a style="outline: none; text-decoration:none; color:inherit" href="#15">15</a>
</span><span class="lnt" id="16"><a style="outline: none; text-decoration:none; color:inherit" href="#16">16</a>
</span><span class="lnt" id="17"><a style="outline: none; text-decoration:none; color:inherit" href="#17">17</a>
</span><span class="lnt" id="18"><a style="outline: none; text-decoration:none; color:inherit" href="#18">18</a>
</span><span class="lnt" id="19"><a style="outline: none; text-decoration:none; color:inherit" href="#19">19</a>
</span><span class="lnt" id="20"><a style="outline: none; text-decoration:none; color:inherit" href="#20">20</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="cp">#!/bin/bash 
</span><span class="cp"></span><span class="c1">#</span>
<span class="c1">#SBATCH --job-name=tensor</span>
<span class="c1">#SBATCH --partition=all</span>
<span class="c1">#SBATCH --account=mjm</span>
<span class="c1">#SBATCH --mem=16gb</span>
<span class="c1">#SBATCH --ntasks=1</span>
<span class="c1">#SBATCH --cpus-per-task=8</span>
<span class="c1">#SBATCH --time=00:30:00</span>
<span class="c1">#SBATCH --output=/mnt/nas/users/mjm/tensor.log</span>
<span class="c1">#SBATCH --error=/mnt/nas/users/mjm/tensor.err</span>
<span class="c1">#SBATCH --gres=gpu:1</span>
<span class="c1">#SBATCH --nodelist=gpu-compute</span>

<span class="nv">CONDA_BIN_PATH</span><span class="o">=</span>/opt/miniconda/bin
<span class="nv">ENV_NAME</span><span class="o">=</span>testEnvGPU
<span class="nv">ENV_PATH</span><span class="o">=</span>/mnt/nas/users/<span class="k">$(</span>whoami<span class="k">)</span>/.conda/envs/<span class="nv">$ENV_NAME</span>
<span class="nb">source</span> <span class="nv">$CONDA_BIN_PATH</span>/activate <span class="nv">$ENV_PATH</span>

python tensor.py
</code></pre></td></tr></table>
</div>
</div><p><code>tensor.job</code>이라는 이름으로 클러스터의 user home directory에 저장합니다.</p>
<p>sbatch에 대한 더 자세한 정보는 <a href="https://slurm.schedmd.com/sbatch.html">Slurm 공식 웹페이지</a>를 참조하세요.</p>
<h3 id="4-slurm-batch-script-실행">4. Slurm batch script 실행<a hidden class="anchor" aria-hidden="true" href="#4-slurm-batch-script-실행">#</a></h3>
<p>Conda environment를 만들 때처럼, <strong>sbatch</strong> 커맨드를 통해 job을 제출합니다. 할당되는 job 번호는 나중에 squeue를 통해 정보를 확인하거나 job을 취소할 때 이용되므로 기록해 놓아야 합니다.</p>
<p>터미널을 여러 개 띄운 다음 <strong>smap -i</strong>로 작업 현황을 확인하고, <strong>cat xxx.log</strong>이나 <strong>tail -f xxx.err</strong>으로 콘솔 출력이나 error를 확인합니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1">1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2">2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3">3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4">4</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">sbatch tensor.job
smap -i <span class="m">1</span> <span class="c1"># 작업 현황을 1초마다 갱신하여 보여줍니다. ctrl+c로 escape 할 수 있습니다.</span>
cat tensor.log
tail -f tensor.err
</code></pre></td></tr></table>
</div>
</div><p>로그 파일에 콘솔 아웃풋이 기록됩니다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="1"><a style="outline: none; text-decoration:none; color:inherit" href="#1"> 1</a>
</span><span class="lnt" id="2"><a style="outline: none; text-decoration:none; color:inherit" href="#2"> 2</a>
</span><span class="lnt" id="3"><a style="outline: none; text-decoration:none; color:inherit" href="#3"> 3</a>
</span><span class="lnt" id="4"><a style="outline: none; text-decoration:none; color:inherit" href="#4"> 4</a>
</span><span class="lnt" id="5"><a style="outline: none; text-decoration:none; color:inherit" href="#5"> 5</a>
</span><span class="lnt" id="6"><a style="outline: none; text-decoration:none; color:inherit" href="#6"> 6</a>
</span><span class="lnt" id="7"><a style="outline: none; text-decoration:none; color:inherit" href="#7"> 7</a>
</span><span class="lnt" id="8"><a style="outline: none; text-decoration:none; color:inherit" href="#8"> 8</a>
</span><span class="lnt" id="9"><a style="outline: none; text-decoration:none; color:inherit" href="#9"> 9</a>
</span><span class="lnt" id="10"><a style="outline: none; text-decoration:none; color:inherit" href="#10">10</a>
</span><span class="lnt" id="11"><a style="outline: none; text-decoration:none; color:inherit" href="#11">11</a>
</span><span class="lnt" id="12"><a style="outline: none; text-decoration:none; color:inherit" href="#12">12</a>
</span><span class="lnt" id="13"><a style="outline: none; text-decoration:none; color:inherit" href="#13">13</a>
</span><span class="lnt" id="14"><a style="outline: none; text-decoration:none; color:inherit" href="#14">14</a>
</span><span class="lnt" id="15"><a style="outline: none; text-decoration:none; color:inherit" href="#15">15</a>
</span><span class="lnt" id="16"><a style="outline: none; text-decoration:none; color:inherit" href="#16">16</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142<span class="o">]</span> This TensorFlow binary is optimized with oneAPI Deep Neural Network Library <span class="o">(</span>oneDNN<span class="o">)</span> to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To <span class="nb">enable</span> them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146<span class="o">]</span> Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads <span class="k">for</span> best performance.
2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185<span class="o">]</span> None of the MLIR Optimization Passes are enabled <span class="o">(</span>registered 2<span class="o">)</span>
Epoch 1/5
1875/1875 <span class="o">[==============================]</span> - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140
Epoch 2/5
1875/1875 <span class="o">[==============================]</span> - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575
Epoch 3/5
1875/1875 <span class="o">[==============================]</span> - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675
Epoch 4/5
1875/1875 <span class="o">[==============================]</span> - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739
Epoch 5/5
1875/1875 <span class="o">[==============================]</span> - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762
313/313 - 4s - loss: 0.0782 - accuracy: 0.9779
<span class="o">[</span>0.078231580555439, 0.9779000282287598<span class="o">]</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="더-알아보기">더 알아보기<a hidden class="anchor" aria-hidden="true" href="#더-알아보기">#</a></h2>
<p><a href="https://ubccr.freshdesk.com/support/solutions/articles/5000688140-submitting-a-slurm-job-script">Submitting a slurm job script</a></p>
<p><a href="https://doc.zih.tu-dresden.de/jobs_and_resources/slurm_examples/">SLRUM Job Examples</a></p>
<p><a href="https://researchcomputing.princeton.edu/support/knowledge-base/tensorflow">TensorFlow on the HPC Clusters</a></p>


  </div>

  <footer class="post-footer">
<nav class="paginav">
  <a class="prev" href="https://hpc.stat.yonsei.ac.kr/docs/05_ipad/">
    <span class="title">« Prev Page</span>
    <br>
    <span>5. 모바일 기기에서(iOS/Android) 클러스터 사용하기</span>
  </a>
  <a class="next" href="https://hpc.stat.yonsei.ac.kr/docs/03_how-to-use-cpu-node_r/">
    <span class="title">Next Page »</span>
    <br>
    <span>3. CPU node 사용법(R)</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <p align="center">
        <a href="http://bk21-bigdata.yonsei.ac.kr/bbs/page.php?hid=equipment">
        <img width='70%' src='https://hpc.stat.yonsei.ac.kr/images/logo.svg' alt='Yonsei BK logo'>
        </a>
        <br>
    </p>
    <span>&copy; 2022 <a href="https://hpc.stat.yonsei.ac.kr">Chili Pepper</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
