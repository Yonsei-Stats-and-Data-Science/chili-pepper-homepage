[{"content":"Filezilla로 파일 전송하기 Filezilla는 MacOS, Windows, Linux에서 사용할 수 있는 FTP 클라이언트입니다. Filezilla로 scp도 이용할 수 있기 때문에, drag \u0026amp; drop으로 편리하게 파일을 전송할 수 있습니다.\nFilezilla를 실행한 뒤 파일-\u0026gt;사이트 관리자를 누릅니다. 좌측 하단의 \u0026lsquo;New site\u0026rsquo;를 클릭하고, 오른쪽에\n 프로토콜: SFTP - SSH File Transfer Protocol 호스트: hpc.stat.yonsei.ac.kr 포트: 공지된 SSH port 로그온 유형: 비밀번호 묻기 사용자: 본인의 user name 을 입력하고 연결을 클릭합니다.  Password를 묻는 창이 나오면 리눅스 user password를 입력합니다. \u0026lsquo;알 수 없는 호스트키\u0026rsquo; 창이 나오면 확인을 클릭합니다.\n아래와 같은 창이 나오면 drag \u0026amp; drop으로 로컬과 서버 양방향으로 파일을 전송할 수 있습니다.\nReference [fn^1] https://www.bettertechtips.com/how-to/use-scp-filezilla/\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/filezilla/","summary":"Filezilla로 파일 전송하기 Filezilla는 MacOS, Windows, Linux에서 사용할 수 있는 FTP 클라이언트입니다. Filezilla로 scp도 이용할 수 있기 때문에, drag \u0026amp; drop으로 편리하게 파일을 전송할 수 있습니다.\nFilezilla를 실행한 뒤 파일-\u0026gt;사이트 관리자를 누릅니다. 좌측 하단의 \u0026lsquo;New site\u0026rsquo;를 클릭하고, 오른쪽에\n 프로토콜: SFTP - SSH File Transfer Protocol 호스트: hpc.stat.yonsei.ac.kr 포트: 공지된 SSH port 로그온 유형: 비밀번호 묻기 사용자: 본인의 user name 을 입력하고 연결을 클릭합니다.  Password를 묻는 창이 나오면 리눅스 user password를 입력합니다.","title":"[Tip] Filezilla로 파일 전송하기"},{"content":"yml 파일 이용해 local과 동일한 conda 환경 구축하기 conda env export 커맨드를 이용해 environment 전체를 .yml 파일로 만들고 이를 이용해 cpu-compute 노드에서 environment를 구축하는 것이 가장 이상적인 방법입니다. 하지만 이 방법은 user의 local 컴퓨터가 linux가 아니면(특히 Windows일 경우) 자잘한 오류가 발생합니다[^fn2]. 차선책으로 설치된 패키지 목록과 버전만을 requirements.txt로 추출하여 노드에서 cpu-compute에서 설치할 수 있습니다.\n  User의 local 컴퓨터에서에서 아래의 커맨드를 통해 virtual environment로부터 환경설정 파일을 추출합니다. —no-builds는 서로 다른 OS에서 conda environment 내 패키지들의 버전 충돌을 방지하기 위한 옵션입니다.\n1 2 3  # export conda setting conda activate [YOUR ENV NAME] conda env export \u0026gt; [ENV NAME] -f [FILENAME].yml --no-builds # OS 문제를 해결해주는 옵션이지만, 완전히 해결되지 않을 수도 있습니다.     yml 파일을 scp를 통해 클러스터 내의 user home directory로 전송합니다. 위의 Step 3 또는 여기를 참조하세요.\n  Conda environment 생성 batch script를 작성합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  #!/bin/bash  #“#SBATCH” directives that convey submission options: #SBATCH --job-name=conda-env-create #SBATCH --nodes=1 #SBATCH --time=50:00 #SBATCH --account=dummyuser #SBATCH --partition=all #SBATCH --nodelist=cpu-compute #SBATCH --output=testEnv.out #SBATCH --error=testEnv.err # The application(s) to execute along with its input arguments and options: CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnv #local에서와 같은 이름으로 입력 ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH conda env create -p ENV_PATH -f testEnv.yml   위 내용에서\n x번 라인의 #SBATCH \u0026ndash;output=testEnv.out의 output log 파일명 x번 라인의 #SBATCH \u0026ndash;error=testEnv.err의 error log 파일명 x번 라인의 environment name xx번 라인의 yml 파일 이름 을 원하는 데로 수정한 뒤 local에서 testEnv.sh로 저장하여 scp로 클러스터 내 user home directory로 전송합니다. 또는 proxy node에 접속한 뒤 home directory에서  1  vi testEnv.sh   를 입력하여 linux의 텍스트 에디터를 실행한 뒤 ctrl+v로 위 내용을 붙여넣기하고 esc, :wq, ENTER를 차례로 눌러 저장합니다.\n  작성한 스크립트 실행하기. proxy node에 SSH접속한 뒤 home directory에서\n1  sbatch testEnv.sh   를 입력해 slurm batch job submission을 수행합니다. 작업이 노드에서 성공적으로 실행되면\n1  Submitted batch job 401   와 같은 메시지가 뜨고 job 번호가 할당됩니다.\n1  squeue   커맨드를 통해 작업 실행 현황을 확인할 수 있습니다.\n1 2  JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 402 all conda-en mjm R 0:01 1 cpu-compute   또는 아래 커맨드를 통해 실시간으로 작업 실행 현황을 확인할 수 있습니다.\n1  smap -i 1   다음 커맨드를 통해 error log파일의 내용을 확인할 수 있습니다.\n1  cat testEnv.err   Local 환경이 linux가 아니었을 경우 거의 항상 다음과 같은 오류가 발생합니다.\n1 2  ResolvePackageNotFound: - libgfortran=5.0.0   이 경우 user가 직접 env 파일을 수정해야 합니다. 이런 경우 ResolvePackageNotFound 아래에 나오는 패키지들을 yml 파일에서 삭제해주면 문제가 해결될 수 있습니다.\n1  vi testEnv.yml   로 yml 파일을 열면 아래와 같은 결과가 나오는데,\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026#34;testEnv.yml\u0026#34; 36L, 673C 1,1 Top name: testEnv channels: - conda-forge - anaconda - defaults dependencies: - ca-certificates=2020.10.14 - certifi=2020.6.20 - joblib=1.1.0 - libblas=3.9.0 - libcblas=3.9.0 - libcxx=12.0.0 - libffi=3.3 - libgfortran=5.0.0 - libgfortran5=9.3.0 - liblapack=3.9.0     화살표 키를 움직여 삭제해야 하는 줄까지 이동한 다음 dd를 입력하면 해당 줄이 삭제됩니다. 그 후 esc, :wq, ENTER를 차례로 눌러 저장합니다.\n이 방법으로 문제가 해결될 수도 있고 아닐 수도 있습니다. 이 튜토리얼에서는 문제가 해결되지 않습니다.\nconda 패키지 목록에서 libgfortran을 검색하고 platform 옵션을 linux-64로 설정하면, 버전이 3.0.0까지 밖에 없는 것을 알 수 있습니다. 반면 osx-64(MacOS)는 5.0.0 버전이 존재합니다. 이 때문에 MacOS에서 만든 virtual environment가 linux OS를 사용하는 cpu-compute 노드에서 재현될 수 없었던 것입니다.\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/conda_env_export_yml/","summary":"yml 파일 이용해 local과 동일한 conda 환경 구축하기 conda env export 커맨드를 이용해 environment 전체를 .yml 파일로 만들고 이를 이용해 cpu-compute 노드에서 environment를 구축하는 것이 가장 이상적인 방법입니다. 하지만 이 방법은 user의 local 컴퓨터가 linux가 아니면(특히 Windows일 경우) 자잘한 오류가 발생합니다[^fn2]. 차선책으로 설치된 패키지 목록과 버전만을 requirements.txt로 추출하여 노드에서 cpu-compute에서 설치할 수 있습니다.\n  User의 local 컴퓨터에서에서 아래의 커맨드를 통해 virtual environment로부터 환경설정 파일을 추출합니다. —no-builds는 서로 다른 OS에서 conda environment 내 패키지들의 버전 충돌을 방지하기 위한 옵션입니다.","title":"How to Use GPU Node for SLURM"},{"content":"How to use CPU node for SLURM Step 1 - terminal 앱 고르기 User는 SSH로 proxy node에 접속하여 클러스터를 사용합니다. 터미널 환경과 vi 에디터에 익숙한 user는 자신에게 친숙한 앱을 사용하면 됩니다. 그렇지 않은 경우, Visual Studio Code를 사용하는 것을 추천하며, 이 튜토리얼에서는 Visual Studio Code를 사용하는 것을 전제로 합니다. 추천 이유는 다음과 같습니다.\n Windows, MacOS, Linux에서 모두 사용 가능합니다. Web Version도 있기 때문에 모바일 디바이스에서도 사용할 수 있습니다. 또한 터미널과 에디터, 파일 브라우저가 통합되어 있기 때문에 불편하게 vi나 nano등의 CUI 기반 텍스트 에디터를 사용할 필요가 없으며, 파일 전송도 scp등의 복잡한 프로토콜을 사용할 필요 없이 drag \u0026amp; drop으로 수행할 수 있습니다.  터미널에서 ssh 접속만 할 수 있다면 어떤 기기에서도 proxy node에 접속하여 작업을 제출할 수 있으며, 터미널이 종료되어도 작업은 계속 실행됩니다. Standard output(Python, R에서 console에 출력되는 메시지)가 로그 파일에 기록되므로, 나중에 다시 터미널에 접속하여 job 실행 현황을 확인할 수 있습니다.\nVisual Studio Code외에 다른 앱을 사용하실 경우 추천하는 앱은 다음과 같습니다.\n Windows 10: PowerShell보다는 Windows Terminal를 추천합니다. MacOS: 기본 터미널을 사용해도 되지만, iTerm2를 추천합니다. iOS: Blink Android: Termux  Step 2 - proxy node SSH 접속 1. Visual Studio Code extensions에서 Remote Development 설치fn^3 Microsoft가 제공하는 Remote Development extension pack을 설치합니다. Remote-WSL, Remote-Containers, Remote-SSH가 자동적으로 같이 설치됩니다. 2. Remote Explorer에서 SSH Targets를 선택 후, Add New 클릭 3. ssh 접속 커맨드 입력 아래와 같은 창이 뜨면 ssh 커맨드를 입력하여 proxy node에 접속합니다. 아래 코드에 Slack으로 안내받은 ip, port, username을 넣어서 위 창에 입력하고 Enter키를 누르면 됩니다. SSH의 default port는 22이지만, 저희의 클러스터는 보안상 이유로 다른 port를 사용합니다.\n1  ssh -p [port] [username]@[ip]   4. SSH configuration file을 저장할 장소 선택 Select SSH configuration file to update가 나오면 맨 위 항목을 선택합니다. Host added! 라는 메시지가 우측 하단에 나옵니다. 5. Remote Explore에서 Connect to Host in New Window 선택 6. 서버 Platform 선택 Linux를 선택합니다. 7. Password 입력 안내받은 password를 입력하여 로그인합니다. 8. 파일 시스템 마운트 좌측 탭의 파일 모양 아이콘을 클릭하고 Open Folder 버튼을 클릭합니다. 기본적으로 user home directory 경로가 입력되어 있습니다. OK를 누릅니다. 9. 둘러보기   좌측 file explorer에서 파일을 관리합니다. Windows 탐색기나 MacOS Finder에서 drag\u0026amp;drop으로 파일을 옮길 수 있습니다. 클러스터 내부의 파일을 user의 local 컴퓨터로 가져오는 것도 drag\u0026amp;drop으로 가능합니다.\n  ctrl + shift + ~키를 누르면 터미널이 열립니다. 여기서 서버 사용에 필요한 커맨드를 입력합니다.\n  text editor에서 코드와 스크립트를 수정하고 이미지 파일 등을 열람합니다.\n  Step 3 - 파일 시스템 구조 이해 NAS(Network Attached Storage)에 각 user의 home directory가 있습니다. NAS는 모든 node에 마운트되어 있으며, 모든 node에서 user명과 group명 및 관련 설정이 동일합니다. User명은 컴퓨팅 클러스터 사용 신청시 제출하신 이메일 주소의 @ 앞 부분과 동일합니다.\nUser home directory의 prefix는 /mnt/nas/users/입니다. 예를 들어, dummyuser라는 user의 home directory의 경로는 /mnt/nas/users/dummyuser/입니다. 다른 user의 home directory를 열람할 수 없도록 권한설정이 되어 있습니다. 각 user는 데이터와 코드, 설정 파일 등을 자신의 home directory 내에 저장합니다.\n Linux에서 directory를 이동하는 명령어는 cd입니다. home directory를 나타내는 기호는 ~입니다. 현재 directory를 확인하는 명령어는 pwd입니다 파일 목록을 확인하는 명령어는 ls입니다.  따라서 user는 proxy node아래의 명령어를 통해 자신의 홈 directory로 이동해 그 안에 있는 파일 목록을 확인할 수 있습니다.\n1 2  cd ~ ls   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # with the tree command the home directory will typically look like this /mnt/nas/users/dummyuser/ ├── .bash_history ├── .bash_logout ├── .bashrc ├── .conda ├── .config ├── GettingStarted.md ├── .gnupg ├── .ipynb_checkpoints ├── .ipython ├── .jupyter ├── .local ├── logs ├── .npm ├── .profile ├── .python_history ├── some_script.sh ├── .ssh └── .viminfo   Step 3 - Data Transfer 파일을 옮길 때에는 크게 \u0026lsquo;SCP\u0026rsquo;와 \u0026lsquo;Git\u0026rsquo; 두 가지 방법이 있습니다.\n방법 1. scp scp는 SSH와 같은 port를 사용합니다. 아래 커맨드를 이용해 파일을 보내고 받을 수 있습니다. dummyuser를 본인의 user명으로 바꾸고 파일명, directory명을 적절히 바꾸면 됩니다.\nSending a local file(some_file.txt) to the remote home directory 1  scp -P [port] some_file.txt dummyuser@hpc.stat.yonsei.ac.kr:~/   Sending a local directory(some_files/) to the remote home directory 1 2  scp -P [port] -r some_files dummyuser@hpc.stat.yonsei.ac.kr:~/ # /mnt/nas/users/dummyuser/some_files/ will be created   Recieving a remote file(some_file.txt) in the home directory to the current local directory 1  scp -P [port] dummyuser@hpc.stat.yonsei.ac.kr:~/some_file.txt   Recieving a remote directory(/mnt/nas/users/dummyuser/some_files) in the home directory to the current local directory 1  scp -P [port] -r dummyuser@hpc.stat.yonsei.ac.kr:~/some_files ./   이 외의 scp 옵션들은 여기서 확인할 수 있습니다.\n윈도우에서는 winscp 를 이용해 scp를 drag \u0026amp; drop으로 편리하게 이용할 수 있습니다.\nMacOS에서는 filezilla를 사용할 수 있습니다. 이에 대한 안내는 별도의 글로 작성되어 있습니다.\n방법 2. Git Git이 이미 설치되어 있으므로, 클러스터 내 적절한 directory에서 git clone을 사용합니다.\nStep 4. Conda environment 생성  cpu-compute node에는 conda version 4.11.0이 설치되어 있으며 Python version을 3.10까지 지원합니다fn^1. gpu-compute node에는 conda version 4.6.14가 설치되어 있으며 Python version을 3.8까지 지원합니다.  여기서는 cpu-compute node에서 conda environment를 생성하는 방법을 설명합니다. local에서 작성한 코드가 cpu-compute node에서 오류 없이 작동하도록 하기 위해, local과 cpu-compute node에서 동일한 conda environment를 구축해야 합니다.\n1. local에서 conda environment 생성 이 섹션의 작업은 모두 user의 local 컴퓨터에서 진행합니다.\nminiconda를 설치한 다음, local 컴퓨터의 터미널에서 아래 커맨드로 virtual environment를 설정합니다. testEnv 자리에 원하는 이름을 넣고, python= 뒤에 사용할 Python version을 명시합니다.\n1  conda create -n testEnv python=3.6   성공적으로 생성되면 아래와 같은 결과가 나옵니다.\n1 2 3 4 5 6 7 8 9 10 11  Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate testEnv # # To deactivate an active environment, use # # $ conda deactivate   아래 커맨드를 통해 virtual environment가 제대로 생성되었는지 확인합니다.\n1  conda info --env   1 2 3 4  # conda environments: # base * /opt/miniconda3 testEnv /opt/miniconda3/envs/testEnv   Virtual environment에 진입한 뒤 패키지를 설치합니다. pip로 설치되는 패키지들은 conda로 설치된 패키지에 대한 정보를 모르기 때문에 의존성 충돌이 발생할 수 있으므로 conda만을 사용해서 설치하실 것을 권장합니다. anaconda 웹사이트에서 패키지명을 검색해서 linux-64를 지원하는 버전이 어디까지인지를 확인하고 설치하는 것을 추천합니다. 위 사이트는 설치 커맨드도 제공합니다. 여러 패키지를 설치할 경우 한 커맨드 내에 명시하면 conda가 자동으로 dependency 충돌을 검사해 줍니다.\n1 2 3 4  conda activate testEnv #For example, conda install -c conda-forge lightgbm==2.0.7 scikit-learn matplotlib keras   또는 user가 사용할 중요한 패키지들이 있을 경우 environment를 생성할 때 사용할 패키지 목록을 지정할 수도 있습니다. 아래 커맨드로 설치된 패키지 목록을 확인합니다.\n1  conda list   Environment를 지우려면 아래 커맨드를 입력합니다.\n1  conda remove --name testEnv --all   2. cpu-compute node에 local과 동일한 conda environment 구축하기 conda env export 커맨드를 이용해 environment 전체를 .yml 파일로 만들고 이를 이용해 cpu-compute 노드에서 environment를 구축하는 것이 동일한 environment를 만드는 가장 이상적인 방법입니다. 또는 설치된 패키지 목록과 버전만을 requirements.txt로 추출하여 노드에서 cpu-compute에서 설치할 수 있습니다. 그러나 이 두 방법은 user의 local 컴퓨터가 linux가 아니면 오류가 발생할 확률이 매우 높습니다. 이는 유저가 패키지를 설치할 때 자동으로 설치되는 dependency들의 버전이 OS별로 다를 수 있기 때문입니다. 예를 들어 lightgbm 2.0.7버전은 Python 버전이 3.6일 때 linux와 MacOS에서 둘 다 설치 가능하지만, 이 패키지의 dependency 중 하나인 libgfortran은 MacOS에서는 4.0.0버전이 설치되지만 linux에서는 3.0.0버전까지만 지원되기 때문에 MacOS에서 만든 environment에서 추출한 yml 파일이나 list txt 파일을 클러스터에서 사용하면 오류가 발생합니다[^fn2]. 이 오류는 적절한 조치를 통해 해결할 수 있을 때도 있지만 해결하기 힘들 때도 있습니다.\n따라서 local에서 만든 environment를 cluster로 옮기기보다는, local의 environment에서 사용하는 Python 버전과 중요 패키지들의 버전을 그대로 사용하여 cluster 내에서 environment를 생성하는 것을 추천하며, 이 문서에서는 그 절차를 안내합니다.\n  Conda environment 생성 batch script를 작성합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #!/bin/bash #SBATCH --job-name=conda-env-create #SBATCH --nodes=1 #SBATCH --mem=4gb #SBATCH --partition=all #SBATCH --nodelist=cpu-compute #SBATCH --output=testEnv.out #SBATCH --error=testEnv.err CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnv #local에서와 같은 이름으로 입력 ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.6 source $CONDA_BIN_PATH/activate $ENV_PATH conda install -c conda-forge lightgbm==2.0.7 scikit-learn matplotlib keras pandas numpy   위 내용에서\n 7번 라인의 #SBATCH \u0026ndash;output=testEnv.out의 output log 파일명 8번 라인의 #SBATCH \u0026ndash;error=testEnv.err의 error log 파일명 10번 라인의 environment name 13번 라인의 python version 14번 라인의 패키지 설치 커맨드 를 알맞게 수정한 뒤 local에서 testEnv.sh로 저장하여 scp로 클러스터 내 user home directory로 전송합니다. 또는 proxy node에 접속한 뒤 home directory에서  1  vi testEnv.sh   를 입력하여 linux의 텍스트 에디터를 실행한 뒤 ctrl+v로 위 내용을 붙여넣기하고 esc, :wq, ENTER를 차례로 눌러 저장합니다.\n  작성한 스크립트 실행하기. proxy node에 SSH접속한 뒤 home directory에서\n1  sbatch testEnv.sh   를 입력해 slurm batch job submission을 수행합니다. 작업이 노드에서 성공적으로 실행되면\n1  Submitted batch job 401   와 같은 메시지가 뜨고 job 번호가 할당됩니다.\n1  squeue   커맨드를 통해 작업 실행 현황을 확인할 수 있습니다.\n1 2  JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 402 all conda-en mjm R 0:01 1 cpu-compute   또는 아래 커맨드를 통해 실시간으로 작업 실행 현황을 확인할 수 있습니다.\n1  smap -i 1   다음 커맨드를 통해 output log, error log파일의 내용을 확인할 수 있습니다.\n1  cat testEnv.err   error log 또는 output log는 다음 커맨드를 통해 실시간으로 확인할 수 있습니다.\n1  tail -f testEnv.out     Step 2. make env file and upload file to user’s workspace local에서 만들어진 env 파일을 서버로 옮길 때는 scp를 사용한다. 간단한 사용법은 아래와 같다.\n1 2 3 4 5 6 7  # scp 사용법 # File upload scp [FILEPATH] ghk@[IP address]:~/ # upload from local, ~/ means home directory # File download scp ghk@[IP address]:[FILEPATH] ./ # scp [server file path] [local save path] # directory 전체 다운, 업로드 할 때는 -r 옵션을 사용한다.   Windows 사용자라면 WinSCP 라는 이름의 프로그램을 사용하면 local과 서버 간 파일 전송을 보다 쉽게 처리할 수 있다.\n 💡 env file을 이용한 conda 환경 설정은 local과 서버 작업 환경을 동일하게 설정할 수 있는 신뢰할 수 있는 방법이다. 그러나 conda 환경 설정 과정이 너무 번거롭다면 requirements.txt를 만들어 패키지 버전만 관리해도 충돌을 방지할 수 있다.  1 2 3 4 5 6 7  conda install --force-reinstall -y -q -c conda-forge --file requirements.txt # --force-reinstall : Install the package even if it already exists. # -y : Yes, do not ask for confirmation. # -q : Quiet, do not display progress bar. # -c : Channels, additional channels to search for packages # conda-forge is recommended   Step 3. make SLRUM batch script and run code in server 앞선 단계에서 conda환경이 잘 만들어졌다면 해당 가상환경을 activate하여 코드를 돌리는 SLURM batch script를 작성할 수 있다. 사용자들의 이해를 돕기 위해 TensorFlow 공식 페이지에 게시된 초보자용 튜토리얼 코드를 SLURM을 통해 실행시키는 예제를 공유한다. 먼저, 튜토리얼 코드는 다음과 같다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # tensor.py import tensorflow as tf mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation=\u0026#39;relu\u0026#39;), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;) ]) model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;sparse_categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(x_train, y_train, epochs=5) model.evaluate(x_test, y_test, verbose=2)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  #!/bin/bash # #SBATCH --job-name=gpu-tensor-test #SBATCH --mem=4gb #SBATCH --nodelist=gpu-compute #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --gres=gpu:1 #SBATCH --time=00:20:00 #SBATCH --account=ghk #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/ghk/code/gputest.log CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=tensor ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME ## $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH ## $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8 tensorflow pandas numpy source $CONDA_BIN_PATH/activate $ENV_PATH ## pip uninstall keras ## pip install keras==2.6.0 python /mnt/nas/users/ghk/code/tensor.py    —job-name: 수행할 작업의 이름 —mem: memory limit —nodelist: 작업할 노드의 이름 —ntasks: 작업의 수 —cpus-per-task: 각 작업에서 사용할 cpu 코어의 수 —gres=gpu : 작업에서 사용할 gpu의 개수, gpu-compute 노드에는 총 2개의 gpu가 사용 가능하다. —time: 작업 제한시간 —account: 해당 작업을 수행하는 계정의 이름 —partition: group of nodes with specific characteristics —output: 코드 실행 결과 log  제시한 대로 python 파일과 batch script 파일이 잘 만들어졌다면 sbatch 명령어를 입력하여 계산을 실행할 수 있다.\n1 2  sbatch tensor.sh smap -i 1 # 작업 현황을 1초마다 갱신하여 보여준다. ctrl+c로 escape 할 수 있다.   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ghk@proxy:~/code$ cat gputest.log 2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. 2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2) Epoch 1/5 1875/1875 [==============================] - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140 Epoch 2/5 1875/1875 [==============================] - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575 Epoch 3/5 1875/1875 [==============================] - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675 Epoch 4/5 1875/1875 [==============================] - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739 Epoch 5/5 1875/1875 [==============================] - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762 313/313 - 4s - loss: 0.0782 - accuracy: 0.9779 [0.078231580555439, 0.9779000282287598]   SLURM batch script를 사용자들이 보다 편하게 만들 수 있도록 SLURM Job Configurator 를 새롭게 작성하였다. 사용자들은 gpu 옵션을 체크하거나 해제하여 gpu-compute node 사용 여부를 결정할 수 있다. 해당되는 옵션을 체크하고 Print 버튼을 누르면 손쉽게 batch script를 작성할 수 있다.\n더 알아보기 Submitting a slurm job script\nSLRUM Job Examples\nTensorFlow on the HPC Clusters\nRefernece ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/how-to-use-cpu-node/","summary":"How to use CPU node for SLURM Step 1 - terminal 앱 고르기 User는 SSH로 proxy node에 접속하여 클러스터를 사용합니다. 터미널 환경과 vi 에디터에 익숙한 user는 자신에게 친숙한 앱을 사용하면 됩니다. 그렇지 않은 경우, Visual Studio Code를 사용하는 것을 추천하며, 이 튜토리얼에서는 Visual Studio Code를 사용하는 것을 전제로 합니다. 추천 이유는 다음과 같습니다.\n Windows, MacOS, Linux에서 모두 사용 가능합니다. Web Version도 있기 때문에 모바일 디바이스에서도 사용할 수 있습니다. 또한 터미널과 에디터, 파일 브라우저가 통합되어 있기 때문에 불편하게 vi나 nano등의 CUI 기반 텍스트 에디터를 사용할 필요가 없으며, 파일 전송도 scp등의 복잡한 프로토콜을 사용할 필요 없이 drag \u0026amp; drop으로 수행할 수 있습니다.","title":"How to Use GPU Node for SLURM"},{"content":"How to use GPU node for SLURM Step 1. Export your conda setting conda 환경을 동일하게 맞춰주기 위해 local에서 생성된 가상환경으로부터 환경설정 파일을 만들고, 서버에서 conda 가상환경을 만들 때 사용한다.\n1 2 3 4 5 6 7 8 9 10 11  # export conda setting conda activate [YOUR ENV NAME] conda env export -n [ENV NAME] -f [FILENAME].yml --no-builds # 이러면 조금은 해결되긴 함 # create environment from file conda create --name [YOUR ENV NAME] python = [VESTION] # same env name in yml file conda env create -f [FILENAME].yml conda env create -p [prefix path] -f [filename].yml   —no-builds 옵션은 서로 다른 OS에서 conda 가상환경 파일 내 패키지들의 버전 충돌을 방지하기 위한 것이다. 다만 경우에 따라 완전히 문제를 예방하지는 못하기 때문에 사용자들이 직접 env 파일을 수정하는 상황이 발생할 수 있다. 이런 경우 ResolvePackageNotFound 아래의 패키지들을 env 파일에서 삭제해주면 문제가 해결된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  conda env create -f test.yml Collecting package metadata: done Solving environment: failed # yml 파일에서 아래에 등장하는 패키지들을 지워주면 된다. ResolvePackageNotFound: - libgfortran==3.0.1=h93005f0_2 # --no-builds는 패키지 버전 옆의 빌드 정보를 제거한다. - pyzmq==17.0.0=py36h1de35cc_1 - python==3.6.6=h4a56312_1003 - prompt_toolkit==1.0.15=py36haeda067_0 - libiconv==1.15=h1de35cc_1004 - sqlite==3.25.3=ha441bb4_0 - six==1.11.0=py36h0e22d5e_1 - cryptography==2.3.1=py36hdbc3d79_1000 - openssl==1.0.2p=h1de35cc_1002 - libxml2==2.9.8=hf14e9c8_1005 - libcxxabi==4.0.1=hebd6815_0 - matplotlib==2.2.3=py36h0e0179f_0 - ptyprocess==0.5.2=py36he6521c3_0   Step 2. make env file and upload file to user’s workspace 로컬에서 만들어진 env 파일을 서버로 옮길 때는 scp를 사용한다. 간단한 사용법은 아래와 같다.\n1 2 3 4 5 6 7  # scp 사용법 # File upload scp [FILEPATH] ghk@[IP address]:~/ # upload from local, ~/ means home directory # File download scp ghk@[IP address]:[FILEPATH] ./ # scp [server file path] [local save path] # directory 전체 다운, 업로드 할 때는 -r 옵션을 사용한다.   Windows 사용자라면 WinSCP 라는 이름의 프로그램을 사용하면 로컬과 서버 간 파일 전송을 보다 쉽게 처리할 수 있다.\n 💡 env file을 이용한 conda 환경 설정은 로컬과 서버 작업 환경을 동일하게 설정할 수 있는 신뢰할 수 있는 방법이다. 그러나 conda 환경 설정 과정이 너무 번거롭다면 requirements.txt를 만들어 패키지 버전만 관리해도 충돌을 방지할 수 있다.  1 2 3 4 5 6 7  conda install --force-reinstall -y -q -c conda-forge --file requirements.txt # --force-reinstall : Install the package even if it already exists. # -y : Yes, do not ask for confirmation. # -q : Quiet, do not display progress bar. # -c : Channels, additional channels to search for packages # conda-forge is recommended   Step 3. make SLRUM batch script and run code in server 앞선 단계에서 conda환경이 잘 만들어졌다면 해당 가상환경을 activate하여 코드를 돌리는 SLURM batch script를 작성할 수 있다. 사용자들의 이해를 돕기 위해 TensorFlow 공식 페이지에 게시된 초보자용 튜토리얼 코드를 SLURM을 통해 실행시키는 예제를 공유한다. 먼저, 튜토리얼 코드는 다음과 같다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # tensor.py import tensorflow as tf mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation=\u0026#39;relu\u0026#39;), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;) ]) model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;sparse_categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(x_train, y_train, epochs=5) model.evaluate(x_test, y_test, verbose=2)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  #!/bin/bash # #SBATCH --job-name=gpu-tensor-test #SBATCH --mem=4gb #SBATCH --nodelist=gpu-compute #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --gres=gpu:1 #SBATCH --time=00:20:00 #SBATCH --account=ghk #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/ghk/code/gputest.log CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=tensor ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME ## $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH ## $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8 tensorflow pandas numpy source $CONDA_BIN_PATH/activate $ENV_PATH ## pip uninstall keras ## pip install keras==2.6.0 python /mnt/nas/users/ghk/code/tensor.py    —job-name: 수행할 작업의 이름 —mem: memory limit —nodelist: 작업할 노드의 이름 —ntasks: 작업의 수 —cpus-per-task: 각 작업에서 사용할 cpu 코어의 수 —gres=gpu : 작업에서 사용할 gpu의 개수, gpu-compute 노드에는 총 2개의 gpu가 사용 가능하다. —time: 작업 제한시간 —account: 해당 작업을 수행하는 계정의 이름 —partition: group of nodes with specific characteristics —output: 코드 실행 결과 log  제시한 대로 python 파일과 batch script 파일이 잘 만들어졌다면 sbatch 명령어를 입력하여 계산을 실행할 수 있다.\n1 2  sbatch tensor.sh smap -i 1 # 작업 현황을 1초마다 갱신하여 보여준다. ctrl+c로 escape 할 수 있다.   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ghk@proxy:~/code$ cat gputest.log 2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. 2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2) Epoch 1/5 1875/1875 [==============================] - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140 Epoch 2/5 1875/1875 [==============================] - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575 Epoch 3/5 1875/1875 [==============================] - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675 Epoch 4/5 1875/1875 [==============================] - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739 Epoch 5/5 1875/1875 [==============================] - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762 313/313 - 4s - loss: 0.0782 - accuracy: 0.9779 [0.078231580555439, 0.9779000282287598]   SLURM batch script를 사용자들이 보다 편하게 만들 수 있도록 SLURM Job Configurator 를 새롭게 작성하였다. 사용자들은 gpu 옵션을 체크하거나 해제하여 gpu-compute node 사용 여부를 결정할 수 있다. 해당되는 옵션을 체크하고 Print 버튼을 누르면 손쉽게 batch script를 작성할 수 있다.\n더 알아보기 Submitting a slurm job script\nSLRUM Job Examples\nTensorFlow on the HPC Clusters\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/how-to-use-gpu-node-for-slurm/","summary":"How to use GPU node for SLURM Step 1. Export your conda setting conda 환경을 동일하게 맞춰주기 위해 local에서 생성된 가상환경으로부터 환경설정 파일을 만들고, 서버에서 conda 가상환경을 만들 때 사용한다.\n1 2 3 4 5 6 7 8 9 10 11  # export conda setting conda activate [YOUR ENV NAME] conda env export -n [ENV NAME] -f [FILENAME].yml --no-builds # 이러면 조금은 해결되긴 함 # create environment from file conda create --name [YOUR ENV NAME] python = [VESTION] # same env name in yml file conda env create -f [FILENAME].","title":"How to Use GPU Node for SLURM"},{"content":"요약 Chili Pepper는\n 총 세 개의 컴퓨터로 구성된 컴퓨팅 클러스터입니다. Cpu node 하나와 gpu node 하나, 그리고 이 둘을 관리하는 proxy node로 구성되어 있습니다. Slurm이라는 job scheduler로 여러 사용자의 작업을 각 node에 효율적으로 할당합니다. 각 사용자는 자신만의 conda environment를 스스로 생성하여 사용합니다. 기본적으로 non-interactive입니다.사용자가 자신의 로컬 컴퓨터에서 작성 및 테스트한 코드를 서버에 제출하면 서버가 해당 코드를 실행합니다. 주피터 노트북 환경은 실행 가능하지만, 꼭 필요한 경우에 한하여 요청 시 제공합니다. 이는 노트북 환경은 작업 단위가 아닌 시간 단위로 실행되기 때문에 서버의 RAM 자원을 지나치게 많이 점유하고 다른 작업의 실행을 방해하기 때문입니다. 파일은 위 세 컴퓨터와 별개의 NAS(Network Attached Storage)에 저장되며, 모든 컴퓨터에 마운트되어 있으므로 한번 클러스터 내로 옮긴 파일은 클러스터 내부에서 다시 옮길 필요가 없습니다.  1. 클러스터 구성 1. cpu node  Name: cpu-compute CPU: Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz 32 cores RAM: 128GB OS: ubuntu 18.04.6 LTS conda version: 4.11.0  2. gpu-compute node  Name: gpu-compute CPU: Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz 16 cores GPU: NVIDIA® Tesla® T4 16GB x 2 RAM: 80GB OS: ubuntu 18.04.6 LTS conda version: 4.6.14 GPU driver version: 418.67  3. proxy node  Name: proxy CPU: Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz 2cores RAM: 4GB OS: ubuntu 18.04.6 LTS  특이사항   Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz가 18코어 제품임에도 불구하고 세 컴퓨터에 각각 32코어, 16코어, 2코어로 장착되어 있는 것은 이 세 컴퓨터가 네이버 클라우드 플랫폼에서 호스팅되고 있기 때문입니다. 네이버 클라우드 플랫폼에서 각 컴퓨터에 정해진 코어 수를 할당합니다.\n  proxy node는 사용자가 로그인하여 job을 제출하기 위한 용도로만 쓰이는 컴퓨터이므로 성능이 낮습니다.\n  사용자는 proxy에만 접속할 수 있으며, cpu-compute와 gpu-compute에는 접속할 수 없습니다.\n  2. Slurm job scheduler Job scheduler HPC(High performance computing) 시스템은 개인용 컴퓨터와 달리 여러 사용자가 여러 node를 공유하며 사용합니다. 따라서 누구의 작업이 언제 어느 node에서 실행될지 결정해 주어야 합니다. 이러한 역할을 수행하는 것이 job scheduler입니다.\nJob scheduler를 식당의 웨이터에 비유할 수 있습니다. 식당에 사람이 많으면 줄을 서서 기다려야 합니다. 웨이터는 각 손님 그룹의 수에 맞는 자리가 나면 그 그룹을 테이블로 안내합니다1. 용어   Job: 사용자가 클러스터에서 실행하고자 하는 코드(bash, python, R 등을 모두 포함)\n  Batch job submission: 사용자가 미리 작성한 코드(output을 파일로 저장하는 내용 포함)를 scheduler에게 제출하여 non-interactive하게 실행하는 것\n  Slurm Slurm(Simple Linux Utility for Resource Management)은 HPC에서 많이 채용하는 job scheduler입니다. 전 세계 TOP 500 슈퍼컴퓨터 중 60%가 slurm을 사용합니다2.\nSlurm은 각 사용자의 cpu사용량 등 다양한 통계를 기반으로 작업의 우선순위를 결정할 수 있습니다. 예를 들어, University of Toronto의 Computer Science Department의 HPC는 사용 CPU 코어 수 * 사용 시간(초) 값이 낮은 사용자의 job을 먼저 실행합니다. RAM 사용량은 0.25GB당 CPU 1코어 사용으로, GPU 사용량은 GPU 1개당 CPU 16코어 사용으로 환산합니다3.\n현재 Chili Pepper는 위와 같은 점수제가 아닌 FIFO(First In, First Out) 규칙을 사용하고 있습니다. 일정 기간 운영해본 뒤 상황에 맞추어 규칙을 변경할 예정입니다.\n3. Conda environment Virtual environment Virtual environment를 사용하면 한 컴퓨터 내에서 각 user가 독립적으로 Python과 R 패키지를 관리할 수 있습니다. 또한, 여러 컴퓨터에서 동일한 환경을 구축하여 패키지 버전 차이로 인한 문제 발생을 방지할 수 있습니다4. 이는 특히 GPU driver, CUDA, cuDNN, 딥러닝 라이브러리의 버전 간 호환성이 중요한 딥러닝 job에서 유용합니다.\n여러 사용자가 node를 공유하는 HPC에서 virtual environment의 사용은 필수적입니다. 각 사용자는 자신의 로컬 컴퓨터와 동일한 Python 및 R 환경을 node 내에 구축합니다. 그리고 로컬 컴퓨터에서 코드를 작성하고 이상 없이 실행되는지 테스트합니다. 문제 없이 실행되는 것이 확인된 코드를 slurm을 통해 클러스터에서 실행합니다. Virtual environment는 로컬에서 작성한 코드가 클러스터에서 문제 없이 작동하는 것을 보장합니다.\nConda environment Chili Pepper는 conda를 이용해 virtual environment를 구현합니다. Conda는 Python, R, Ruby, Lua, Scalca, Java, Javascript, C/C++, FORTRAN 등 다양한 언어를 지원할 뿐만 아니라 Windows, MacOS, Linux를 모두 지원합니다5.\nChili Pepper에서 job을 실행하기 위해서는 반드시 conda environment를 사용해야 합니다.\n  https://epcced.github.io/hpc-intro/13-scheduler/index.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://wiki.hpc.odu.edu/en/slurm\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://support.cs.toronto.edu/systems/slurmresource.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.marquette.edu/high-performance-computing/py-venv.php\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://docs.conda.io/en/latest/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/intro/","summary":"요약 Chili Pepper는\n 총 세 개의 컴퓨터로 구성된 컴퓨팅 클러스터입니다. Cpu node 하나와 gpu node 하나, 그리고 이 둘을 관리하는 proxy node로 구성되어 있습니다. Slurm이라는 job scheduler로 여러 사용자의 작업을 각 node에 효율적으로 할당합니다. 각 사용자는 자신만의 conda environment를 스스로 생성하여 사용합니다. 기본적으로 non-interactive입니다.사용자가 자신의 로컬 컴퓨터에서 작성 및 테스트한 코드를 서버에 제출하면 서버가 해당 코드를 실행합니다. 주피터 노트북 환경은 실행 가능하지만, 꼭 필요한 경우에 한하여 요청 시 제공합니다. 이는 노트북 환경은 작업 단위가 아닌 시간 단위로 실행되기 때문에 서버의 RAM 자원을 지나치게 많이 점유하고 다른 작업의 실행을 방해하기 때문입니다.","title":"Intro"},{"content":"1. What is SLURM? Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for its operation and is relatively self-contained.\nIf you need more information, Please Visit https://slurm.schedmd.com/overview.html\n2. Basic SLURM Command   sbatch\n Submit a batch script to SLURM  1 2 3 4  $ sbatch [YOUR_SCRIPT] # output \u0026gt; Submitted batch job 210 # job_id: 210     squeue\n View the queue  1 2 3 4 5  $ squeue # output \u0026gt; JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 210 all test1 ghk R 0:29 1 cpu-compute     scancel\n Cancel a SLURM job  1  $ scancel [YOUR_JOBID]     sinfo\n See the state of system  1 2 3 4 5  $ sinfo # output \u0026gt; PARTITION AVAIL TIMELIMIT NODES STATE NODELIST all* up infinite 2 idle cpu-compute,gpu-compute     smap\n graphically view information about SLURM job    For more information about SLURM command, please visit website below.\n  SLURM Workload Manager\n  SLURM Command Cheatsheet\n  SLURM Reference Sheet(NeSI)\n  Submit your first job(NeSI)\n  3. How to make SLURM batch script? \u0026lsquo;Job submission file\u0026rsquo; is the official SLURM name for the file you use to submit your program and ask for resources from the job scheduler. In this document, we will be using it ‘batch script’ or ‘script’.\nBasic example 1 2 3 4 5 6 7  #!/bin/bash #  # SBATCH --job-name=basic # SBATCH --mem=1gb # SBATCH --ntasks=1 # SBATCH --time=01:00 # SBATCH --output=/mnt/nas/users/testuser/basic.log   Asking 1 tasks, running for no more than 1 minutes limit memory less than 1gb. If any problem with your job, log file(in this case, \u0026lsquo;basic.log\u0026rsquo;) have information to help troubleshoot the issue.\nYou can also use gpu-nodes by using \u0026lsquo;—gres\u0026rsquo; option. Here is an example.\n1 2 3 4 5 6 7 8 9 10 11  #!/bin/bash #  #SBATCH --job-name=basic #SBATCH --nodes=1 #SBATCH --gres=gpu:2 # max : 2 #SBATCH --time=01:00 #SBATCH --account=testuser #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/testuser/torch.log source activate /opt/miniconda/envs/pytorch \u0026amp;\u0026amp; python /mnt/nas/users/testuser/main.py   1 2 3 4 5 6 7 8 9 10  # main.py import torch print(\u0026#39;is cuda avaiable? \u0026#39;, torch.cuda.is_available()) print(\u0026#39;how many cuda devices? \u0026#39;,torch.cuda.device_count()) print(\u0026#39;get first cuda device name =\u0026gt; \u0026#39;, torch.cuda.get_device_name(0)) print(\u0026#39;*** MEMORY INFO ***\u0026#39;) t = torch.cuda.get_device_properties(0).total_memory print(\u0026#39;total memory =\u0026gt; \u0026#39;, t) print(\u0026#39;total memory: \u0026#39;, t)   The job can then be submitted through sbatch\n1 2 3 4 5 6 7  $ sbatch basic.sh $ cat torch.log \u0026gt; is cuda avaiable? True \u0026gt; how many cuda devices? 2 \u0026gt; get first cuda device name =\u0026gt; Tesla T4 \u0026gt; ***MEMORY INFO*** \u0026gt; total memory =\u0026gt; 16879583232   Beacuse we only have 2 gpu machine, this option can’t be set more than 2\nFor the convenience of users, we provide SLURM job configurator page in our website. Please visit SLURM job configurator and make your own SLURM batch script!\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/slurm-documentation/","summary":"1. What is SLURM? Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for its operation and is relatively self-contained.\nIf you need more information, Please Visit https://slurm.schedmd.com/overview.html\n2. Basic SLURM Command   sbatch\n Submit a batch script to SLURM  1 2 3 4  $ sbatch [YOUR_SCRIPT] # output \u0026gt; Submitted batch job 210 # job_id: 210     squeue","title":"SLURM Documentation"},{"content":"Intro This documentation will go over the basics of using the Chili Pepper cluster. Please go through this documentation step-by-step. Contact the server administrator via email or use the Q\u0026amp;A channel in the Slack Group.\nStep 1 - Understanding the Cluster Structure Chili Pepper cluster has a NAS which contains user home directories and other shared files. All users and groups are consistent across all nodes. The prefix for the user directory is /mnt/nas/users/. For example, the home directory for the user dummyuser will be /mnt/nas/users/dummyuser/. The home directory is the recommended directory for users to store scripts, data and configuration files for using the Chili Pepper cluster.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # with the tree command the home directory will typically look like this /mnt/nas/users/dummyuser/ ├── .bash_history ├── .bash_logout ├── .bashrc ├── .conda ├── .config ├── GettingStarted.md ├── .gnupg ├── .ipynb_checkpoints ├── .ipython ├── .jupyter ├── .local ├── logs ├── .npm ├── .profile ├── .python_history ├── some_script.sh ├── .ssh └── .viminfo   Step 2 - Data Transfer With cluster access information(SSH) provided by the administrator, you can send and recieve files from and to the cluster with scp. The dummyuser can send various local files to the cluster in the following fashion. Note that for security purposes the default port for SSH is not 22. The administrator will inform you of this information upon providing access information to the cluster.\nSending a local file(some_file.txt) to the remote home directory 1  scp some_file.txt dummyuser@hpc.stat.yonsei.ac.kr:~/   Sending a local directory(some_files/) to the remote home directory 1 2  scp -r some_files dummyuser@hpc.stat.yonsei.ac.kr:~/ # /mnt/nas/users/dummyuser/some_files/ will be created   Recieving a remote file(some_file.txt) in the home directory to the current local directory 1  scp dummyuser@hpc.stat.yonsei.ac.kr:~/some_file.txt   Recieving a remote directory(/mnt/nas/users/dummyuser/some_files) in the home directory to the current local directory 1  scp -r dummyuser@hpc.stat.yonsei.ac.kr:~/some_files ./   Other various options for scp exist. More information on this topic can be found in this article. Also users can use GitHub or GitLab to upload and download source code to the cluster. This will be handled in a seperate article.\nStep 3 - Writing a SBATCH script for SLURM. From the homepage the SLURM batch scripting tool is available. Let\u0026rsquo;s look at the sample script(/mnt/nas/users/dummyuser/test_script.sh) created by using the tool. The first-half(line 1 ~ 11) of the script consists of directives and parameters for the slurm job. Each user can set the number of nodes, the time for the job to occupy the number of nodes, the location for the output logfile. There are more options available for submitting a job. Additional resources for SBATCH arguments can be found here.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/bin/bash # The interpreter used to execute the script #“#SBATCH” directives that convey submission options: #SBATCH --job-name=conda-env-create #SBATCH --nodes=1 #SBATCH --time=15:00 #SBATCH --account=dummyuser #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/dummyuser/conda.log # The application(s) to execute along with its input arguments and options: CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=myenv ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8 pandas numpy scikit-learn source $CONDA_BIN_PATH/activate $ENV_PATH \u0026amp;\u0026amp; pip freeze   From line 15 to the end of the script are actual bash commands for the node to execute.\n Line 15~16 creates two local variables(ENV_NAME and ENV_PATH). In the above script a conda environment named myenv will be created under /mnt/nas/users/dummyuser/.conda/envs/myenv. Line 18 will remove the environment in ENV_PATH if it is present. Line 19 will create a conda environment in ENV_PATH thanks to the -y(--yes) flag. This environment will have a Python interpreter of version 3.8 along with listed packages(pandas, numpy and scikit-learn). Line 20 will activate the conda environment in ENV_PATH and then sequentially run a pip freeze to the stdout. Note that the stdout is saved in the log file from line 11(/mnt/nas/users/dummyuser/conda.log).  To actually run a data science job, the only thing you have to do is to change the required packages for your environment, modify the pip freeze into python your_script_to_run.py.\nStep 4 - Submitting the script The submission of the script from the above is very simple.\n1  sbatch test_script.sh   You can check the current job queue with the following command.\n1  squeue   When you want to cancel the job you have submitted, get the JOBID from the squeue command and use the scancel command in the following fashion. Suppose the JOBID is 23.\n1  scancel 23   Note that ordinary users cannot cancel jobs that belong to other users, but the administrator can.\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/using-slurm-copy/","summary":"Intro This documentation will go over the basics of using the Chili Pepper cluster. Please go through this documentation step-by-step. Contact the server administrator via email or use the Q\u0026amp;A channel in the Slack Group.\nStep 1 - Understanding the Cluster Structure Chili Pepper cluster has a NAS which contains user home directories and other shared files. All users and groups are consistent across all nodes. The prefix for the user directory is /mnt/nas/users/.","title":"How do I use the Chili Pepper Cluster?"},{"content":"Creating a Python Kernel Admin Prerequisite Admin must enable conda for all users by creating a symlink. This will let users create their own virtual environment by using the conda create command.\n1  ln -s /opt/conda/bin/conda /usr/local/bin/conda   User Instructions Python  Users can launch a terminal session with either JupyterHub or SSH connections. Launch a bash session.  1  bash   Users then can create a virtual environment in the following way. Note that specifying ipykernel package will make the user easily create jupyter kernels from that environment. Also users can create virtual environments with various python versions(3.6 ~ 3.9). Activate the environment. If any warnings occur, read the warning and do the recommended procedure. Most of the time you will need to refresh your shell with bash.  1 2 3 4 5 6 7 8  # create environemnt conda create -n NAME_OF_VIRTUAL_ENV python=3.8 ipykernel # refresh your shell bash # activate environemnt conda activate NAME_OF_VIRTUAL_ENV   Install packages via pip.  1 2 3 4 5  # directly pip install PACKAGE_NAME # requirements.txt pip install -r YOUR_REQUIREMENTS.txt   Add the virtual environment as a kernel. This will be only available to each user.  1  python -m ipykernel install --user --name NAME_OF_VIRTUAL_ENV --display-name \u0026#34;[displayKenrelName]\u0026#34;   R  Launch a bash session via JupyterHub or SSH.  1  bash   Users then can create a virtual environment in the following way.  1 2 3 4 5 6 7 8  # create environemnt conda create -n NAME_OF_VIRTUAL_ENV r-essentials r-base r-irkernel # refresh your shell bash # activate environemnt conda activate NAME_OF_VIRTUAL_ENV   Install packages via install.packages().  1 2  # directly Rscript -e \u0026#39;install.packages(c(\u0026#34;dplyr\u0026#34;))\u0026#39;   Add the virtual environment as a kernel. This will be only available to each user.  1  Rscript -e \u0026#34;IRkernel::installspec(name=\u0026#39;myRkernel\u0026#39;, displayname=\u0026#39;My R Kernel\u0026#39;)\u0026#34;   Removing Kernels To remove kernels use the jupyter command in terminal.\nView your current kernel list with the following command from a bash terminal.\n1  jupyter kernelspec list   Remove kernel with the following command.\n1  jupyter kernelspec remove KERNELNAME   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/configuring-jupyter-kernel/","summary":"Creating a Python Kernel Admin Prerequisite Admin must enable conda for all users by creating a symlink. This will let users create their own virtual environment by using the conda create command.\n1  ln -s /opt/conda/bin/conda /usr/local/bin/conda   User Instructions Python  Users can launch a terminal session with either JupyterHub or SSH connections. Launch a bash session.  1  bash   Users then can create a virtual environment in the following way.","title":"Creating Your Custom Jupyter Kernel from a Virtual Environment"}]