[{"content":"How to use CPU node for SLURM Step 1 - terminal 앱 고르기 User는 SSH로 proxy node에 접속하여 클러스터를 사용합니다. 터미널 환경과 vi 에디터에 익숙한 user는 자신에게 친숙한 앱을 사용하면 됩니다. 그렇지 않은 경우, Visual Studio Code를 사용하는 것을 추천하며, 이 튜토리얼에서는 Visual Studio Code를 사용하는 것을 전제로 합니다. 추천 이유는 다음과 같습니다.\n Windows, MacOS, Linux에서 모두 사용 가능합니다. Web Version도 있기 때문에 모바일 디바이스에서도 사용할 수 있습니다. 또한 터미널과 에디터, 파일 브라우저가 통합되어 있기 때문에 불편하게 vi나 nano등의 CUI 기반 텍스트 에디터를 사용할 필요가 없으며, 파일 전송도 scp등의 복잡한 프로토콜을 사용할 필요 없이 drag \u0026amp; drop으로 수행할 수 있습니다.  proxy node  proxy node는 user가 로그인하여 파일을 정리하고 job을 cpu-compute와 gpu-compute node에 제출하는 용도로만 쓰이는 컴퓨터입니다. 터미널에서 ssh 접속만 할 수 있다면 어떤 기기에서도 proxy node에 접속하여 job을 제출할 수 있습니다. 일단 job을 제출하면, 터미널이 종료되고 user와 proxy node 간의 연결이 끊겨도 job은 계속 cpu-compute나 gpu-compute node에서 실행됩니다. Standard output(Python, R에서 console에 출력되는 메시지)이 로그 파일에 기록되므로, 나중에 다시 터미널에 접속하여 job 실행 현황을 확인할 수 있습니다.  Visual Studio Code외에 다른 앱을 사용하실 경우 추천하는 앱은 다음과 같습니다.\n Windows 10: PowerShell보다는 Windows Terminal를 추천합니다. MacOS: 기본 터미널을 사용해도 되지만, iTerm2를 추천합니다. iOS: Blink Android: Termux  Step 2 - proxy node SSH 접속 1. Visual Studio Code extensions에서 Remote Development 설치fn^3 Microsoft가 제공하는 Remote Development extension pack을 설치합니다. Remote-WSL, Remote-Containers, Remote-SSH가 자동적으로 같이 설치됩니다. 2. Remote Explorer에서 SSH Targets를 선택 후, Add New 클릭 3. ssh 접속 커맨드 입력 아래와 같은 창이 뜨면 ssh 커맨드를 입력하여 proxy node에 접속합니다. 아래 코드에 Slack으로 안내받은 ip, port, username을 넣어서 위 창에 입력하고 Enter키를 누르면 됩니다. SSH의 default port는 22이지만, 저희의 클러스터는 보안상 이유로 다른 port를 사용합니다.\n1  ssh -p [port] [username]@[ip]   4. SSH configuration file을 저장할 장소 선택 Select SSH configuration file to update가 나오면 맨 위 항목을 선택합니다. Host added! 라는 메시지가 우측 하단에 나옵니다. 5. Remote Explore에서 Connect to Host in New Window 선택 6. 서버 Platform 선택 Linux를 선택합니다. 7. Password 입력 안내받은 password를 입력하여 로그인합니다. 8. 파일 시스템 마운트 좌측 탭의 파일 모양 아이콘을 클릭하고 Open Folder 버튼을 클릭합니다. 기본적으로 user home directory 경로가 입력되어 있습니다. OK를 누릅니다. 9. 둘러보기   좌측 file explorer에서 파일을 관리합니다. Windows 탐색기나 MacOS Finder에서 drag\u0026amp;drop으로 파일을 옮길 수 있습니다. 클러스터 내부의 파일을 user의 local 컴퓨터로 가져오는 것도 drag\u0026amp;drop으로 가능합니다.\n  ctrl + shift + ~키를 누르면 터미널이 열립니다. 여기서 서버 사용에 필요한 커맨드를 입력합니다.\n  text editor에서 코드와 스크립트를 수정하고 이미지 파일 등을 열람합니다.\n  Step 3. 파일 시스템 구조 이해 NAS(Network Attached Storage)에 각 user의 home directory가 있습니다. NAS는 모든 node에 마운트되어 있으며, 모든 node에서 user명과 group명 및 관련 설정이 동일합니다. User명은 컴퓨팅 클러스터 사용 신청시 제출하신 이메일 주소의 @ 앞 부분과 동일합니다.\nUser home directory의 prefix는 /mnt/nas/users/입니다. 예를 들어, dummyuser라는 user의 home directory의 경로는 /mnt/nas/users/dummyuser/입니다. 다른 user의 home directory를 열람할 수 없도록 권한설정이 되어 있습니다. 각 user는 데이터와 코드, 설정 파일 등을 자신의 home directory 내에 저장합니다.\n Linux에서 directory를 이동하는 명령어는 cd입니다. home directory를 나타내는 기호는 ~입니다. 현재 directory를 확인하는 명령어는 pwd입니다 파일 목록을 확인하는 명령어는 ls입니다.  따라서 user는 proxy node아래의 명령어를 통해 자신의 홈 directory로 이동해 그 안에 있는 파일 목록을 확인할 수 있습니다.\n1 2  cd ~ ls   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # with the tree command the home directory will typically look like this /mnt/nas/users/dummyuser/ ├── .bash_history ├── .bash_logout ├── .bashrc ├── .conda ├── .config ├── GettingStarted.md ├── .gnupg ├── .ipynb_checkpoints ├── .ipython ├── .jupyter ├── .local ├── logs ├── .npm ├── .profile ├── .python_history ├── some_script.sh ├── .ssh └── .viminfo   ~~\nStep 4. Conda environment 생성  cpu-compute node에는 conda version 4.11.0이 설치되어 있으며 Python version을 3.10까지 지원합니다fn^1. gpu-compute node에는 conda version 4.6.14가 설치되어 있으며 Python version을 3.8까지 지원합니다.  여기서는 cpu-compute node에서 conda environment를 생성하는 방법을 설명합니다. local에서 작성한 코드가 cpu-compute node에서 오류 없이 작동하도록 하기 위해, local과 cpu-compute node에서 동일한 conda environment를 구축해야 합니다.\n1. local에서 conda environment 생성 이 섹션의 작업은 모두 클러스터가 아니라 user의 local 컴퓨터에서 진행합니다.\nminiconda를 설치한 다음, local 컴퓨터의 터미널에서 아래 커맨드로 virtual environment를 설정합니다. testEnv 자리에 원하는 이름을 넣고, python= 뒤에 사용할 Python version을 명시합니다.\n1  conda create -n testEnv python=3.6   성공적으로 생성되면 아래와 같은 결과가 나옵니다.\n1 2 3 4 5 6 7 8 9 10 11  Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate testEnv # # To deactivate an active environment, use # # $ conda deactivate   아래 커맨드를 통해 virtual environment가 제대로 생성되었는지 확인합니다.\n1  conda info --env   1 2 3 4  # conda environments: # base * /opt/miniconda3 testEnv /opt/miniconda3/envs/testEnv   Virtual environment에 진입한 뒤 패키지를 설치합니다.\n pip로 설치되는 패키지들은 conda로 설치된 패키지에 대한 정보를 모르기 때문에 의존성 충돌이 발생할 수 있으므로 conda만을 사용해서 설치하실 것을 권장합니다. anaconda 웹사이트에서 패키지명을 검색해서 linux-64를 지원하는 버전이 어디까지인지를 확인하고 설치하는 것을 추천합니다. 이 사이트는 설치 커맨드도 제공합니다. 여러 패키지를 설치할 경우 한 커맨드 내에 명시하면 conda가 자동으로 dependency 충돌을 검사해 줍니다. 패키지 버전을 명시할 때는 **==**를 사용합니다.  1 2 3 4  conda activate testEnv #For example, conda install -c conda-forge lightgbm==2.0.7 matplotlib scikit-learn pandas numpy   또는 user가 사용할 중요한 패키지들이 있을 경우 environment를 생성할 때 사용할 패키지 목록을 지정할 수도 있습니다. 아래 커맨드로 설치된 패키지 목록을 확인합니다.\n1  conda list   Environment를 지우려면 아래 커맨드를 입력합니다.\n1  conda remove --name testEnv --all   2. cpu-compute node에 local과 동일한 conda environment 구축하기  conda env export 커맨드를 이용해 environment 전체를 .yml 파일로 만들고 이를 이용해 cpu-compute 노드에서 environment를 구축하는 것이 동일한 environment를 만드는 가장 이상적인 방법입니다. 또는 설치된 패키지 목록과 버전만을 requirements.txt로 추출하여 노드에서 cpu-compute에서 설치할 수 있습니다. 그러나 이 두 방법은 user의 local 컴퓨터가 linux가 아니면 오류가 발생할 확률이 매우 높습니다. 이는 유저가 패키지를 설치할 때 자동으로 설치되는 dependency들의 버전이 OS별로 다를 수 있기 때문입니다.  예를 들어 lightgbm 2.0.7버전은 Python 버전이 3.6일 때 linux와 MacOS에서 둘 다 설치 가능하지만, 이 패키지의 dependency 중 하나인 libgfortran은 MacOS에서는 4.0.0버전이 설치되지만 linux에서는 3.0.0버전까지만 지원되기 때문에 MacOS에서 만든 environment에서 추출한 yml 파일이나 list txt 파일을 클러스터에서 사용하면 오류가 발생합니다[^fn2]. 이 오류는 적절한 조치를 통해 해결할 수 있을 때도 있지만 해결하기 힘들 때도 있습니다.    따라서 local에서 만든 environment를 cluster로 옮기기보다는, local의 environment에서 사용하는 Python 버전과 중요 패키지들의 버전을 그대로 사용하여 cluster 내에서 environment를 생성하는 것을 추천하며, 이 문서에서는 그 절차를 안내합니다.\n  Conda environment 생성 batch script를 작성합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #!/bin/bash #SBATCH --job-name=conda-env-create #SBATCH --nodes=1 #SBATCH --mem=4gb #SBATCH --partition=all #SBATCH --nodelist=cpu-compute #SBATCH --output=testEnv.log #SBATCH --error=testEnv.err CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnv #local에서와 같은 이름으로 입력 ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.6 source $CONDA_BIN_PATH/activate $ENV_PATH conda install -c conda-forge lightgbm==2.0.7 matplotlib scikit-learn pandas numpy   위 내용에서\n 7번 라인의 #SBATCH \u0026ndash;output=testEnv.out의 output log 파일명 8번 라인의 #SBATCH \u0026ndash;error=testEnv.err의 error log 파일명 10번 라인의 environment name 13번 라인의 python version 14번 라인의 패키지 설치 커맨드 를 알맞게 수정하여 Visual Studio Code에서 작성한 뒤,클러스터 내 user home directory에 testEnv.job으로 저장합니다.    작성한 스크립트 실행하기. Visual Studio Code 하단 터미널에\n1  sbatch testEnv.job   를 입력해 slurm batch job submission을 수행합니다. 작업이 노드에서 성공적으로 실행되면\n1  Submitted batch job 401   와 같은 메시지가 뜨고 job 번호가 할당됩니다.\n1  squeue   커맨드를 통해 작업 실행 현황을 확인할 수 있습니다.\n1 2  JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 402 all conda-en mjm R 0:01 1 cpu-compute   또는 아래 커맨드를 통해 실시간(1초 단위)으로 작업 실행 현황을 확인할 수 있습니다.\n1  smap -i 1 # ctrl+c로 escape 할 수 있습니다.   다음 커맨드를 통해 output log, error log파일의 내용을 확인할 수 있습니다.\n1  cat testEnv.err   error log 또는 output log는 다음 커맨드를 통해 실시간으로 확인할 수 있습니다.\n1  tail -f testEnv.log     Step 5. Slrum batch script 작성하여 서버에 제출하기 1. Python 코드 작성 이제 클러스터에서 실행할 Python 코드를 local에서 작성합니다. 머신 러닝 코드일 경우, Epoch 수를 작게 하는 등의 작업을 통해 빨리 실행되는 코드를 가지고 코드가 문제 없이 실행되는지 먼저 local에서 확인합니다. 그 후 실제로 실행할 코드를 작성하여 클러스터의 user home directory에 옮기거나, Visual Studio Code내에서 작성하여 저장합니다.\n아래는 tree 기반 boosting 알고리즘인 LightGBM으로 mnist dataset을 분류하는 코드입니다. Matplotlib으로 boost round에 대한 loss curve와 accuracy curve의 plot을 만들어 loss_curve.jpg라는 파일로 저장합니다fn^4. Batch script를 작성할 때는 알고리즘의 output이 자동으로 저장되지 않으므로 파일로 결과를 저장하는 코드를 꼭 포함해야 합니다. 아래 코드를 cpu_test_python.py로 저장하여 user home directory에 둡니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  import numpy as np from time import process_time import matplotlib.pyplot as plt from lightgbm import LGBMClassifier from sklearn.metrics import accuracy_score, log_loss from sklearn.datasets import fetch_openml from sklearn.model_selection import train_test_split def lgb(n=10, c=0, sequence=1): mnist = fetch_openml(\u0026#39;mnist_784\u0026#39;) x_train, x_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.33, random_state=42) proba_test = np.zeros((n, y_test.shape[0], len(np.unique(y_test)))) proba_train = np.zeros((n, y_train.shape[0], len(np.unique(y_train)))) test_score = [] train_score = [] tr_time = [] seq = [] while(n): model = LGBMClassifier(n_estimators=sequence) t0 = process_time() model.fit(x_train, y_train) tr_time.append(process_time() - t0) test_score.append(accuracy_score(y_test, model.predict(x_test))) train_score.append(accuracy_score(y_train, model.predict(x_train))) proba_test[c, ] = model.predict_proba(x_test) proba_train[c, ] = model.predict_proba(x_train) seq.append(sequence) sequence *= 2 n -= 1 c += 1 ce_train = [] ce_test = [] for i in range(10): ce_test.append(log_loss(y_test, proba_test[i])) ce_train.append(log_loss(y_train, proba_train[i])) np.savetxt(\u0026#39;round\u0026#39;+ str(i) + \u0026#39;proba_test.csv\u0026#39;, proba_test[i]) np.savetxt(\u0026#39;round\u0026#39;+ str(i) + \u0026#39;proba_train.csv\u0026#39;, proba_train[i]) np.savetxt(\u0026#39;test_score.csv\u0026#39;, test_score, delimiter=\u0026#39;,\u0026#39;) np.savetxt(\u0026#39;train_score.csv\u0026#39;, train_score, delimiter=\u0026#39;,\u0026#39;) np.savetxt(\u0026#39;ce_test.csv\u0026#39;, ce_test, delimiter=\u0026#39;,\u0026#39;) np.savetxt(\u0026#39;ce_train.csv\u0026#39;, ce_train, delimiter=\u0026#39;,\u0026#39;) fig, ax1 = plt.subplots() l1 = ax1.plot(seq, ce_test, \u0026#39;:\u0026#39;, label=\u0026#39;loss-test\u0026#39;, color=\u0026#39;r\u0026#39;) l2 = ax1.plot(seq, ce_train, \u0026#39;:\u0026#39;, label=\u0026#39;loss-train\u0026#39;, color=\u0026#39;b\u0026#39;) ax1.set_xlabel(\u0026#34;Boost rounds\u0026#34;) ax1.set_ylabel(\u0026#34;Cross Entropy\u0026#34;) ax2 = ax1.twinx() l3 = ax2.plot(seq, test_score, label=\u0026#39;accuracy-test\u0026#39;, color=\u0026#39;r\u0026#39;) l4 = ax2.plot(seq, train_score, label=\u0026#39;accuracy-train\u0026#39;, color=\u0026#39;b\u0026#39;) ax2.set_ylabel(\u0026#34;Accuracy\u0026#34;) lb = l1 + l2 + l3 + l4 label = [l.get_label() for l in lb] ax1.legend(lb, label, loc=0) plt.title(\u0026#39;loss curve/ accuracy\u0026#39;) plt.savefig(\u0026#39;loss_curve.jpg\u0026#39;, dpi=500) if __name__ == \u0026#39;__main__\u0026#39;: lgb()   2. 현재 클러스터 자원 사용량 확인 아래 커맨드를 통해 cpu-compute 노드의 cpu와 RAM 사용 현황을 볼 수 있습니다.\n1  sinfo -o \u0026#34;%n %e %m %a %c %C\u0026#34;   아래와 같은 결과가 나옵니다.\n1 2 3  HOSTNAMES FREE_MEM MEMORY AVAIL CPUS CPUS(A/I/O/T) cpu-compute 105589 128916 up 32 0/32/0/32 gpu-compute 53318 80532 up 16 0/16/0/16    CPUS의 A/I/O/T는 allocated/idle/other/total을 의미합니다. 자신의 job이 바로 실행되기를 원한다면, Slurm batch script를 작성할 때  RAM 용량을 FREE_MEM보다 적게 설정해야 합니다. CPU 코어 개수를 CPUS idle보다 적게 설정해야 합니다.   현재 가용 자원보다 더 많은 자원을 요구하는 script를 작성하면, job이 바로 실행되지 않습니다. 대기 상태에 있다가 다른 사용자들의 job이 끝나고 자원이 반환되면 job이 실행됩니다.  3. Slurm batch script 작성 앞선 단계에서 만든 해당 conda environment를 activate하고 코드를 실행하는 Slurm batch script를 작성합니다. 클러스터 소개 페이지의 slurm job configurator를 사용하면 script를 쉽게 작성할 수 있습니다.\n Conda activate에 체크합니다. 빈칸들을 채웁니다. Script란에 python xxx.py라고 작성합니다. 이는 home directory에 있는 xxx.py 파일을 Python으로 실행하라는 의미입니다. Print \u0026amp; Copy 버튼을 누르면 내용이 클립보드에 복사됩니다.  Slurm batch script의 내용은 아래와 같습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #!/bin/bash # #SBATCH --job-name=python_test_cpu #SBATCH --partition=all #SBATCH --account=mjm #SBATCH --mem=4gb #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --time=01:00:00 #SBATCH --output=/mnt/nas/users/mjm/python_test_cpu.log #SBATCH --error=/mnt/nas/users/mjm/python_test_cpu.err #SBATCH --nodelist=cpu-compute CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnv ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME source $CONDA_BIN_PATH/activate $ENV_PATH python python_test_cpu.py   python_test_cpu.job이라는 이름으로 클러스터의 user home directory에 저장합니다.\nScript 윗부분의 #SBATCH 옵션들의 의미는 다음과 같습니다.\n —job-name: 수행할 작업의 이름 —mem: memory limit —nodelist: 작업할 노드의 이름 —ntasks: 작업의 수 —cpus-per-task: 각 작업에서 사용할 cpu 코어의 수 —time: 작업 제한시간 —account: 해당 작업을 수행하는 계정의 이름 —partition: group of nodes with specific characteristics \u0026ndash;nodelist: 사용할 node의 이름 —output: 코드 실행 결과 log 파일. 확장자는 out이나 log가 가능합니다. —error: 코드 실행 결과 log  sbatch에 대한 더 자세한 정보는 Slurm 공식 웹페이지를 참조하세요.\n4. Slurm batch script 실행 Conda environment를 만들 때처럼, sbatch 커맨드를 통해 job을 제출합니다. 할당되는 job 번호는 나중에 job 정보를 확인하거나 job을 취소할 때 이용되므로 기록해 놓아야 합니다.\nsqueue나 smap -i로 작업 현황을 확인하고, cat xxx.log이나 tail -f xxx.err으로 콘솔 출력이나 error를 확인합니다.\n1 2 3 4  sbatch python_test_cpu.job smap -i 1 # 작업 현황을 1초마다 갱신하여 보여줍니다. ctrl+c로 escape 할 수 있습니다. cat python_test_cpu.log tail -f python_test_cpu.err   현재 작업이 자원을 얼마나 할당받았는지 확인하려면 다음 커맨드를 사용합니다. NumCPUs=4가 코어를 4개 할당받았다는 뜻이고, mem=4G가 RAM을 4gb 할당받았다는 뜻입니다.\n1  scontrol show job [job number]   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  UserId=mjm(1003) GroupId=mjm(1003) MCS_label=N/A Priority=4294901694 Nice=0 Account=mjm QOS=(null) JobState=RUNNING Reason=None Dependency=(null) Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:00:05 TimeLimit=01:00:00 TimeMin=N/A SubmitTime=2022-03-17T15:31:01 EligibleTime=2022-03-17T15:31:01 StartTime=2022-03-17T15:31:01 EndTime=2022-03-17T16:31:01 Deadline=N/A PreemptTime=None SuspendTime=None SecsPreSuspend=0 LastSchedEval=2022-03-17T15:31:01 Partition=all AllocNode:Sid=proxy:30897 ReqNodeList=cpu-compute ExcNodeList=(null) NodeList=cpu-compute BatchHost=cpu-compute NumNodes=1 NumCPUs=4 NumTasks=1 CPUs/Task=4 ReqB:S:C:T=0:0:*:* TRES=cpu=4,mem=4G,node=1,billing=4 Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=* MinCPUsNode=4 MinMemoryNode=4G MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 Gres=(null) Reservation=(null) OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) Command=/mnt/nas/users/mjm/python_test_cpu.job WorkDir=/mnt/nas/users/mjm StdErr=/mnt/nas/users/mjm/python_test_cpu.err StdIn=/dev/null StdOut=/mnt/nas/users/mjm/python_test_cpu.log Power=   작업이 완료되면 squeue Visual Stuio Code의 file explorer는 실시간으로 변화가 반영되지 않습니다. 새로고침 버튼을 눌러 주면 변화가 반영되고 output 파일이 explorer에 보입니다. 작업이 끝나기 전에 취소하려면 scance 커맨드를 사용합니다.\n1  scancel [job number]   더 알아보기 Submitting a slurm job script\nSLRUM Job Examples\nRefernece ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/how-to-use-cpu-node/","summary":"How to use CPU node for SLURM Step 1 - terminal 앱 고르기 User는 SSH로 proxy node에 접속하여 클러스터를 사용합니다. 터미널 환경과 vi 에디터에 익숙한 user는 자신에게 친숙한 앱을 사용하면 됩니다. 그렇지 않은 경우, Visual Studio Code를 사용하는 것을 추천하며, 이 튜토리얼에서는 Visual Studio Code를 사용하는 것을 전제로 합니다. 추천 이유는 다음과 같습니다.\n Windows, MacOS, Linux에서 모두 사용 가능합니다. Web Version도 있기 때문에 모바일 디바이스에서도 사용할 수 있습니다. 또한 터미널과 에디터, 파일 브라우저가 통합되어 있기 때문에 불편하게 vi나 nano등의 CUI 기반 텍스트 에디터를 사용할 필요가 없으며, 파일 전송도 scp등의 복잡한 프로토콜을 사용할 필요 없이 drag \u0026amp; drop으로 수행할 수 있습니다.","title":"CPU node 사용법(Python)"},{"content":"How to use GPU node for SLURM Step 1. Export your conda setting conda 환경을 동일하게 맞춰주기 위해 local에서 생성된 가상환경으로부터 환경설정 파일을 만들고, 서버에서 conda 가상환경을 만들 때 사용한다.\n1 2 3 4 5 6 7 8 9 10 11  # export conda setting conda activate [YOUR ENV NAME] conda env export -n [ENV NAME] -f [FILENAME].yml --no-builds # 이러면 조금은 해결되긴 함 # create environment from file conda create --name [YOUR ENV NAME] python = [VESTION] # same env name in yml file conda env create -f [FILENAME].yml conda env create -p [prefix path] -f [filename].yml   —no-builds 옵션은 서로 다른 OS에서 conda 가상환경 파일 내 패키지들의 버전 충돌을 방지하기 위한 것이다. 다만 경우에 따라 완전히 문제를 예방하지는 못하기 때문에 사용자들이 직접 env 파일을 수정하는 상황이 발생할 수 있다. 이런 경우 ResolvePackageNotFound 아래의 패키지들을 env 파일에서 삭제해주면 문제가 해결된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  conda env create -f test.yml Collecting package metadata: done Solving environment: failed # yml 파일에서 아래에 등장하는 패키지들을 지워주면 된다. ResolvePackageNotFound: - libgfortran==3.0.1=h93005f0_2 # --no-builds는 패키지 버전 옆의 빌드 정보를 제거한다. - pyzmq==17.0.0=py36h1de35cc_1 - python==3.6.6=h4a56312_1003 - prompt_toolkit==1.0.15=py36haeda067_0 - libiconv==1.15=h1de35cc_1004 - sqlite==3.25.3=ha441bb4_0 - six==1.11.0=py36h0e22d5e_1 - cryptography==2.3.1=py36hdbc3d79_1000 - openssl==1.0.2p=h1de35cc_1002 - libxml2==2.9.8=hf14e9c8_1005 - libcxxabi==4.0.1=hebd6815_0 - matplotlib==2.2.3=py36h0e0179f_0 - ptyprocess==0.5.2=py36he6521c3_0   Step 2. make env file and upload file to user’s workspace 로컬에서 만들어진 env 파일을 서버로 옮길 때는 scp를 사용한다. 간단한 사용법은 아래와 같다.\n1 2 3 4 5 6 7  # scp 사용법 # File upload scp [FILEPATH] ghk@[IP address]:~/ # upload from local, ~/ means home directory # File download scp ghk@[IP address]:[FILEPATH] ./ # scp [server file path] [local save path] # directory 전체 다운, 업로드 할 때는 -r 옵션을 사용한다.   Windows 사용자라면 WinSCP 라는 이름의 프로그램을 사용하면 로컬과 서버 간 파일 전송을 보다 쉽게 처리할 수 있다.\n 💡 env file을 이용한 conda 환경 설정은 로컬과 서버 작업 환경을 동일하게 설정할 수 있는 신뢰할 수 있는 방법이다. 그러나 conda 환경 설정 과정이 너무 번거롭다면 requirements.txt를 만들어 패키지 버전만 관리해도 충돌을 방지할 수 있다.  1 2 3 4 5 6 7  conda install --force-reinstall -y -q -c conda-forge --file requirements.txt # --force-reinstall : Install the package even if it already exists. # -y : Yes, do not ask for confirmation. # -q : Quiet, do not display progress bar. # -c : Channels, additional channels to search for packages # conda-forge is recommended   Step 3. make SLRUM batch script and run code in server 앞선 단계에서 conda환경이 잘 만들어졌다면 해당 가상환경을 activate하여 코드를 돌리는 SLURM batch script를 작성할 수 있다. 사용자들의 이해를 돕기 위해 TensorFlow 공식 페이지에 게시된 초보자용 튜토리얼 코드를 SLURM을 통해 실행시키는 예제를 공유한다. 먼저, 튜토리얼 코드는 다음과 같다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # tensor.py import tensorflow as tf mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation=\u0026#39;relu\u0026#39;), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;) ]) model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;sparse_categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(x_train, y_train, epochs=5) model.evaluate(x_test, y_test, verbose=2)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  #!/bin/bash # #SBATCH --job-name=gpu-tensor-test #SBATCH --mem=4gb #SBATCH --nodelist=gpu-compute #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --gres=gpu:1 #SBATCH --time=00:20:00 #SBATCH --account=ghk #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/ghk/code/gputest.log CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=tensor ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME ## $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH ## $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8 tensorflow pandas numpy source $CONDA_BIN_PATH/activate $ENV_PATH ## pip uninstall keras ## pip install keras==2.6.0 python /mnt/nas/users/ghk/code/tensor.py    —job-name: 수행할 작업의 이름 —mem: memory limit —nodelist: 작업할 노드의 이름 —ntasks: 작업의 수 —cpus-per-task: 각 작업에서 사용할 cpu 코어의 수 —gres=gpu : 작업에서 사용할 gpu의 개수, gpu-compute 노드에는 총 2개의 gpu가 사용 가능하다. —time: 작업 제한시간 —account: 해당 작업을 수행하는 계정의 이름 —partition: group of nodes with specific characteristics —output: 코드 실행 결과 log  제시한 대로 python 파일과 batch script 파일이 잘 만들어졌다면 sbatch 명령어를 입력하여 계산을 실행할 수 있다.\n1 2  sbatch tensor.sh smap -i 1 # 작업 현황을 1초마다 갱신하여 보여준다. ctrl+c로 escape 할 수 있다.   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ghk@proxy:~/code$ cat gputest.log 2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. 2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2) Epoch 1/5 1875/1875 [==============================] - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140 Epoch 2/5 1875/1875 [==============================] - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575 Epoch 3/5 1875/1875 [==============================] - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675 Epoch 4/5 1875/1875 [==============================] - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739 Epoch 5/5 1875/1875 [==============================] - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762 313/313 - 4s - loss: 0.0782 - accuracy: 0.9779 [0.078231580555439, 0.9779000282287598]   SLURM batch script를 사용자들이 보다 편하게 만들 수 있도록 SLURM Job Configurator 를 새롭게 작성하였다. 사용자들은 gpu 옵션을 체크하거나 해제하여 gpu-compute node 사용 여부를 결정할 수 있다. 해당되는 옵션을 체크하고 Print 버튼을 누르면 손쉽게 batch script를 작성할 수 있다.\n더 알아보기 Submitting a slurm job script\nSLRUM Job Examples\nTensorFlow on the HPC Clusters\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/how-to-use-gpu-node-for-slurm/","summary":"How to use GPU node for SLURM Step 1. Export your conda setting conda 환경을 동일하게 맞춰주기 위해 local에서 생성된 가상환경으로부터 환경설정 파일을 만들고, 서버에서 conda 가상환경을 만들 때 사용한다.\n1 2 3 4 5 6 7 8 9 10 11  # export conda setting conda activate [YOUR ENV NAME] conda env export -n [ENV NAME] -f [FILENAME].yml --no-builds # 이러면 조금은 해결되긴 함 # create environment from file conda create --name [YOUR ENV NAME] python = [VESTION] # same env name in yml file conda env create -f [FILENAME].","title":"How to Use GPU Node for SLURM"},{"content":"요약 Chili Pepper는\n 총 세 개의 컴퓨터로 구성된 컴퓨팅 클러스터입니다. Cpu node 하나와 gpu node 하나, 그리고 이 둘을 관리하는 proxy node로 구성되어 있습니다. Slurm이라는 job scheduler로 여러 사용자의 작업을 각 node에 효율적으로 할당합니다. 각 사용자는 자신만의 conda environment를 스스로 생성하여 사용합니다. 기본적으로 non-interactive입니다.사용자가 자신의 로컬 컴퓨터에서 작성 및 테스트한 코드를 서버에 제출하면 서버가 해당 코드를 실행합니다. 주피터 노트북 환경은 실행 가능하지만, 꼭 필요한 경우에 한하여 요청 시 제공합니다. 이는 노트북 환경은 작업 단위가 아닌 시간 단위로 실행되기 때문에 서버의 RAM 자원을 지나치게 많이 점유하고 다른 작업의 실행을 방해하기 때문입니다. 파일은 위 세 컴퓨터와 별개의 NAS(Network Attached Storage)에 저장되며, 모든 컴퓨터에 마운트되어 있으므로 한번 클러스터 내로 옮긴 파일은 클러스터 내부에서 다시 옮길 필요가 없습니다.  1. 클러스터 구성 1. cpu node  Name: cpu-compute CPU: Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz 32 cores RAM: 128GB OS: ubuntu 18.04.6 LTS conda version: 4.11.0  2. gpu-compute node  Name: gpu-compute CPU: Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz 16 cores GPU: NVIDIA® Tesla® T4 16GB x 2 RAM: 80GB OS: ubuntu 18.04.6 LTS conda version: 4.6.14 GPU driver version: 418.67  3. proxy node  Name: proxy CPU: Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz 2cores RAM: 4GB OS: ubuntu 18.04.6 LTS  특이사항   Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz가 18코어 제품임에도 불구하고 세 컴퓨터에 각각 32코어, 16코어, 2코어로 장착되어 있는 것은 이 세 컴퓨터가 네이버 클라우드 플랫폼에서 호스팅되고 있기 때문입니다. 네이버 클라우드 플랫폼에서 각 컴퓨터에 정해진 코어 수를 할당합니다.\n  proxy node는 사용자가 로그인하여 job을 제출하기 위한 용도로만 쓰이는 컴퓨터이므로 성능이 낮습니다.\n  사용자는 proxy에만 접속할 수 있으며, cpu-compute와 gpu-compute에는 접속할 수 없습니다.\n  2. Slurm job scheduler Job scheduler HPC(High performance computing) 시스템은 개인용 컴퓨터와 달리 여러 사용자가 여러 node를 공유하며 사용합니다. 따라서 누구의 작업이 언제 어느 node에서 실행될지 결정해 주어야 합니다. 이러한 역할을 수행하는 것이 job scheduler입니다.\nJob scheduler를 식당의 웨이터에 비유할 수 있습니다. 식당에 사람이 많으면 줄을 서서 기다려야 합니다. 웨이터는 각 손님 그룹의 수에 맞는 자리가 나면 그 그룹을 테이블로 안내합니다1. 용어   Job: 사용자가 클러스터에서 실행하고자 하는 코드(bash, python, R 등을 모두 포함)\n  Batch job submission: 사용자가 미리 작성한 코드(output을 파일로 저장하는 내용 포함)를 scheduler에게 제출하여 non-interactive하게 실행하는 것\n  Slurm Slurm(Simple Linux Utility for Resource Management)은 HPC에서 많이 채용하는 job scheduler입니다. 전 세계 TOP 500 슈퍼컴퓨터 중 60%가 slurm을 사용합니다2.\nSlurm은 각 사용자의 cpu사용량 등 다양한 통계를 기반으로 작업의 우선순위를 결정할 수 있습니다. 예를 들어, University of Toronto의 Computer Science Department의 HPC는 사용 CPU 코어 수 * 사용 시간(초) 값이 낮은 사용자의 job을 먼저 실행합니다. RAM 사용량은 0.25GB당 CPU 1코어 사용으로, GPU 사용량은 GPU 1개당 CPU 16코어 사용으로 환산합니다3.\n현재 Chili Pepper는 위와 같은 점수제가 아닌 FIFO(First In, First Out) 규칙을 사용하고 있습니다. 일정 기간 운영해본 뒤 상황에 맞추어 규칙을 변경할 예정입니다.\n3. Conda environment Virtual environment Virtual environment를 사용하면 한 컴퓨터 내에서 각 user가 독립적으로 Python과 R 패키지를 관리할 수 있습니다. 또한, 여러 컴퓨터에서 동일한 환경을 구축하여 패키지 버전 차이로 인한 문제 발생을 방지할 수 있습니다4. 이는 특히 GPU driver, CUDA, cuDNN, 딥러닝 라이브러리의 버전 간 호환성이 중요한 딥러닝 job에서 유용합니다.\n여러 사용자가 node를 공유하는 HPC에서 virtual environment의 사용은 필수적입니다. 각 사용자는 자신의 로컬 컴퓨터와 동일한 Python 및 R 환경을 node 내에 구축합니다. 그리고 로컬 컴퓨터에서 코드를 작성하고 이상 없이 실행되는지 테스트합니다. 문제 없이 실행되는 것이 확인된 코드를 slurm을 통해 클러스터에서 실행합니다. Virtual environment는 로컬에서 작성한 코드가 클러스터에서 문제 없이 작동하는 것을 보장합니다.\nConda environment Chili Pepper는 conda를 이용해 virtual environment를 구현합니다. Conda는 Python, R, Ruby, Lua, Scalca, Java, Javascript, C/C++, FORTRAN 등 다양한 언어를 지원할 뿐만 아니라 Windows, MacOS, Linux를 모두 지원합니다5.\nChili Pepper에서 job을 실행하기 위해서는 반드시 conda environment를 사용해야 합니다.\n  https://epcced.github.io/hpc-intro/13-scheduler/index.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://wiki.hpc.odu.edu/en/slurm\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://support.cs.toronto.edu/systems/slurmresource.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.marquette.edu/high-performance-computing/py-venv.php\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://docs.conda.io/en/latest/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/intro/","summary":"요약 Chili Pepper는\n 총 세 개의 컴퓨터로 구성된 컴퓨팅 클러스터입니다. Cpu node 하나와 gpu node 하나, 그리고 이 둘을 관리하는 proxy node로 구성되어 있습니다. Slurm이라는 job scheduler로 여러 사용자의 작업을 각 node에 효율적으로 할당합니다. 각 사용자는 자신만의 conda environment를 스스로 생성하여 사용합니다. 기본적으로 non-interactive입니다.사용자가 자신의 로컬 컴퓨터에서 작성 및 테스트한 코드를 서버에 제출하면 서버가 해당 코드를 실행합니다. 주피터 노트북 환경은 실행 가능하지만, 꼭 필요한 경우에 한하여 요청 시 제공합니다. 이는 노트북 환경은 작업 단위가 아닌 시간 단위로 실행되기 때문에 서버의 RAM 자원을 지나치게 많이 점유하고 다른 작업의 실행을 방해하기 때문입니다.","title":"Intro"},{"content":"1. What is SLURM? Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for its operation and is relatively self-contained.\nIf you need more information, Please Visit https://slurm.schedmd.com/overview.html\n2. Basic SLURM Command   sbatch\n Submit a batch script to SLURM  1 2 3 4  $ sbatch [YOUR_SCRIPT] # output \u0026gt; Submitted batch job 210 # job_id: 210     squeue\n View the queue  1 2 3 4 5  $ squeue # output \u0026gt; JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 210 all test1 ghk R 0:29 1 cpu-compute     scancel\n Cancel a SLURM job  1  $ scancel [YOUR_JOBID]     sinfo\n See the state of system  1 2 3 4 5  $ sinfo # output \u0026gt; PARTITION AVAIL TIMELIMIT NODES STATE NODELIST all* up infinite 2 idle cpu-compute,gpu-compute     smap\n graphically view information about SLURM job    For more information about SLURM command, please visit website below.\n  SLURM Workload Manager\n  SLURM Command Cheatsheet\n  SLURM Reference Sheet(NeSI)\n  Submit your first job(NeSI)\n  3. How to make SLURM batch script? \u0026lsquo;Job submission file\u0026rsquo; is the official SLURM name for the file you use to submit your program and ask for resources from the job scheduler. In this document, we will be using it ‘batch script’ or ‘script’.\nBasic example 1 2 3 4 5 6 7  #!/bin/bash #  # SBATCH --job-name=basic # SBATCH --mem=1gb # SBATCH --ntasks=1 # SBATCH --time=01:00 # SBATCH --output=/mnt/nas/users/testuser/basic.log   Asking 1 tasks, running for no more than 1 minutes limit memory less than 1gb. If any problem with your job, log file(in this case, \u0026lsquo;basic.log\u0026rsquo;) have information to help troubleshoot the issue.\nYou can also use gpu-nodes by using \u0026lsquo;—gres\u0026rsquo; option. Here is an example.\n1 2 3 4 5 6 7 8 9 10 11  #!/bin/bash #  #SBATCH --job-name=basic #SBATCH --nodes=1 #SBATCH --gres=gpu:2 # max : 2 #SBATCH --time=01:00 #SBATCH --account=testuser #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/testuser/torch.log source activate /opt/miniconda/envs/pytorch \u0026amp;\u0026amp; python /mnt/nas/users/testuser/main.py   1 2 3 4 5 6 7 8 9 10  # main.py import torch print(\u0026#39;is cuda avaiable? \u0026#39;, torch.cuda.is_available()) print(\u0026#39;how many cuda devices? \u0026#39;,torch.cuda.device_count()) print(\u0026#39;get first cuda device name =\u0026gt; \u0026#39;, torch.cuda.get_device_name(0)) print(\u0026#39;*** MEMORY INFO ***\u0026#39;) t = torch.cuda.get_device_properties(0).total_memory print(\u0026#39;total memory =\u0026gt; \u0026#39;, t) print(\u0026#39;total memory: \u0026#39;, t)   The job can then be submitted through sbatch\n1 2 3 4 5 6 7  $ sbatch basic.sh $ cat torch.log \u0026gt; is cuda avaiable? True \u0026gt; how many cuda devices? 2 \u0026gt; get first cuda device name =\u0026gt; Tesla T4 \u0026gt; ***MEMORY INFO*** \u0026gt; total memory =\u0026gt; 16879583232   Beacuse we only have 2 gpu machine, this option can’t be set more than 2\nFor the convenience of users, we provide SLURM job configurator page in our website. Please visit SLURM job configurator and make your own SLURM batch script!\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/slurm-documentation/","summary":"1. What is SLURM? Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for its operation and is relatively self-contained.\nIf you need more information, Please Visit https://slurm.schedmd.com/overview.html\n2. Basic SLURM Command   sbatch\n Submit a batch script to SLURM  1 2 3 4  $ sbatch [YOUR_SCRIPT] # output \u0026gt; Submitted batch job 210 # job_id: 210     squeue","title":"SLURM Documentation"},{"content":"Intro This documentation will go over the basics of using the Chili Pepper cluster. Please go through this documentation step-by-step. Contact the server administrator via email or use the Q\u0026amp;A channel in the Slack Group.\nStep 1 - Understanding the Cluster Structure Chili Pepper cluster has a NAS which contains user home directories and other shared files. All users and groups are consistent across all nodes. The prefix for the user directory is /mnt/nas/users/. For example, the home directory for the user dummyuser will be /mnt/nas/users/dummyuser/. The home directory is the recommended directory for users to store scripts, data and configuration files for using the Chili Pepper cluster.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # with the tree command the home directory will typically look like this /mnt/nas/users/dummyuser/ ├── .bash_history ├── .bash_logout ├── .bashrc ├── .conda ├── .config ├── GettingStarted.md ├── .gnupg ├── .ipynb_checkpoints ├── .ipython ├── .jupyter ├── .local ├── logs ├── .npm ├── .profile ├── .python_history ├── some_script.sh ├── .ssh └── .viminfo   Step 2 - Data Transfer With cluster access information(SSH) provided by the administrator, you can send and recieve files from and to the cluster with scp. The dummyuser can send various local files to the cluster in the following fashion. Note that for security purposes the default port for SSH is not 22. The administrator will inform you of this information upon providing access information to the cluster.\nSending a local file(some_file.txt) to the remote home directory 1  scp some_file.txt dummyuser@hpc.stat.yonsei.ac.kr:~/   Sending a local directory(some_files/) to the remote home directory 1 2  scp -r some_files dummyuser@hpc.stat.yonsei.ac.kr:~/ # /mnt/nas/users/dummyuser/some_files/ will be created   Recieving a remote file(some_file.txt) in the home directory to the current local directory 1  scp dummyuser@hpc.stat.yonsei.ac.kr:~/some_file.txt   Recieving a remote directory(/mnt/nas/users/dummyuser/some_files) in the home directory to the current local directory 1  scp -r dummyuser@hpc.stat.yonsei.ac.kr:~/some_files ./   Other various options for scp exist. More information on this topic can be found in this article. Also users can use GitHub or GitLab to upload and download source code to the cluster. This will be handled in a seperate article.\nStep 3 - Writing a SBATCH script for SLURM. From the homepage the SLURM batch scripting tool is available. Let\u0026rsquo;s look at the sample script(/mnt/nas/users/dummyuser/test_script.sh) created by using the tool. The first-half(line 1 ~ 11) of the script consists of directives and parameters for the slurm job. Each user can set the number of nodes, the time for the job to occupy the number of nodes, the location for the output logfile. There are more options available for submitting a job. Additional resources for SBATCH arguments can be found here.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/bin/bash # The interpreter used to execute the script #“#SBATCH” directives that convey submission options: #SBATCH --job-name=conda-env-create #SBATCH --nodes=1 #SBATCH --time=15:00 #SBATCH --account=dummyuser #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/dummyuser/conda.log # The application(s) to execute along with its input arguments and options: CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=myenv ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8 pandas numpy scikit-learn source $CONDA_BIN_PATH/activate $ENV_PATH \u0026amp;\u0026amp; pip freeze   From line 15 to the end of the script are actual bash commands for the node to execute.\n Line 15~16 creates two local variables(ENV_NAME and ENV_PATH). In the above script a conda environment named myenv will be created under /mnt/nas/users/dummyuser/.conda/envs/myenv. Line 18 will remove the environment in ENV_PATH if it is present. Line 19 will create a conda environment in ENV_PATH thanks to the -y(--yes) flag. This environment will have a Python interpreter of version 3.8 along with listed packages(pandas, numpy and scikit-learn). Line 20 will activate the conda environment in ENV_PATH and then sequentially run a pip freeze to the stdout. Note that the stdout is saved in the log file from line 11(/mnt/nas/users/dummyuser/conda.log).  To actually run a data science job, the only thing you have to do is to change the required packages for your environment, modify the pip freeze into python your_script_to_run.py.\nStep 4 - Submitting the script The submission of the script from the above is very simple.\n1  sbatch test_script.sh   You can check the current job queue with the following command.\n1  squeue   When you want to cancel the job you have submitted, get the JOBID from the squeue command and use the scancel command in the following fashion. Suppose the JOBID is 23.\n1  scancel 23   Note that ordinary users cannot cancel jobs that belong to other users, but the administrator can.\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/using-slurm-copy/","summary":"Intro This documentation will go over the basics of using the Chili Pepper cluster. Please go through this documentation step-by-step. Contact the server administrator via email or use the Q\u0026amp;A channel in the Slack Group.\nStep 1 - Understanding the Cluster Structure Chili Pepper cluster has a NAS which contains user home directories and other shared files. All users and groups are consistent across all nodes. The prefix for the user directory is /mnt/nas/users/.","title":"How do I use the Chili Pepper Cluster?"},{"content":"Creating a Python Kernel Admin Prerequisite Admin must enable conda for all users by creating a symlink. This will let users create their own virtual environment by using the conda create command.\n1  ln -s /opt/conda/bin/conda /usr/local/bin/conda   User Instructions Python  Users can launch a terminal session with either JupyterHub or SSH connections. Launch a bash session.  1  bash   Users then can create a virtual environment in the following way. Note that specifying ipykernel package will make the user easily create jupyter kernels from that environment. Also users can create virtual environments with various python versions(3.6 ~ 3.9). Activate the environment. If any warnings occur, read the warning and do the recommended procedure. Most of the time you will need to refresh your shell with bash.  1 2 3 4 5 6 7 8  # create environemnt conda create -n NAME_OF_VIRTUAL_ENV python=3.8 ipykernel # refresh your shell bash # activate environemnt conda activate NAME_OF_VIRTUAL_ENV   Install packages via pip.  1 2 3 4 5  # directly pip install PACKAGE_NAME # requirements.txt pip install -r YOUR_REQUIREMENTS.txt   Add the virtual environment as a kernel. This will be only available to each user.  1  python -m ipykernel install --user --name NAME_OF_VIRTUAL_ENV --display-name \u0026#34;[displayKenrelName]\u0026#34;   R  Launch a bash session via JupyterHub or SSH.  1  bash   Users then can create a virtual environment in the following way.  1 2 3 4 5 6 7 8  # create environemnt conda create -n NAME_OF_VIRTUAL_ENV r-essentials r-base r-irkernel # refresh your shell bash # activate environemnt conda activate NAME_OF_VIRTUAL_ENV   Install packages via install.packages().  1 2  # directly Rscript -e \u0026#39;install.packages(c(\u0026#34;dplyr\u0026#34;))\u0026#39;   Add the virtual environment as a kernel. This will be only available to each user.  1  Rscript -e \u0026#34;IRkernel::installspec(name=\u0026#39;myRkernel\u0026#39;, displayname=\u0026#39;My R Kernel\u0026#39;)\u0026#34;   Removing Kernels To remove kernels use the jupyter command in terminal.\nView your current kernel list with the following command from a bash terminal.\n1  jupyter kernelspec list   Remove kernel with the following command.\n1  jupyter kernelspec remove KERNELNAME   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/configuring-jupyter-kernel/","summary":"Creating a Python Kernel Admin Prerequisite Admin must enable conda for all users by creating a symlink. This will let users create their own virtual environment by using the conda create command.\n1  ln -s /opt/conda/bin/conda /usr/local/bin/conda   User Instructions Python  Users can launch a terminal session with either JupyterHub or SSH connections. Launch a bash session.  1  bash   Users then can create a virtual environment in the following way.","title":"Creating Your Custom Jupyter Kernel from a Virtual Environment"}]