[{"content":"5. iOS에서 클러스터 사용하기 2번 문서에서 설명했듯이, 어느 환경에서든 SSH 접속만 가능하다면 클러스터 이용이 가능합니다. 이 문서는 iPad에서 koder라는 앱을 이용해 클러스터를 이용하는 예제를 다룹니다.\n1. 파일 시스템 접속 클러스터의 파일 시스템에 접속하여 파일을 열람하고 수정할 수 있습니다.  좌측 상단의 2번째 아이콘을 클릭하여 FTP/SFTP 설정으로 들어갑니다. 좌측 하단의 + 버튼을 누르면 New FTP Connection 설정 창이 나옵니다.  3. 아래 내용을 입력한 다음 Create를 누릅니다.\n  먼저, Connection을 SFTP로 바꿉니다.\n  Name은 이 connection 설정의 이름을 의미합니다. 원하는 이름을 입력합니다.\n  Host Name에 hpc.stat.yonsei.ac.kr을 입력합니다.\n  Username, Password에 linux username, password를 입력합니다.\n  Port에 Slack에서 안내한 SSH 포트번호를 입력합니다.\n  화면 좌측 탭에 connection이 생성됩니다.   화면 좌측 탭에 connection이 생성됩니다. 이를 클릭하여 접속합니다.\n  User home directory의 파일들이 나옵니다. 파일을 클릭하면 오른쪽의 텍스트 에디터 창에 내용이 표시됩니다. 파일 내용을 수정한 뒤 저장하려면 우측 탭 상단에 있는 업로드 모양 아이콘을 누릅니다.   2. SSH 접속 커맨드를 입력하고 job을 제출하려면 SSH로 접속해야 합니다.\n  좌측 탭 하단의 콘솔 모양 아이콘을 클릭하여 SSH 접속 절정 창을 엽니다.   아래 사진을 참고하여 정보를 입력하고 **Connect*를 누릅니다.\n 맨 위에는 hpc.stat.yonsei.ac.kr을 입력합니다. 그 다음 칸에는 linux username을 입력합니다. 그 다음 칸에는 linux user password를 입력합니다. 그 다음 칸에는 Slack에서 공지한 SSH 포트번호를 입력합니다.    SSH로 proxy node에 접속되고 터미널 환경이 나타납니다. 이제 Visual Studio Code에서 했던 것처럼 클러스터를 사용합니다.   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/05_ipad/","summary":"5. iOS에서 클러스터 사용하기 2번 문서에서 설명했듯이, 어느 환경에서든 SSH 접속만 가능하다면 클러스터 이용이 가능합니다. 이 문서는 iPad에서 koder라는 앱을 이용해 클러스터를 이용하는 예제를 다룹니다.\n1. 파일 시스템 접속 클러스터의 파일 시스템에 접속하여 파일을 열람하고 수정할 수 있습니다.  좌측 상단의 2번째 아이콘을 클릭하여 FTP/SFTP 설정으로 들어갑니다. 좌측 하단의 + 버튼을 누르면 New FTP Connection 설정 창이 나옵니다.  3. 아래 내용을 입력한 다음 Create를 누릅니다.\n  먼저, Connection을 SFTP로 바꿉니다.","title":"5. iOS에서 클러스터 사용하기"},{"content":"4. GPU node에서 Python 코드 실행하기 2번 문서를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.\ngpu-compute node에서는 Python만 사용 가능합니다.\nStep 4. Export your conda setting 버전 관리 딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.\n GPU 드라이버 버전(418.67) Python 버전 CUDA 버전(호환성 표) cuDNN, 딥러닝 라이브러리(tensorflow, pytorch) 버전(호환성 표: tensorflow, pytorch)  이들의 버전 간 호환이 되는 조합을 숙지하고 이에 따라 conda environment를 만들어야 합니다. gpu-compute node의 GPU 드라이버 버전은 418.67으로 고정되어 있지만, 나머지 요소들의 버전은 conda environment마다 다르게 설정할 수 있습니다. 단, Python 버전의 경우 gpu-compute node에는 conda version 4.6.14가 설치되어 있으므로 3.8까지만 지원합니다.\nGPU 드라이버 버전(418.67)에 맞는 Python 버전과 딥러닝 라이브러리 버전을 정한 다음 conda create 명령어에서 버전을 명시해 주면 알아서 CUDA와 cuDNN 버전을 맞춰 줍니다. 이 문서에서는 이 방법을 사용합니다.\n이 문서에서 사용하는 버전은 tensorflow-gpu-2.2.0입니다.\n1. local에서 conda environment 생성 2번 문서의 step 4의 내용에 따라 local에서 conda environment를 생성합니다. conda list로 CUDA, cudnn 버전을 확인합니다.\n2. gpu-compute node에서 동일한 conda environment 구축 두 가지 방법을 소개합니다.\n2.1. 중요 패키지의 버전만 맞추기 2번 문서에서 한 것처럼 tensorflow 등의 버전만 동일하게 하여 gpu-compute node에서 conda create로 conda environment를 만들 수 있습니다.\n 이 방법은 2번 문서의 안내를 따라 진행하면 됩니다. 따라서 설명을 생략하고 sbatch script만 제시합니다. Slurm job configurator에서 Using GPU에 체크한다는 점만 다릅니다. 이 문서에서 사용하는 버전은 tensorflow-gpu-2.2.0입니다.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #!/bin/bash #SBATCH --job-name=testEnvGPU #SBATCH --nodes=1 #SBATCH --mem=4gb #SBATCH --partition=all #SBATCH --nodelist=gpu-compute #SBATCH --output=testEnvGPU.log #SBATCH --error=testEnvGPU.err CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnvGPU #local에서와 같은 이름으로 입력 ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.7 source $CONDA_BIN_PATH/activate $ENV_PATH conda install -y tensorflow-gpu=2.2.0   cudatoolkit, cudnn 등이 용량이 커서 시간이 조금 오래 걸립니다.\n2.2. local environment export하기 Local에서 생성된 가상환경으로부터 환경설정 yml 파일을 만들고, 이를 이용해 gpu-compute node에서 conda environment를 생성하여 conda 환경을 동일하게 맞출 수도 있습니다. 이게 가장 이상적인 방법이지만, local OS가 linux가 아닐 경우 문제가 발생할 수 있습니다. 이 문서에서는 이 방법을 설명합니다.\nLocal에서 아래 커맨드로 yml 파일을 추출합니다.\n1 2 3  # export conda setting conda activate [YOUR ENV NAME] conda env export -n [ENV NAME] -f [FILENAME].yml --no-builds # 이러면 문제가 해결될 수 있습니다.   yml 파일을 클러스터 내 user home directory로 옮기고 아래 커맨드를 slurm job script에 추가하고 sbatch로 실행합니다. 이 때 Slurm job configurator에서 Using GPU에 체크해야 합니다.\n1 2 3 4 5 6  # create environment from file conda create --name [YOUR ENV NAME] python = [VESTION] # same env name in yml file conda env create -f [FILENAME].yml conda env create -p [prefix path] -f [filename].yml   —no-builds 옵션은 서로 다른 OS에서 conda environment 내 패키지들의 버전 충돌을 방지하기 위한 것입니다. 이 옵션만으로 문제가 해결되기도 하지만, 해결되지 않으면 user가 직접 yml 파일을 수정해야 합니다. 에러 메시지에 ResolvePackageNotFound라는 문구가 나오는데, 이 문구 아래의 패키지들을 yml 파일에서 삭제해주면 문제가 해결될 수 있습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  conda env create -f test.yml Collecting package metadata: done Solving environment: failed # yml 파일에서 아래에 등장하는 패키지들을 지워줍니다. ResolvePackageNotFound: - libgfortran==3.0.1=h93005f0_2 # --no-builds 옵션을 쓰면 패키지 버전 옆의 빌드 정보가 나오지 않습니다. - pyzmq==17.0.0=py36h1de35cc_1 - python==3.6.6=h4a56312_1003 - prompt_toolkit==1.0.15=py36haeda067_0 - libiconv==1.15=h1de35cc_1004 - sqlite==3.25.3=ha441bb4_0 - six==1.11.0=py36h0e22d5e_1 - cryptography==2.3.1=py36hdbc3d79_1000 - openssl==1.0.2p=h1de35cc_1002 - libxml2==2.9.8=hf14e9c8_1005 - libcxxabi==4.0.1=hebd6815_0 - matplotlib==2.2.3=py36h0e0179f_0 - ptyprocess==0.5.2=py36he6521c3_0    💡 `yml` file을 이용한 conda 환경 설정은 로컬과 서버 작업 환경을 동일하게 설정할 수 있는 신뢰할 수 있는 방법이지만, conda 환경 설정 과정이 너무 번거롭다면 requirements.txt를 만들어 패키지 버전만 관리할 수도 있습니다.  1 2 3 4 5 6 7  conda install --force-reinstall -y -q -c conda-forge --file requirements.txt # --force-reinstall : Install the package even if it already exists. # -y : Yes, do not ask for confirmation. # -q : Quiet, do not display progress bar. # -c : Channels, additional channels to search for packages # conda-forge is recommended   Step 5. Slrum batch script 작성하여 서버에 제출하기 1. Python 코드 작성 이제 클러스터에서 실행할 Python 코드를 local에서 작성합니다. 먼저 local에서 코드가 오류 없이 돌아가는지 확인합니다. 그 후 클러스터의 user home directory에 옮기거나, Visual Studio Code내에서 작성하여 저장합니다.\n아래는 TensorFlow 공식 페이지에 게시된 초보자용 문서 코드입니다. Batch script를 작성할 때는 알고리즘의 output이 자동으로 저장되지 않으므로 파일로 결과를 저장하는 코드를 포함하는 것이 좋습니다. 아래 코드에는 결과를 저장하는 코드는 없지만, tensorflow가 학습 과정을 콘솔에 출력하기 때문에 이를 로그 파일에서 볼 수 있습니다. 아래 코드를 tensor.py라는 이름으로 user home directory에 저장합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # tensor.py import tensorflow as tf mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation=\u0026#39;relu\u0026#39;), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;) ]) model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;sparse_categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(x_train, y_train, epochs=5) model.evaluate(x_test, y_test, verbose=2)   2. 현재 클러스터 자원 사용량 확인 gpu-compute의 여유 cpu 코어 개수와 RAM은 문서22번 문서에 있는 방법을 통해 확인합니다. GPU의 경우 한 user가 하나의 GPU만을 사용하도록 되어 있습니다. 따라서 gpu-compute node는 최대 2명의 user가 사용할 수 있습니다. squeue 커맨드를 통해 gpu-compute node에서 실행 중이거나 실행 대기 중인 job의 개수를 파악합니다.\n3. Slurm batch script 작성 앞선 단계에서 만든 해당 conda environment를 activate하고 코드를 실행하는 Slurm batch script를 작성합니다. 클러스터 소개 페이지의 slurm job configurator를 사용하면 script를 쉽게 작성할 수 있습니다.\n Conda activate에 체크합니다. Using GPU에 체크합니다. 빈칸들을 채웁니다. Script란에 python xxx.py라고 작성합니다. 이는 home directory에 있는 xxx.py 파일을 Python으로 실행하라는 의미입니다. Print \u0026amp; Copy 버튼을 누르면 내용이 클립보드에 복사됩니다.  이 문서에서 사용한 Slurm batch script의 내용은 아래와 같습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/bin/bash # #SBATCH --job-name=tensor #SBATCH --partition=all #SBATCH --account=mjm #SBATCH --mem=16gb #SBATCH --ntasks=1 #SBATCH --cpus-per-task=8 #SBATCH --time=00:30:00 #SBATCH --output=/mnt/nas/users/mjm/tensor.log #SBATCH --error=/mnt/nas/users/mjm/tensor.err #SBATCH --gres=gpu:1 #SBATCH --nodelist=gpu-compute CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnvGPU ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME source $CONDA_BIN_PATH/activate $ENV_PATH python tensor.py   tensor.job이라는 이름으로 클러스터의 user home directory에 저장합니다.\nsbatch에 대한 더 자세한 정보는 Slurm 공식 웹페이지를 참조하세요.\n4. Slurm batch script 실행 Conda environment를 만들 때처럼, sbatch 커맨드를 통해 job을 제출합니다. 할당되는 job 번호는 나중에 squeue를 통해 정보를 확인하거나 job을 취소할 때 이용되므로 기록해 놓아야 합니다.\n터미널을 여러 개 띄운 다음 smap -i로 작업 현황을 확인하고, cat xxx.log이나 tail -f xxx.err으로 콘솔 출력이나 error를 확인합니다.\n1 2 3 4  sbatch tensor.job smap -i 1 # 작업 현황을 1초마다 갱신하여 보여줍니다. ctrl+c로 escape 할 수 있습니다. cat tensor.log tail -f tensor.err   로그 파일에 콘솔 아웃풋이 기록됩니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. 2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2) Epoch 1/5 1875/1875 [==============================] - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140 Epoch 2/5 1875/1875 [==============================] - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575 Epoch 3/5 1875/1875 [==============================] - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675 Epoch 4/5 1875/1875 [==============================] - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739 Epoch 5/5 1875/1875 [==============================] - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762 313/313 - 4s - loss: 0.0782 - accuracy: 0.9779 [0.078231580555439, 0.9779000282287598]   더 알아보기 Submitting a slurm job script\nSLRUM Job Examples\nTensorFlow on the HPC Clusters\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/04_how-to-use-gpu-node-for-slurm-copy/","summary":"4. GPU node에서 Python 코드 실행하기 2번 문서를 먼저 숙지하시기 바랍니다. 이 문서는 2번 문서의 Step 1, 2, 3 이후의 내용만을 다룹니다.\ngpu-compute node에서는 Python만 사용 가능합니다.\nStep 4. Export your conda setting 버전 관리 딥러닝 라이브러리를 사용할 때에는 버전 관리가 중요합니다.\n GPU 드라이버 버전(418.67) Python 버전 CUDA 버전(호환성 표) cuDNN, 딥러닝 라이브러리(tensorflow, pytorch) 버전(호환성 표: tensorflow, pytorch)  이들의 버전 간 호환이 되는 조합을 숙지하고 이에 따라 conda environment를 만들어야 합니다.","title":"4. GPU node 사용법(Python)"},{"content":"3. CPU node에서 R 코드 실행하기 2번 문서의 Step 1, 2, 3을 먼저 숙지하시기 바랍니다. 이 문서는 그 이후의 내용만을 다룹니다.\n1. R 코드 작성 클러스터에서 실행할 R 코드를 local에서 작성합니다. 코드가 문제 없이 실행되는지 먼저 local에서 확인합니다. 그 후 실제로 실행할 코드를 작성하여 클러스터의 user home directory에 옮기거나, Visual Studio Code내에서 작성하여 저장합니다.\nR은 cpu-compute에만 설치되어 있습니다. R은 conda environment를 사용하지 않습니다. R 패키지들은 user별 directory가 아닌 NAS 내의 공통 폴더에 저장됩니다. 실행할 R 코드를 script로 작성한 다음 Slurm batch script 내에 해당 script를 실행하도록 Rscript xxx.R command를 적어주면 됩니다.\n아래의 샘플 코드는 xgboost와 caret을 설치 및 로드하고 learning과 prediction을 수행한 다음 prediction 결과 plot을 jpeg로 저장하는 코드입니다. Batch script를 작성할 때는 알고리즘의 output이 자동으로 저장되지 않으므로 파일로 결과를 저장하는 코드를 포함하는 것이 좋습니다. 아래 코드를 R_test_cpu.R로 저장하여 user home directory에 둡니다.\n**install.packages()**에서\n force = FALSE 옵션은 이미 설치된 패키지를 또 설치하는 것을 막아줍니다1. INSTALL_opts = c('\u0026ndash;no-lock') 옵션은 설치가 이전에 강제로 중단되어서 directory에 락이 걸렸을 때 락을 무시하고 설치하게 합니다2.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  install.packages(\u0026#34;xgboost\u0026#34;, force = FALSE, INSTALL_opts = c(\u0026#39;--no-lock\u0026#39;)) install.packages(\u0026#34;caret\u0026#34;, force = FALSE, INSTALL_opts = c(\u0026#39;--no-lock\u0026#39;)) library(xgboost) library(caret) boston = MASS::Boston str(boston) set.seed(12) indexes = createDataPartition(boston$medv, p = .85, list = F) train = boston[indexes, ] test = boston[-indexes, ] train_x = data.matrix(train[, -13]) train_y = train[,13] test_x = data.matrix(test[, -13]) test_y = test[, 13] xgb_train = xgb.DMatrix(data = train_x, label = train_y) xgb_test = xgb.DMatrix(data = test_x, label = test_y) xgbc = xgboost(data = xgb_train, max.depth = 2, nrounds = 50) print(xgbc) pred_y = predict(xgbc, xgb_test) mse = mean((test_y - pred_y)^2) mae = caret::MAE(test_y, pred_y) rmse = caret::RMSE(test_y, pred_y) cat(\u0026#34;MSE: \u0026#34;, mse, \u0026#34;MAE: \u0026#34;, mae, \u0026#34; RMSE: \u0026#34;, rmse) x = 1:length(test_y) jpeg(file=\u0026#34;R_plot.jpeg\u0026#34;) plot(x, test_y, col = \u0026#34;red\u0026#34;, type = \u0026#34;l\u0026#34;) lines(x, pred_y, col = \u0026#34;blue\u0026#34;, type = \u0026#34;l\u0026#34;) legend(x = 1, y = 38, legend = c(\u0026#34;original test_y\u0026#34;, \u0026#34;predicted test_y\u0026#34;), col = c(\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;), box.lty = 1, cex = 0.8, lty = c(1, 1)) dev.off()   3\n2. 현재 클러스터 자원 사용량 확인 아래 커맨드를 통해 cpu-compute 노드의 cpu와 RAM 사용 현황을 볼 수 있습니다.\n1  sinfo -o \u0026#34;%n %e %m %a %c %C\u0026#34;   아래와 같은 결과가 나옵니다.\n1 2 3  HOSTNAMES FREE_MEM MEMORY AVAIL CPUS CPUS(A/I/O/T) cpu-compute 105589 128916 up 32 0/32/0/32 gpu-compute 53318 80532 up 16 0/16/0/16    CPUS의 A/I/O/T는 allocated/idle/other/total을 의미합니다. 자신의 job이 바로 실행되기를 원한다면, Slurm batch script를 작성할 때  RAM 용량을 FREE_MEM보다 적게 설정해야 합니다. CPU 코어 개수를 CPUS idle보다 적게 설정해야 합니다.   현재 가용 자원보다 더 많은 자원을 요구하는 script를 작성하면, job이 바로 실행되지 않습니다. 대기 상태에 있다가 다른 사용자들의 job이 끝나고 자원이 반환되면 job이 실행됩니다.  3. Slurm batch script 작성 작성한 코드를 cpu-compute node에서 실행하는 Slurm batch script를 작성합니다. 클러스터 소개 페이지의 slurm job configurator를 사용하면 script를 쉽게 작성할 수 있습니다.\n Python과 달리 conda environment를 사용하지 않으므로, conda activate에 체크하지 않습니다. 빈칸들을 채웁니다. Script란에 Rscript xxx.R라고 작성합니다. 이는 home directory에 있는 xxx.R 파일을 R로 실행하라는 의미입니다. Print \u0026amp; Copy 버튼을 누르면 내용이 클립보드에 복사됩니다.  R_test_cpu.job이라는 이름으로 클러스터의 user home directory에 저장합니다.\nConfigurator로 생성한 Slurm batch script의 내용은 아래와 같습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #!/bin/bash # #SBATCH --job-name=R_test_cpu #SBATCH --partition=all #SBATCH --account=mjm #SBATCH --mem=16gb #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --time=00:50:00 #SBATCH --output=/mnt/nas/users/mjm/R_test_cpu.log #SBATCH --error=/mnt/nas/users/mjm/R_test_cpu.err #SBATCH --nodelist=cpu-compute Rscript R_test_cpu.R   Script 윗부분의 #SBATCH 옵션들의 의미는 다음과 같습니다.\n —job-name: 수행할 작업의 이름 —mem: memory limit —nodelist: 작업할 노드의 이름 —ntasks: 작업의 수 —cpus-per-task: 각 작업에서 사용할 cpu 코어의 수 —time: 작업 제한시간 —account: 해당 작업을 수행하는 계정의 이름 —partition: group of nodes with specific characteristics \u0026ndash;nodelist: 사용할 node의 이름 —output: 코드 실행 결과 log 파일. 확장자는 out이나 log가 가능합니다. —error: 코드 실행 결과 log  sbatch에 대한 더 자세한 정보는 Slurm 공식 웹페이지를 참조하세요.\n4. Slurm batch script 실행 sbatch 커맨드를 통해 job을 제출합니다. 2번 문서의 Step 4에서처럼, ctrl+shift+~를 눌러 터미널을 여러 개 띄우고 smap -i로 작업 현황을 확인하고, tail -f xxx.out, tail -f xxx.err으로 콘솔 출력이나 error를 확인합니다. 작업은 5분 이내에 끝납니다.\n1  sbatch R_test_cpu.job   더 알아보기 Submitting a slurm job script\nSLRUM Job Examples\nReferences   https://stat.ethz.ch/pipermail/r-help/2010-May/239492.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://github.com/lumiamitie/TIL/blob/master/rstudy/package_lock.md\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.datatechnotes.com/2020/08/regression-example-with-xgboost-in-r.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/03_how-to-use-cpu-node_r/","summary":"3. CPU node에서 R 코드 실행하기 2번 문서의 Step 1, 2, 3을 먼저 숙지하시기 바랍니다. 이 문서는 그 이후의 내용만을 다룹니다.\n1. R 코드 작성 클러스터에서 실행할 R 코드를 local에서 작성합니다. 코드가 문제 없이 실행되는지 먼저 local에서 확인합니다. 그 후 실제로 실행할 코드를 작성하여 클러스터의 user home directory에 옮기거나, Visual Studio Code내에서 작성하여 저장합니다.\nR은 cpu-compute에만 설치되어 있습니다. R은 conda environment를 사용하지 않습니다. R 패키지들은 user별 directory가 아닌 NAS 내의 공통 폴더에 저장됩니다.","title":"3. CPU node 사용법(R)"},{"content":"CPU node에서 Python 코드 실행하기 Step 1 - terminal 앱 고르기 User는 SSH로 proxy node에 접속하여 클러스터를 사용합니다. 터미널 환경과 vi 에디터에 익숙한 user는 자신에게 친숙한 앱을 사용하면 됩니다. 그렇지 않은 경우 Visual Studio Code를 사용하는 것을 추천합니다. 이 문서에서는 Visual Studio Code를 사용하는 것을 전제로 합니다. 추천 이유는 다음과 같습니다.\n Windows, MacOS, Linux에서 모두 사용 가능합니다. 터미널과 에디터, 파일 브라우저가 통합되어 있습니다.  불편하게 vi나 nano등의 CLI용 텍스트 에디터를 사용할 필요가 없습니다. 파일 전송시 scp등의 복잡한 프로토콜을 사용할 필요 없이 drag \u0026amp; drop으로 수행할 수 있습니다.    Visual Studio Code외에 다른 앱을 사용하실 경우 추천하는 앱은 다음과 같습니다.\n Windows 10: WSL2(Windows Subsystem for Linux 2)와 Windows Terminal을 설치하여 사용하는 것을 추천합니다. MacOS: 기본 터미널을 사용해도 되지만, iTerm2를 추천합니다. iOS: 5번 문서를 참조하세요. Android: Termux  proxy node  proxy node는 user가 로그인하여 파일을 정리하고 cpu-compute나 gpu-compute node에 job을 제출하는 용도로만 쓰는 컴퓨터입니다.  따라서 proxy node는 성능이 낮습니다. proxy node에서는 Python 작업 등을 실행하지 마세요.   터미널에서 SSH 접속만 할 수 있다면 어떤 기기에서도 proxy node에 접속하여 job을 제출할 수 있습니다. 일단 job을 제출하면, 터미널이 종료되고 user와 proxy node 간의 연결이 끊겨도 job은 계속 cpu-compute나 gpu-compute node에서 실행됩니다. Standard output(Python, R에서 console에 출력되는 메시지)이 로그 파일에 기록되므로, 나중에 다시 터미널에 접속하여 job 실행 현황을 확인할 수 있습니다.  Step 2 - proxy node SSH 접속 Visual Studio Code를 설치하고 아래 안내에 따라 설정합니다.\n1. Visual Studio Code extensions에서 Remote Development 설치[fn^3] Microsoft가 제공하는 Remote Development extension pack을 설치합니다. Remote-WSL, Remote-Containers, Remote-SSH가 자동적으로 같이 설치됩니다. 2. Remote Explorer에서 SSH Targets를 선택 후, Add New 클릭 3. ssh 접속 커맨드 입력 아래와 같은 창이 뜨면 SSH 커맨드를 입력하여 proxy node에 접속합니다. 아래 코드에 Slack으로 안내받은 port, username을 넣어서 위 창에 입력하고 Enter키를 누르면 됩니다. SSH의 default port는 22이지만, 저희는 보안상 이유로 다른 port를 사용합니다.\n1  ssh -p [port] [username]@hpc.stat.yonsei.ac.kr   또는 안내받은 proxy node의 ip를 입력해도 됩니다.\n1  ssh -p [port] [username]@[ip]   4. SSH configuration file을 저장할 장소 선택 Select SSH configuration file to update가 나오면 맨 위 항목을 선택합니다. Host added! 라는 메시지가 우측 하단에 나옵니다. 5. Remote Explore에서 Connect to Host in New Window 선택 6. 서버 Platform 선택 Linux를 선택합니다. 7. Password 입력 안내받은 password를 입력하여 로그인합니다. 8. 파일 시스템 마운트 좌측 탭의 파일 모양 아이콘을 클릭하고 Open Folder 버튼을 클릭합니다. 기본적으로 user home directory 경로가 입력되어 있습니다. OK를 누릅니다. 9. 둘러보기   좌측 file explorer에서 파일을 관리합니다. Windows 탐색기나 MacOS Finder에서 drag\u0026amp;drop으로 파일을 옮길 수 있습니다. 클러스터 내부의 파일을 user의 local 컴퓨터로 가져오는 것도 drag\u0026amp;drop으로 가능합니다.\n  ctrl + shift + ~키를 누르면 터미널이 열립니다. 여기서 서버 사용에 필요한 커맨드를 입력합니다. 터미널은 여러 개 띄울 수 있습니다.\n  text editor에서 코드와 스크립트를 수정하고 이미지 파일 등을 열람합니다.\n  10. user password 변경 모든 user의 초기 password가 다 동일하기 때문에, 각 user는 첫 접속 시 password를 변경할 것을 권장합니다. 터미널에서 아래 커맨드를 입력하여 password를 변경합니다.\n1  passwd   Step 3. 파일 시스템 구조 이해 NAS(Network Attached Storage)에 각 user의 home directory가 있습니다. NAS는 모든 node에 마운트되어 있으며, 모든 node에서 user명과 group명 및 관련 설정이 동일합니다. User명은 컴퓨팅 클러스터 사용 신청시 제출하신 이메일 주소의 @ 앞 부분과 동일합니다.\nUser home directory의 prefix는 /mnt/nas/users/입니다. 예를 들어, dummyuser라는 user의 home directory의 경로는 /mnt/nas/users/dummyuser/입니다. 다른 user의 home directory를 열람할 수 없도록 권한설정이 되어 있습니다. 각 user는 데이터와 코드, 설정 파일 등을 자신의 home directory 내에 저장합니다.\n Linux에서 directory를 이동하는 명령어는 cd입니다. home directory를 나타내는 기호는 ~입니다. 현재 directory를 확인하는 명령어는 pwd입니다 파일 목록을 확인하는 명령어는 ls입니다.  따라서 user는 proxy node아래의 명령어를 통해 자신의 홈 directory로 이동해 그 안에 있는 파일 목록을 확인할 수 있습니다.\n1 2  cd ~ ls   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # with the tree command the home directory will typically look like this /mnt/nas/users/dummyuser/ ├── .bash_history ├── .bash_logout ├── .bashrc ├── .conda ├── .config ├── GettingStarted.md ├── .gnupg ├── .ipynb_checkpoints ├── .ipython ├── .jupyter ├── .local ├── logs ├── .npm ├── .profile ├── .python_history ├── some_script.sh ├── .ssh └── .viminfo   Step 4. Conda environment 생성  cpu-compute node에는 conda version 4.11.0이 설치되어 있으며 Python version을 3.10까지 지원합니다1. gpu-compute node에는 conda version 4.6.14가 설치되어 있으며 Python version을 3.8까지 지원합니다.  여기서는 cpu-compute node에서 conda environment를 생성하는 방법을 설명합니다. local에서 작성한 코드가 cpu-compute node에서 오류 없이 작동하도록 하기 위해, local과 cpu-compute node에서 동일한 conda environment를 구축해야 합니다.\n4.1. local에서 conda environment 생성 이 섹션의 작업은 모두 클러스터가 아니라 user의 local 컴퓨터에서 진행합니다.\nminiconda를 설치한 다음, local 컴퓨터의 터미널에서 아래 커맨드로 virtual environment를 설정합니다. testEnv 자리에 원하는 이름을 넣고, python= 뒤에 사용할 Python version을 명시합니다.\n1  conda create -n testEnv python=3.6   성공적으로 생성되면 아래와 같은 결과가 나옵니다.\n1 2 3 4 5 6 7 8 9 10 11  Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate testEnv # # To deactivate an active environment, use # # $ conda deactivate   아래 커맨드를 통해 virtual environment가 제대로 생성되었는지 확인합니다.\n1  conda info --env   1 2 3 4  # conda environments: # base * /opt/miniconda3 testEnv /opt/miniconda3/envs/testEnv   Virtual environment에 진입한 뒤 패키지를 설치합니다.\n pip로 설치되는 패키지들은 conda로 설치된 패키지에 대한 정보를 모르기 때문에 의존성 충돌이 발생할 수 있으므로 conda만을 사용해서 설치하실 것을 권장합니다. anaconda 웹사이트에서 패키지명을 검색해서 linux-64를 지원하는 버전이 어디까지인지를 확인하고 설치하는 것을 추천합니다. 이 사이트는 설치 커맨드도 제공합니다. 여러 패키지를 설치할 경우 한 커맨드 내에 명시하면 conda가 자동으로 dependency 충돌을 검사해 줍니다. 패키지 버전을 명시할 때는 =를 사용합니다.  1 2 3 4  conda activate testEnv #For example, conda install -c conda-forge lightgbm=2.0.7 matplotlib scikit-learn pandas numpy   아래 커맨드로 설치된 패키지 목록을 확인합니다.\n1  conda list   Environment를 지우려면 아래 커맨드를 입력합니다.\n1  conda remove --name testEnv --all   2. cpu-compute node에 local과 동일한 conda environment 구축하기  conda env export 커맨드를 이용해 environment 전체를 .yml 파일로 만들고 이를 이용해 cpu-compute 노드에서 environment를 구축하는 것이 동일한 environment를 만드는 가장 이상적인 방법입니다. 또는 설치된 패키지 목록과 버전만을 requirements.txt로 추출하여 노드에서 cpu-compute에서 설치할 수 있습니다. 그러나 이 두 방법은 user의 local 컴퓨터가 linux가 아니면 오류가 발생할 확률이 매우 높습니다. 이는 유저가 패키지를 설치할 때 자동으로 설치되는 dependency들의 버전이 OS별로 다를 수 있기 때문입니다.  예를 들어 lightgbm 2.0.7버전은 Python 버전이 3.6일 때 linux와 MacOS에서 둘 다 설치 가능하지만, 이 패키지의 dependency 중 하나인 libgfortran은 MacOS에서는 4.0.0버전이 설치되지만 linux에서는 3.0.0버전까지만 지원되기 때문에 MacOS에서 만든 environment에서 추출한 yml 파일이나 list txt 파일을 클러스터에서 사용하면 오류가 발생합니다2. 이 오류는 적절한 조치를 통해 해결할 수 있을 때도 있지만 해결하기 힘들 때도 있습니다.    따라서 local에서 만든 environment를 cluster로 옮기기보다는, local의 environment에서 사용하는 Python 버전과 중요 패키지들의 버전을 그대로 사용하여 cluster 내에서 environment를 생성하는 것을 추천하며, 이 문서에서는 그 절차를 안내합니다.\n  Conda environment 생성 slurm batch script를 작성합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #!/bin/bash #SBATCH --job-name=testEnv #SBATCH --nodes=1 #SBATCH --mem=4gb #SBATCH --partition=all #SBATCH --nodelist=cpu-compute #SBATCH --output=testEnv.log #SBATCH --error=testEnv.err CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnv #local에서와 같은 이름으로 입력 ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH #env가 이미 존재하면 삭제 $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.6 source $CONDA_BIN_PATH/activate $ENV_PATH conda install -y lightgbm=2.0.7 scikit-learn pandas numpy   위 내용에서\n 2번 라인의 #SBATCH \u0026ndash;job-name=testEnv의 job name 7번 라인의 #SBATCH \u0026ndash;output=testEnv.log의 output log 파일명 8번 라인의 #SBATCH \u0026ndash;error=testEnv.err의 error log 파일명 10번 라인의 environment name 13번 라인의 python version 14번 라인의 패키지 설치 커맨드 를 알맞게 수정하여 Visual Studio Code에서 작성한 뒤, 클러스터 내 user home directory에 [your_env_name].job으로 저장합니다.    작성한 스크립트 실행하기. Visual Studio Code 하단 터미널에\n1  sbatch [your_env_name].job   를 입력해 slurm batch job submission을 수행합니다. 작업이 노드에서 성공적으로 실행되면\n1  Submitted batch job 401   와 같은 메시지가 뜨고 job 번호가 할당됩니다. 할당되는 job 번호는 나중에 squeue를 통해 정보를 확인하거나 job을 취소할 때 이용되므로 기록해 놓아야 합니다.\n1  squeue   커맨드를 통해 작업 실행 현황을 확인할 수 있습니다.\n1 2  JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 402 all testEnv mjm R 0:01 1 cpu-compute   또는 아래 커맨드를 통해 실시간(1초 단위)으로 작업 실행 현황을 확인할 수 있습니다. ctrl+c로 escape 할 수 있습니다.\n1  smap -i 1   다음 커맨드를 통해 output log, error log파일의 내용을 확인할 수 있습니다.\n1 2  cat [your_job-name].log cat [your_job-name].err   log 파일의 내용을 다음 커맨드를 통해 실시간으로 확인할 수 있습니다. ctrl+c로 escape할 수 있습니다.\n1 2  tail -f [your_job_name].log tail -f [your_job_name].err   터미널을 여러 개 띄워 놓고 각각에 smap과 tail 커맨드를 입력하면 편리하게 실행 상황을 모니터링할 수 있습니다.\n위 샘플 코드는 약 3분 안에 작업이 완료됩니다. smap에서 작업 목록이 사라진 후 cat으로 로그 파일을 열어서\n1 2 3 4 5 6  pandas-1.1.3 | 10.5 MB | | 0% pandas-1.1.3 | 10.5 MB | #######1 | 71% pandas-1.1.3 | 10.5 MB | ########## | 100% Preparing transaction: ...working... done Verifying transaction: ...working... done Executing transaction: ...working... done   와 같은 기록이 남아 있으면 conda environment 생성이 완료된 것입니다.\n작업이 끝나기 전에 취소하려면 scancel 커맨드를 사용합니다.\n1  scancel [job_number]     Step 5. Slrum batch script 작성하여 서버에 제출하기 5.1. Python 코드 작성 이제 클러스터에서 실행할 Python 코드를 local에서 작성합니다. 코드가 오류 없이 작동하는지 local에서 확인합니다. 그 후 코드 파일을 user home directory에 옮기거나, Visual Studio Code내에서 작성하여 저장합니다.\n아래는 tree 기반 boosting 알고리즘인 LightGBM으로 mnist dataset을 분류하는 코드입니다. Boosting round를 10회 수행하고 학습 결과를 csv파일로 저장합니다3. Batch script를 작성할 때는 알고리즘의 output이 자동으로 저장되지 않으므로 파일로 결과를 저장하는 코드를 포함하는 것이 좋습니다. 단, 콘솔에 출력되는 내용은 output log에 자동으로 기록됩니다. 아래 코드를 python_test_cpu.py로 저장하여 user home directory에 둡니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  import numpy as np from time import process_time from lightgbm import LGBMClassifier from sklearn.metrics import accuracy_score, log_loss from sklearn.datasets import fetch_openml from sklearn.model_selection import train_test_split def lgb(n=10, c=0, sequence=1): mnist = fetch_openml(\u0026#39;mnist_784\u0026#39;) x_train, x_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.33, random_state=42) proba_test = np.zeros((n, y_test.shape[0], len(np.unique(y_test)))) proba_train = np.zeros((n, y_train.shape[0], len(np.unique(y_train)))) test_score = [] train_score = [] tr_time = [] seq = [] while(n): model = LGBMClassifier(n_estimators=sequence) t0 = process_time() model.fit(x_train, y_train) tr_time.append(process_time() - t0) test_score.append(accuracy_score(y_test, model.predict(x_test))) train_score.append(accuracy_score(y_train, model.predict(x_train))) proba_test[c, ] = model.predict_proba(x_test) proba_train[c, ] = model.predict_proba(x_train) seq.append(sequence) sequence *= 2 n -= 1 c += 1 ce_train = [] ce_test = [] for i in range(10): ce_test.append(log_loss(y_test, proba_test[i])) ce_train.append(log_loss(y_train, proba_train[i])) np.savetxt(\u0026#39;round\u0026#39;+ str(i) + \u0026#39;proba_test.csv\u0026#39;, proba_test[i]) np.savetxt(\u0026#39;round\u0026#39;+ str(i) + \u0026#39;proba_train.csv\u0026#39;, proba_train[i]) np.savetxt(\u0026#39;test_score.csv\u0026#39;, test_score, delimiter=\u0026#39;,\u0026#39;) np.savetxt(\u0026#39;train_score.csv\u0026#39;, train_score, delimiter=\u0026#39;,\u0026#39;) np.savetxt(\u0026#39;ce_test.csv\u0026#39;, ce_test, delimiter=\u0026#39;,\u0026#39;) np.savetxt(\u0026#39;ce_train.csv\u0026#39;, ce_train, delimiter=\u0026#39;,\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: lgb()   5.2. 현재 클러스터 자원 사용량 확인 아래 커맨드를 통해 cpu-compute 노드의 cpu와 RAM 사용 현황을 볼 수 있습니다.\n1  sinfo -o \u0026#34;%n %e %m %a %c %C\u0026#34;   아래와 같은 결과가 나옵니다.\n1 2 3  HOSTNAMES FREE_MEM MEMORY AVAIL CPUS CPUS(A/I/O/T) cpu-compute 105589 128916 up 32 0/32/0/32 gpu-compute 53318 80532 up 16 0/16/0/16    CPUS의 A/I/O/T는 allocated/idle/other/total을 의미합니다. 자신의 job이 바로 실행되기를 원한다면, Slurm batch script를 작성할 때  RAM 용량을 FREE_MEM보다 적게 설정해야 합니다. CPU 코어 개수를 CPUS idle보다 적게 설정해야 합니다.   현재 가용 자원보다 더 많은 자원을 요구하는 script를 작성하면, job이 바로 실행되지 않습니다. 대기 상태에 있다가 다른 user들의 job이 끝나고 자원이 반환되면 job이 실행됩니다.  5.3. Slurm batch script 작성 앞선 단계에서 만든 해당 conda environment를 activate하고 코드를 실행하는 Slurm batch script를 작성합니다. 클러스터 소개 페이지의 slurm job configurator를 사용하면 script를 쉽게 작성할 수 있습니다.\n Conda activate에 체크합니다. 빈칸들을 채웁니다. Script란에 python xxx.py라고 작성합니다. 이는 home directory에 있는 xxx.py 파일을 Python으로 실행하라는 의미입니다. Print \u0026amp; Copy 버튼을 누르면 내용이 클립보드에 복사됩니다.  Slurm batch script의 내용은 아래와 같습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #!/bin/bash # #SBATCH --job-name=python_test_cpu #SBATCH --partition=all #SBATCH --account=mjm #SBATCH --mem=4gb #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --time=01:00:00 #SBATCH --output=/mnt/nas/users/mjm/python_test_cpu.log #SBATCH --error=/mnt/nas/users/mjm/python_test_cpu.err #SBATCH --nodelist=cpu-compute CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnv ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME source $CONDA_BIN_PATH/activate $ENV_PATH python python_test_cpu.py   python_test_cpu.job이라는 이름으로 클러스터의 user home directory에 저장합니다.\nScript 윗부분의 #SBATCH 옵션들의 의미는 다음과 같습니다.\n —job-name: 수행할 작업의 이름 —mem: memory limit —nodelist: 작업할 노드의 이름 —ntasks: 작업의 수 —cpus-per-task: 각 작업에서 사용할 cpu 코어의 수 —time: 작업 제한시간 —account: 해당 작업을 수행하는 계정의 이름 —partition: group of nodes with specific characteristics \u0026ndash;nodelist: 사용할 node의 이름 —output: 코드 실행 결과 log 파일. 확장자는 out이나 log가 가능합니다. —error: 코드 실행 결과 log  sbatch에 대한 더 자세한 정보는 Slurm 공식 웹페이지를 참조하세요.\n5.4. Slurm batch script 실행 Conda environment를 만들 때처럼, sbatch 커맨드를 통해 job을 제출합니다. 할당되는 job 번호는 나중에 squeue를 통해 정보를 확인하거나 job을 취소할 때 이용되므로 기록해 놓아야 합니다.\nStep 4에서처럼, ctrl+shift+~를 눌러 터미널을 여러 개 띄우고 smap -i로 작업 현황을 확인하고, tail -f xxx.out, tail -f xxx.err으로 콘솔 출력이나 error를 확인합니다. 작업은 4분 정도 걸립니다.\n1  sbatch python_test_cpu.job   현재 작업이 자원을 얼마나 할당받았는지 확인하려면 다음 커맨드를 사용합니다. NumCPUs=4가 코어를 4개 할당받았다는 뜻이고, mem=4G가 RAM을 4gb 할당받았다는 뜻입니다. 이 커맨드는 다른 user가 제출한 job에 대해서도 사용할 수 있습니다.\n1  scontrol show job [job number]   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  UserId=mjm(1003) GroupId=mjm(1003) MCS_label=N/A Priority=4294901694 Nice=0 Account=mjm QOS=(null) JobState=RUNNING Reason=None Dependency=(null) Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:00:05 TimeLimit=01:00:00 TimeMin=N/A SubmitTime=2022-03-17T15:31:01 EligibleTime=2022-03-17T15:31:01 StartTime=2022-03-17T15:31:01 EndTime=2022-03-17T16:31:01 Deadline=N/A PreemptTime=None SuspendTime=None SecsPreSuspend=0 LastSchedEval=2022-03-17T15:31:01 Partition=all AllocNode:Sid=proxy:30897 ReqNodeList=cpu-compute ExcNodeList=(null) NodeList=cpu-compute BatchHost=cpu-compute NumNodes=1 NumCPUs=4 NumTasks=1 CPUs/Task=4 ReqB:S:C:T=0:0:*:* TRES=cpu=4,mem=4G,node=1,billing=4 Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=* MinCPUsNode=4 MinMemoryNode=4G MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 Gres=(null) Reservation=(null) OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) Command=/mnt/nas/users/mjm/python_test_cpu.job WorkDir=/mnt/nas/users/mjm StdErr=/mnt/nas/users/mjm/python_test_cpu.err StdIn=/dev/null StdOut=/mnt/nas/users/mjm/python_test_cpu.log Power=   Visual Stuio Code의 file explorer는 실시간으로 변화가 반영되지 않습니다. 새로고침 버튼을 눌러 주면 변화가 반영되고 output 파일이 explorer에 보입니다.\n더 알아보기 Submitting a slurm job script\nSLRUM Job Examples\nReferences   https://docs.conda.io/projects/conda/en/latest/release-notes.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://github.com/conda/conda/issues/9399\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.kaggle.com/samanemami/script-lightgbm-mnist\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/02_how-to-use-cpu-node_python/","summary":"CPU node에서 Python 코드 실행하기 Step 1 - terminal 앱 고르기 User는 SSH로 proxy node에 접속하여 클러스터를 사용합니다. 터미널 환경과 vi 에디터에 익숙한 user는 자신에게 친숙한 앱을 사용하면 됩니다. 그렇지 않은 경우 Visual Studio Code를 사용하는 것을 추천합니다. 이 문서에서는 Visual Studio Code를 사용하는 것을 전제로 합니다. 추천 이유는 다음과 같습니다.\n Windows, MacOS, Linux에서 모두 사용 가능합니다. 터미널과 에디터, 파일 브라우저가 통합되어 있습니다.  불편하게 vi나 nano등의 CLI용 텍스트 에디터를 사용할 필요가 없습니다.","title":"2. CPU node 사용법(Python)"},{"content":"요약 Chili Pepper는\n 총 세 개의 컴퓨터로 구성된 컴퓨팅 클러스터입니다. CPU node 하나, GPU node 하나, 그리고 이 둘을 관리하는 proxy node로 구성되어 있습니다. Slurm이라는 job scheduler로 여러 user의 작업을 각 node에 효율적으로 할당합니다. 각 user는 자신만의 conda environment를 스스로 생성하여 사용합니다. 기본적으로 non-interactive입니다. User가 자신의 로컬 컴퓨터에서 작성 및 테스트한 코드를 서버에 제출하면 서버가 해당 코드를 실행합니다. 주피터 노트북 환경은 실행 가능하지만, 꼭 필요한 경우에 한하여 요청 시 제공합니다. 이는 노트북 환경은 작업 단위가 아닌 시간 단위로 실행되기 때문에 서버의 RAM 자원을 지나치게 많이 점유하고 다른 작업의 실행을 방해하기 때문입니다. 파일은 위 세 컴퓨터와 별개의 NAS(Network Attached Storage)에 저장되며, 모든 컴퓨터에 마운트되어 있으므로 한번 클러스터 내로 옮긴 파일은 클러스터 내부에서 다시 옮길 필요가 없습니다.  1. 클러스터 구성 1. CPU node  Name: cpu-compute CPU: Intel® Xeon® Gold 5220 CPU @ 2.20GHz 32 cores RAM: 128GB OS: ubuntu 18.04.6 LTS conda version: 4.11.0  2. GPU node  Name: gpu-compute CPU: Intel® Xeon® Gold 5220 CPU @ 2.20GHz 16 cores GPU: NVIDIA® Tesla® T4 16GB x 2 RAM: 80GB OS: ubuntu 18.04.6 LTS conda version: 4.6.14 GPU driver version: 418.67  3. proxy node  Name: proxy CPU: Intel® Xeon® Gold 5220 CPU @ 2.20GHz 2 cores RAM: 4GB OS: ubuntu 18.04.6 LTS  특이사항   Intel® Xeon® Gold 5220 CPU @ 2.20GHz가 18코어 제품임에도 불구하고 세 컴퓨터에 각각 32코어, 16코어, 2코어로 장착되어 있는 것은 이 세 컴퓨터가 네이버 클라우드 플랫폼에서 호스팅되고 있기 때문입니다. 네이버 클라우드 플랫폼에서 각 컴퓨터에 정해진 코어 수를 할당합니다.\n  proxy node는 user가 로그인하여 job을 제출하기 위한 용도로만 쓰이는 컴퓨터이므로 성능이 낮습니다.\n  User는 proxy에만 접속할 수 있으며, cpu-compute와 gpu-compute에는 접속할 수 없습니다.\n  2. Slurm job scheduler Job scheduler HPC(High performance computing) 시스템은 개인용 컴퓨터와 달리 여러 user가 여러 node를 공유하며 사용합니다. 따라서 누구의 작업이 언제 어느 node에서 실행될지 결정해 주어야 합니다. 이러한 역할을 수행하는 것이 job scheduler입니다.\nJob scheduler를 식당의 웨이터에 비유할 수 있습니다. 식당에 사람이 많으면 줄을 서서 기다려야 합니다. 웨이터는 각 손님 그룹의 수에 맞는 자리가 나면 그 그룹을 테이블로 안내합니다1. 용어   Job: user가 클러스터에서 실행하고자 하는 코드(bash, python, R 등을 모두 포함)\n  Batch job submission: user가 미리 작성한 코드(output을 파일로 저장하는 내용 포함)를 scheduler에게 제출하여 non-interactive하게 서버에서 실행하는 것\n  Slurm Slurm(Simple Linux Utility for Resource Management)은 HPC에서 많이 채용하는 job scheduler입니다. 전 세계 TOP 500 슈퍼컴퓨터 중 60%가 slurm을 사용합니다2.\nSlurm은 각 user의 cpu사용량 등 다양한 통계를 기반으로 작업의 우선순위를 결정할 수 있습니다. 예를 들어, University of Toronto의 Computer Science Department의 HPC는 사용 CPU 코어 수 * 사용 시간(초) 값이 낮은 user의 job을 먼저 실행합니다. RAM 사용량은 0.25GB당 CPU 1코어 사용으로, GPU 사용량은 GPU 1개당 CPU 16코어 사용으로 환산합니다3.\n현재 Chili Pepper는 위와 같은 점수제가 아닌 FIFO(First In, First Out) 규칙을 사용하고 있습니다. 일정 기간 운영해본 뒤 상황에 맞추어 규칙을 변경할 예정입니다.\n3. Conda environment Virtual environment Virtual environment를 사용하면 한 컴퓨터 내에서 각 user가 독립적으로 Python 패키지를 관리할 수 있습니다. 또한, 여러 컴퓨터에서 동일한 환경을 구축하여 패키지 버전 차이로 인한 문제 발생을 방지할 수 있습니다4. 이는 특히 GPU driver, CUDA, cuDNN, 딥러닝 라이브러리의 버전 간 호환성이 중요한 딥러닝 job에서 유용합니다.\n여러 user가 node를 공유하는 HPC에서 virtual environment의 사용은 필수적입니다. 각 user는 자신의 로컬 컴퓨터와 동일한 Python 환경을 node 내에 구축합니다. 그리고 로컬 컴퓨터에서 코드를 작성하고 이상 없이 실행되는지 테스트합니다. 문제 없이 실행되는 것이 확인된 코드를 slurm을 통해 클러스터에서 실행합니다. Virtual environment는 로컬에서 작성한 코드가 클러스터에서 문제 없이 작동하는 것을 보장합니다.\nConda environment Chili Pepper는 conda를 이용해 virtual environment를 구현합니다. conda는 Windows, MacOS, Linux를 모두 지원합니다5.\nChili Pepper에서 Python job을 실행하기 위해서는 반드시 conda environment를 사용해야 합니다.\nReferences   https://epcced.github.io/hpc-intro/13-scheduler/index.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://wiki.hpc.odu.edu/en/slurm\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://support.cs.toronto.edu/systems/slurmresource.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.marquette.edu/high-performance-computing/py-venv.php\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://docs.conda.io/en/latest/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/01_intro/","summary":"요약 Chili Pepper는\n 총 세 개의 컴퓨터로 구성된 컴퓨팅 클러스터입니다. CPU node 하나, GPU node 하나, 그리고 이 둘을 관리하는 proxy node로 구성되어 있습니다. Slurm이라는 job scheduler로 여러 user의 작업을 각 node에 효율적으로 할당합니다. 각 user는 자신만의 conda environment를 스스로 생성하여 사용합니다. 기본적으로 non-interactive입니다. User가 자신의 로컬 컴퓨터에서 작성 및 테스트한 코드를 서버에 제출하면 서버가 해당 코드를 실행합니다. 주피터 노트북 환경은 실행 가능하지만, 꼭 필요한 경우에 한하여 요청 시 제공합니다.","title":"1. Introduction"},{"content":"1. What is SLURM? Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for its operation and is relatively self-contained.\nIf you need more information, Please Visit https://slurm.schedmd.com/overview.html\n2. Basic SLURM Command   sbatch\n Submit a batch script to SLURM  1 2 3 4  $ sbatch [YOUR_SCRIPT] # output \u0026gt; Submitted batch job 210 # job_id: 210     squeue\n View the queue  1 2 3 4 5  $ squeue # output \u0026gt; JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 210 all test1 ghk R 0:29 1 cpu-compute     scancel\n Cancel a SLURM job  1  $ scancel [YOUR_JOBID]     sinfo\n See the state of system  1 2 3 4 5  $ sinfo # output \u0026gt; PARTITION AVAIL TIMELIMIT NODES STATE NODELIST all* up infinite 2 idle cpu-compute,gpu-compute     smap\n graphically view information about SLURM job    For more information about SLURM command, please visit website below.\n  SLURM Workload Manager\n  SLURM Command Cheatsheet\n  SLURM Reference Sheet(NeSI)\n  Submit your first job(NeSI)\n  3. How to make SLURM batch script? \u0026lsquo;Job submission file\u0026rsquo; is the official SLURM name for the file you use to submit your program and ask for resources from the job scheduler. In this document, we will be using it ‘batch script’ or ‘script’.\nBasic example 1 2 3 4 5 6 7  #!/bin/bash #  # SBATCH --job-name=basic # SBATCH --mem=1gb # SBATCH --ntasks=1 # SBATCH --time=01:00 # SBATCH --output=/mnt/nas/users/testuser/basic.log   Asking 1 tasks, running for no more than 1 minutes limit memory less than 1gb. If any problem with your job, log file(in this case, \u0026lsquo;basic.log\u0026rsquo;) have information to help troubleshoot the issue.\nYou can also use gpu-nodes by using \u0026lsquo;—gres\u0026rsquo; option. Here is an example.\n1 2 3 4 5 6 7 8 9 10 11  #!/bin/bash #  #SBATCH --job-name=basic #SBATCH --nodes=1 #SBATCH --gres=gpu:2 # max : 2 #SBATCH --time=01:00 #SBATCH --account=testuser #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/testuser/torch.log source activate /opt/miniconda/envs/pytorch \u0026amp;\u0026amp; python /mnt/nas/users/testuser/main.py   1 2 3 4 5 6 7 8 9 10  # main.py import torch print(\u0026#39;is cuda avaiable? \u0026#39;, torch.cuda.is_available()) print(\u0026#39;how many cuda devices? \u0026#39;,torch.cuda.device_count()) print(\u0026#39;get first cuda device name =\u0026gt; \u0026#39;, torch.cuda.get_device_name(0)) print(\u0026#39;*** MEMORY INFO ***\u0026#39;) t = torch.cuda.get_device_properties(0).total_memory print(\u0026#39;total memory =\u0026gt; \u0026#39;, t) print(\u0026#39;total memory: \u0026#39;, t)   The job can then be submitted through sbatch\n1 2 3 4 5 6 7  $ sbatch basic.sh $ cat torch.log \u0026gt; is cuda avaiable? True \u0026gt; how many cuda devices? 2 \u0026gt; get first cuda device name =\u0026gt; Tesla T4 \u0026gt; ***MEMORY INFO*** \u0026gt; total memory =\u0026gt; 16879583232   Beacuse we only have 2 gpu machine, this option can’t be set more than 2\nFor the convenience of users, we provide SLURM job configurator page in our website. Please visit SLURM job configurator and make your own SLURM batch script!\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/slurm-documentation/","summary":"1. What is SLURM? Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for its operation and is relatively self-contained.\nIf you need more information, Please Visit https://slurm.schedmd.com/overview.html\n2. Basic SLURM Command   sbatch\n Submit a batch script to SLURM  1 2 3 4  $ sbatch [YOUR_SCRIPT] # output \u0026gt; Submitted batch job 210 # job_id: 210     squeue","title":"SLURM Documentation"},{"content":"Intro This documentation will go over the basics of using the Chili Pepper cluster. Please go through this documentation step-by-step. Contact the server administrator via email or use the Q\u0026amp;A channel in the Slack Group.\nStep 1 - Understanding the Cluster Structure Chili Pepper cluster has a NAS which contains user home directories and other shared files. All users and groups are consistent across all nodes. The prefix for the user directory is /mnt/nas/users/. For example, the home directory for the user dummyuser will be /mnt/nas/users/dummyuser/. The home directory is the recommended directory for users to store scripts, data and configuration files for using the Chili Pepper cluster.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # with the tree command the home directory will typically look like this /mnt/nas/users/dummyuser/ ├── .bash_history ├── .bash_logout ├── .bashrc ├── .conda ├── .config ├── GettingStarted.md ├── .gnupg ├── .ipynb_checkpoints ├── .ipython ├── .jupyter ├── .local ├── logs ├── .npm ├── .profile ├── .python_history ├── some_script.sh ├── .ssh └── .viminfo   Step 2 - Data Transfer With cluster access information(SSH) provided by the administrator, you can send and recieve files from and to the cluster with scp. The dummyuser can send various local files to the cluster in the following fashion. Note that for security purposes the default port for SSH is not 22. The administrator will inform you of this information upon providing access information to the cluster.\nSending a local file(some_file.txt) to the remote home directory 1  scp some_file.txt dummyuser@hpc.stat.yonsei.ac.kr:~/   Sending a local directory(some_files/) to the remote home directory 1 2  scp -r some_files dummyuser@hpc.stat.yonsei.ac.kr:~/ # /mnt/nas/users/dummyuser/some_files/ will be created   Recieving a remote file(some_file.txt) in the home directory to the current local directory 1  scp dummyuser@hpc.stat.yonsei.ac.kr:~/some_file.txt   Recieving a remote directory(/mnt/nas/users/dummyuser/some_files) in the home directory to the current local directory 1  scp -r dummyuser@hpc.stat.yonsei.ac.kr:~/some_files ./   Other various options for scp exist. More information on this topic can be found in this article. Also users can use GitHub or GitLab to upload and download source code to the cluster. This will be handled in a seperate article.\nStep 3 - Writing a SBATCH script for SLURM. From the homepage the SLURM batch scripting tool is available. Let\u0026rsquo;s look at the sample script(/mnt/nas/users/dummyuser/test_script.sh) created by using the tool. The first-half(line 1 ~ 11) of the script consists of directives and parameters for the slurm job. Each user can set the number of nodes, the time for the job to occupy the number of nodes, the location for the output logfile. There are more options available for submitting a job. Additional resources for SBATCH arguments can be found here.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/bin/bash # The interpreter used to execute the script #“#SBATCH” directives that convey submission options: #SBATCH --job-name=conda-env-create #SBATCH --nodes=1 #SBATCH --time=15:00 #SBATCH --account=dummyuser #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/dummyuser/conda.log # The application(s) to execute along with its input arguments and options: CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=myenv ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8 pandas numpy scikit-learn source $CONDA_BIN_PATH/activate $ENV_PATH \u0026amp;\u0026amp; pip freeze   From line 15 to the end of the script are actual bash commands for the node to execute.\n Line 15~16 creates two local variables(ENV_NAME and ENV_PATH). In the above script a conda environment named myenv will be created under /mnt/nas/users/dummyuser/.conda/envs/myenv. Line 18 will remove the environment in ENV_PATH if it is present. Line 19 will create a conda environment in ENV_PATH thanks to the -y(--yes) flag. This environment will have a Python interpreter of version 3.8 along with listed packages(pandas, numpy and scikit-learn). Line 20 will activate the conda environment in ENV_PATH and then sequentially run a pip freeze to the stdout. Note that the stdout is saved in the log file from line 11(/mnt/nas/users/dummyuser/conda.log).  To actually run a data science job, the only thing you have to do is to change the required packages for your environment, modify the pip freeze into python your_script_to_run.py.\nStep 4 - Submitting the script The submission of the script from the above is very simple.\n1  sbatch test_script.sh   You can check the current job queue with the following command.\n1  squeue   When you want to cancel the job you have submitted, get the JOBID from the squeue command and use the scancel command in the following fashion. Suppose the JOBID is 23.\n1  scancel 23   Note that ordinary users cannot cancel jobs that belong to other users, but the administrator can.\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/using-slurm-copy/","summary":"Intro This documentation will go over the basics of using the Chili Pepper cluster. Please go through this documentation step-by-step. Contact the server administrator via email or use the Q\u0026amp;A channel in the Slack Group.\nStep 1 - Understanding the Cluster Structure Chili Pepper cluster has a NAS which contains user home directories and other shared files. All users and groups are consistent across all nodes. The prefix for the user directory is /mnt/nas/users/.","title":"How do I use the Chili Pepper Cluster?"},{"content":"Creating a Python Kernel Admin Prerequisite Admin must enable conda for all users by creating a symlink. This will let users create their own virtual environment by using the conda create command.\n1  ln -s /opt/conda/bin/conda /usr/local/bin/conda   User Instructions Python  Users can launch a terminal session with either JupyterHub or SSH connections. Launch a bash session.  1  bash   Users then can create a virtual environment in the following way. Note that specifying ipykernel package will make the user easily create jupyter kernels from that environment. Also users can create virtual environments with various python versions(3.6 ~ 3.9). Activate the environment. If any warnings occur, read the warning and do the recommended procedure. Most of the time you will need to refresh your shell with bash.  1 2 3 4 5 6 7 8  # create environemnt conda create -n NAME_OF_VIRTUAL_ENV python=3.8 ipykernel # refresh your shell bash # activate environemnt conda activate NAME_OF_VIRTUAL_ENV   Install packages via pip.  1 2 3 4 5  # directly pip install PACKAGE_NAME # requirements.txt pip install -r YOUR_REQUIREMENTS.txt   Add the virtual environment as a kernel. This will be only available to each user.  1  python -m ipykernel install --user --name NAME_OF_VIRTUAL_ENV --display-name \u0026#34;[displayKenrelName]\u0026#34;   R  Launch a bash session via JupyterHub or SSH.  1  bash   Users then can create a virtual environment in the following way.  1 2 3 4 5 6 7 8  # create environemnt conda create -n NAME_OF_VIRTUAL_ENV r-essentials r-base r-irkernel # refresh your shell bash # activate environemnt conda activate NAME_OF_VIRTUAL_ENV   Install packages via install.packages().  1 2  # directly Rscript -e \u0026#39;install.packages(c(\u0026#34;dplyr\u0026#34;))\u0026#39;   Add the virtual environment as a kernel. This will be only available to each user.  1  Rscript -e \u0026#34;IRkernel::installspec(name=\u0026#39;myRkernel\u0026#39;, displayname=\u0026#39;My R Kernel\u0026#39;)\u0026#34;   Removing Kernels To remove kernels use the jupyter command in terminal.\nView your current kernel list with the following command from a bash terminal.\n1  jupyter kernelspec list   Remove kernel with the following command.\n1  jupyter kernelspec remove KERNELNAME   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/configuring-jupyter-kernel/","summary":"Creating a Python Kernel Admin Prerequisite Admin must enable conda for all users by creating a symlink. This will let users create their own virtual environment by using the conda create command.\n1  ln -s /opt/conda/bin/conda /usr/local/bin/conda   User Instructions Python  Users can launch a terminal session with either JupyterHub or SSH connections. Launch a bash session.  1  bash   Users then can create a virtual environment in the following way.","title":"Creating Your Custom Jupyter Kernel from a Virtual Environment"}]