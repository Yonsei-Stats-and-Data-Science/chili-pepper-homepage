[{"content":"5. iOSì—ì„œ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©í•˜ê¸° 2ë²ˆ ë¬¸ì„œì—ì„œ ì„¤ëª…í–ˆë“¯ì´, ì–´ëŠ í™˜ê²½ì—ì„œë“  SSH ì ‘ì†ë§Œ ê°€ëŠ¥í•˜ë‹¤ë©´ í´ëŸ¬ìŠ¤í„° ì´ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” iPadì—ì„œ koderë¼ëŠ” ì•±ì„ ì´ìš©í•´ í´ëŸ¬ìŠ¤í„°ë¥¼ ì´ìš©í•˜ëŠ” ì˜ˆì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.\n1. íŒŒì¼ ì‹œìŠ¤í…œ ì ‘ì† í´ëŸ¬ìŠ¤í„°ì˜ íŒŒì¼ ì‹œìŠ¤í…œì— ì ‘ì†í•˜ì—¬ íŒŒì¼ì„ ì—´ëŒí•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì¢Œì¸¡ ìƒë‹¨ì˜ 2ë²ˆì§¸ ì•„ì´ì½˜ì„ í´ë¦­í•˜ì—¬ FTP/SFTP ì„¤ì •ìœ¼ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. ì¢Œì¸¡ í•˜ë‹¨ì˜ + ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ New FTP Connection ì„¤ì • ì°½ì´ ë‚˜ì˜µë‹ˆë‹¤.  3. ì•„ë˜ ë‚´ìš©ì„ ì…ë ¥í•œ ë‹¤ìŒ Createë¥¼ ëˆ„ë¦…ë‹ˆë‹¤.\n  ë¨¼ì €, Connectionì„ SFTPë¡œ ë°”ê¿‰ë‹ˆë‹¤.\n  Nameì€ ì´ connection ì„¤ì •ì˜ ì´ë¦„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì›í•˜ëŠ” ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n  Host Nameì— hpc.stat.yonsei.ac.krì„ ì…ë ¥í•©ë‹ˆë‹¤.\n  Username, Passwordì— linux username, passwordë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.\n  Portì— Slackì—ì„œ ì•ˆë‚´í•œ SSH í¬íŠ¸ë²ˆí˜¸ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.\n  í™”ë©´ ì¢Œì¸¡ íƒ­ì— connectionì´ ìƒì„±ë©ë‹ˆë‹¤.   í™”ë©´ ì¢Œì¸¡ íƒ­ì— connectionì´ ìƒì„±ë©ë‹ˆë‹¤. ì´ë¥¼ í´ë¦­í•˜ì—¬ ì ‘ì†í•©ë‹ˆë‹¤.\n  User home directoryì˜ íŒŒì¼ë“¤ì´ ë‚˜ì˜µë‹ˆë‹¤. íŒŒì¼ì„ í´ë¦­í•˜ë©´ ì˜¤ë¥¸ìª½ì˜ í…ìŠ¤íŠ¸ ì—ë””í„° ì°½ì— ë‚´ìš©ì´ í‘œì‹œë©ë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ ìˆ˜ì •í•œ ë’¤ ì €ì¥í•˜ë ¤ë©´ ìš°ì¸¡ íƒ­ ìƒë‹¨ì— ìˆëŠ” ì—…ë¡œë“œ ëª¨ì–‘ ì•„ì´ì½˜ì„ ëˆ„ë¦…ë‹ˆë‹¤.   2. SSH ì ‘ì† ì»¤ë§¨ë“œë¥¼ ì…ë ¥í•˜ê³  jobì„ ì œì¶œí•˜ë ¤ë©´ SSHë¡œ ì ‘ì†í•´ì•¼ í•©ë‹ˆë‹¤.\n  ì¢Œì¸¡ íƒ­ í•˜ë‹¨ì˜ ì½˜ì†” ëª¨ì–‘ ì•„ì´ì½˜ì„ í´ë¦­í•˜ì—¬ SSH ì ‘ì† ì ˆì • ì°½ì„ ì—½ë‹ˆë‹¤.   ì•„ë˜ ì‚¬ì§„ì„ ì°¸ê³ í•˜ì—¬ ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  **Connect*ë¥¼ ëˆ„ë¦…ë‹ˆë‹¤.\n ë§¨ ìœ„ì—ëŠ” hpc.stat.yonsei.ac.krì„ ì…ë ¥í•©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒ ì¹¸ì—ëŠ” linux usernameì„ ì…ë ¥í•©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒ ì¹¸ì—ëŠ” linux user passwordë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒ ì¹¸ì—ëŠ” Slackì—ì„œ ê³µì§€í•œ SSH í¬íŠ¸ë²ˆí˜¸ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.    SSHë¡œ proxy nodeì— ì ‘ì†ë˜ê³  í„°ë¯¸ë„ í™˜ê²½ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ì´ì œ Visual Studio Codeì—ì„œ í–ˆë˜ ê²ƒì²˜ëŸ¼ í´ëŸ¬ìŠ¤í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/05_ipad/","summary":"5. iOSì—ì„œ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©í•˜ê¸° 2ë²ˆ ë¬¸ì„œì—ì„œ ì„¤ëª…í–ˆë“¯ì´, ì–´ëŠ í™˜ê²½ì—ì„œë“  SSH ì ‘ì†ë§Œ ê°€ëŠ¥í•˜ë‹¤ë©´ í´ëŸ¬ìŠ¤í„° ì´ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” iPadì—ì„œ koderë¼ëŠ” ì•±ì„ ì´ìš©í•´ í´ëŸ¬ìŠ¤í„°ë¥¼ ì´ìš©í•˜ëŠ” ì˜ˆì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.\n1. íŒŒì¼ ì‹œìŠ¤í…œ ì ‘ì† í´ëŸ¬ìŠ¤í„°ì˜ íŒŒì¼ ì‹œìŠ¤í…œì— ì ‘ì†í•˜ì—¬ íŒŒì¼ì„ ì—´ëŒí•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì¢Œì¸¡ ìƒë‹¨ì˜ 2ë²ˆì§¸ ì•„ì´ì½˜ì„ í´ë¦­í•˜ì—¬ FTP/SFTP ì„¤ì •ìœ¼ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. ì¢Œì¸¡ í•˜ë‹¨ì˜ + ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ New FTP Connection ì„¤ì • ì°½ì´ ë‚˜ì˜µë‹ˆë‹¤.  3. ì•„ë˜ ë‚´ìš©ì„ ì…ë ¥í•œ ë‹¤ìŒ Createë¥¼ ëˆ„ë¦…ë‹ˆë‹¤.\n  ë¨¼ì €, Connectionì„ SFTPë¡œ ë°”ê¿‰ë‹ˆë‹¤.","title":"5. iOSì—ì„œ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©í•˜ê¸°"},{"content":"4. GPU nodeì—ì„œ Python ì½”ë“œ ì‹¤í–‰í•˜ê¸° 2ë²ˆ ë¬¸ì„œë¥¼ ë¨¼ì € ìˆ™ì§€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” 2ë²ˆ ë¬¸ì„œì˜ Step 1, 2, 3 ì´í›„ì˜ ë‚´ìš©ë§Œì„ ë‹¤ë£¹ë‹ˆë‹¤.\ngpu-compute nodeì—ì„œëŠ” Pythonë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\nStep 4. Export your conda setting ë²„ì „ ê´€ë¦¬ ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ë•Œì—ëŠ” ë²„ì „ ê´€ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.\n GPU ë“œë¼ì´ë²„ ë²„ì „(418.67) Python ë²„ì „ CUDA ë²„ì „(í˜¸í™˜ì„± í‘œ) cuDNN, ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬(tensorflow, pytorch) ë²„ì „(í˜¸í™˜ì„± í‘œ: tensorflow, pytorch)  ì´ë“¤ì˜ ë²„ì „ ê°„ í˜¸í™˜ì´ ë˜ëŠ” ì¡°í•©ì„ ìˆ™ì§€í•˜ê³  ì´ì— ë”°ë¼ conda environmentë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. gpu-compute nodeì˜ GPU ë“œë¼ì´ë²„ ë²„ì „ì€ 418.67ìœ¼ë¡œ ê³ ì •ë˜ì–´ ìˆì§€ë§Œ, ë‚˜ë¨¸ì§€ ìš”ì†Œë“¤ì˜ ë²„ì „ì€ conda environmentë§ˆë‹¤ ë‹¤ë¥´ê²Œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¨, Python ë²„ì „ì˜ ê²½ìš° gpu-compute nodeì—ëŠ” conda version 4.6.14ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ 3.8ê¹Œì§€ë§Œ ì§€ì›í•©ë‹ˆë‹¤.\nGPU ë“œë¼ì´ë²„ ë²„ì „(418.67)ì— ë§ëŠ” Python ë²„ì „ê³¼ ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ ì •í•œ ë‹¤ìŒ conda create ëª…ë ¹ì–´ì—ì„œ ë²„ì „ì„ ëª…ì‹œí•´ ì£¼ë©´ ì•Œì•„ì„œ CUDAì™€ cuDNN ë²„ì „ì„ ë§ì¶° ì¤ë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œëŠ” ì´ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\nì´ ë¬¸ì„œì—ì„œ ì‚¬ìš©í•˜ëŠ” ë²„ì „ì€ tensorflow-gpu-2.2.0ì…ë‹ˆë‹¤.\n1. localì—ì„œ conda environment ìƒì„± 2ë²ˆ ë¬¸ì„œì˜ step 4ì˜ ë‚´ìš©ì— ë”°ë¼ localì—ì„œ conda environmentë¥¼ ìƒì„±í•©ë‹ˆë‹¤. conda listë¡œ CUDA, cudnn ë²„ì „ì„ í™•ì¸í•©ë‹ˆë‹¤.\n2. gpu-compute nodeì—ì„œ ë™ì¼í•œ conda environment êµ¬ì¶• ë‘ ê°€ì§€ ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.\n2.1. ì¤‘ìš” íŒ¨í‚¤ì§€ì˜ ë²„ì „ë§Œ ë§ì¶”ê¸° 2ë²ˆ ë¬¸ì„œì—ì„œ í•œ ê²ƒì²˜ëŸ¼ tensorflow ë“±ì˜ ë²„ì „ë§Œ ë™ì¼í•˜ê²Œ í•˜ì—¬ gpu-compute nodeì—ì„œ conda createë¡œ conda environmentë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n ì´ ë°©ë²•ì€ 2ë²ˆ ë¬¸ì„œì˜ ì•ˆë‚´ë¥¼ ë”°ë¼ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì„¤ëª…ì„ ìƒëµí•˜ê³  sbatch scriptë§Œ ì œì‹œí•©ë‹ˆë‹¤. Slurm job configuratorì—ì„œ Using GPUì— ì²´í¬í•œë‹¤ëŠ” ì ë§Œ ë‹¤ë¦…ë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œ ì‚¬ìš©í•˜ëŠ” ë²„ì „ì€ tensorflow-gpu-2.2.0ì…ë‹ˆë‹¤.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #!/bin/bash #SBATCH --job-name=testEnvGPU #SBATCH --nodes=1 #SBATCH --mem=4gb #SBATCH --partition=all #SBATCH --nodelist=gpu-compute #SBATCH --output=testEnvGPU.log #SBATCH --error=testEnvGPU.err CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnvGPU #localì—ì„œì™€ ê°™ì€ ì´ë¦„ìœ¼ë¡œ ì…ë ¥ ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.7 source $CONDA_BIN_PATH/activate $ENV_PATH conda install -y tensorflow-gpu=2.2.0   cudatoolkit, cudnn ë“±ì´ ìš©ëŸ‰ì´ ì»¤ì„œ ì‹œê°„ì´ ì¡°ê¸ˆ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.\n2.2. local environment exportí•˜ê¸° Localì—ì„œ ìƒì„±ëœ ê°€ìƒí™˜ê²½ìœ¼ë¡œë¶€í„° í™˜ê²½ì„¤ì • yml íŒŒì¼ì„ ë§Œë“¤ê³ , ì´ë¥¼ ì´ìš©í•´ gpu-compute nodeì—ì„œ conda environmentë¥¼ ìƒì„±í•˜ì—¬ conda í™˜ê²½ì„ ë™ì¼í•˜ê²Œ ë§ì¶œ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ê²Œ ê°€ì¥ ì´ìƒì ì¸ ë°©ë²•ì´ì§€ë§Œ, local OSê°€ linuxê°€ ì•„ë‹ ê²½ìš° ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œëŠ” ì´ ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\nLocalì—ì„œ ì•„ë˜ ì»¤ë§¨ë“œë¡œ yml íŒŒì¼ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n1 2 3  # export conda setting conda activate [YOUR ENV NAME] conda env export -n [ENV NAME] -f [FILENAME].yml --no-builds # ì´ëŸ¬ë©´ ë¬¸ì œê°€ í•´ê²°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.   yml íŒŒì¼ì„ í´ëŸ¬ìŠ¤í„° ë‚´ user home directoryë¡œ ì˜®ê¸°ê³  ì•„ë˜ ì»¤ë§¨ë“œë¥¼ slurm job scriptì— ì¶”ê°€í•˜ê³  sbatchë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ ë•Œ Slurm job configuratorì—ì„œ Using GPUì— ì²´í¬í•´ì•¼ í•©ë‹ˆë‹¤.\n1 2 3 4 5 6  # create environment from file conda create --name [YOUR ENV NAME] python = [VESTION] # same env name in yml file conda env create -f [FILENAME].yml conda env create -p [prefix path] -f [filename].yml   â€”no-builds ì˜µì…˜ì€ ì„œë¡œ ë‹¤ë¥¸ OSì—ì„œ conda environment ë‚´ íŒ¨í‚¤ì§€ë“¤ì˜ ë²„ì „ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤. ì´ ì˜µì…˜ë§Œìœ¼ë¡œ ë¬¸ì œê°€ í•´ê²°ë˜ê¸°ë„ í•˜ì§€ë§Œ, í•´ê²°ë˜ì§€ ì•Šìœ¼ë©´ userê°€ ì§ì ‘ yml íŒŒì¼ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì—ëŸ¬ ë©”ì‹œì§€ì— ResolvePackageNotFoundë¼ëŠ” ë¬¸êµ¬ê°€ ë‚˜ì˜¤ëŠ”ë°, ì´ ë¬¸êµ¬ ì•„ë˜ì˜ íŒ¨í‚¤ì§€ë“¤ì„ yml íŒŒì¼ì—ì„œ ì‚­ì œí•´ì£¼ë©´ ë¬¸ì œê°€ í•´ê²°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  conda env create -f test.yml Collecting package metadata: done Solving environment: failed # yml íŒŒì¼ì—ì„œ ì•„ë˜ì— ë“±ì¥í•˜ëŠ” íŒ¨í‚¤ì§€ë“¤ì„ ì§€ì›Œì¤ë‹ˆë‹¤. ResolvePackageNotFound: - libgfortran==3.0.1=h93005f0_2 # --no-builds ì˜µì…˜ì„ ì“°ë©´ íŒ¨í‚¤ì§€ ë²„ì „ ì˜†ì˜ ë¹Œë“œ ì •ë³´ê°€ ë‚˜ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤. - pyzmq==17.0.0=py36h1de35cc_1 - python==3.6.6=h4a56312_1003 - prompt_toolkit==1.0.15=py36haeda067_0 - libiconv==1.15=h1de35cc_1004 - sqlite==3.25.3=ha441bb4_0 - six==1.11.0=py36h0e22d5e_1 - cryptography==2.3.1=py36hdbc3d79_1000 - openssl==1.0.2p=h1de35cc_1002 - libxml2==2.9.8=hf14e9c8_1005 - libcxxabi==4.0.1=hebd6815_0 - matplotlib==2.2.3=py36h0e0179f_0 - ptyprocess==0.5.2=py36he6521c3_0    ğŸ’¡ `yml` fileì„ ì´ìš©í•œ conda í™˜ê²½ ì„¤ì •ì€ ë¡œì»¬ê³¼ ì„œë²„ ì‘ì—… í™˜ê²½ì„ ë™ì¼í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ì§€ë§Œ, conda í™˜ê²½ ì„¤ì • ê³¼ì •ì´ ë„ˆë¬´ ë²ˆê±°ë¡­ë‹¤ë©´ requirements.txtë¥¼ ë§Œë“¤ì–´ íŒ¨í‚¤ì§€ ë²„ì „ë§Œ ê´€ë¦¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  1 2 3 4 5 6 7  conda install --force-reinstall -y -q -c conda-forge --file requirements.txt # --force-reinstall : Install the package even if it already exists. # -y : Yes, do not ask for confirmation. # -q : Quiet, do not display progress bar. # -c : Channels, additional channels to search for packages # conda-forge is recommended   Step 5. Slrum batch script ì‘ì„±í•˜ì—¬ ì„œë²„ì— ì œì¶œí•˜ê¸° 1. Python ì½”ë“œ ì‘ì„± ì´ì œ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰í•  Python ì½”ë“œë¥¼ localì—ì„œ ì‘ì„±í•©ë‹ˆë‹¤. ë¨¼ì € localì—ì„œ ì½”ë“œê°€ ì˜¤ë¥˜ ì—†ì´ ëŒì•„ê°€ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ê·¸ í›„ í´ëŸ¬ìŠ¤í„°ì˜ user home directoryì— ì˜®ê¸°ê±°ë‚˜, Visual Studio Codeë‚´ì—ì„œ ì‘ì„±í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\nì•„ë˜ëŠ” TensorFlow ê³µì‹ í˜ì´ì§€ì— ê²Œì‹œëœ ì´ˆë³´ììš© ë¬¸ì„œ ì½”ë“œì…ë‹ˆë‹¤. Batch scriptë¥¼ ì‘ì„±í•  ë•ŒëŠ” ì•Œê³ ë¦¬ì¦˜ì˜ outputì´ ìë™ìœ¼ë¡œ ì €ì¥ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ íŒŒì¼ë¡œ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì½”ë“œë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì•„ë˜ ì½”ë“œì—ëŠ” ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì½”ë“œëŠ” ì—†ì§€ë§Œ, tensorflowê°€ í•™ìŠµ ê³¼ì •ì„ ì½˜ì†”ì— ì¶œë ¥í•˜ê¸° ë•Œë¬¸ì— ì´ë¥¼ ë¡œê·¸ íŒŒì¼ì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ tensor.pyë¼ëŠ” ì´ë¦„ìœ¼ë¡œ user home directoryì— ì €ì¥í•©ë‹ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # tensor.py import tensorflow as tf mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation=\u0026#39;relu\u0026#39;), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;) ]) model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;sparse_categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(x_train, y_train, epochs=5) model.evaluate(x_test, y_test, verbose=2)   2. í˜„ì¬ í´ëŸ¬ìŠ¤í„° ìì› ì‚¬ìš©ëŸ‰ í™•ì¸ gpu-computeì˜ ì—¬ìœ  cpu ì½”ì–´ ê°œìˆ˜ì™€ RAMì€ ë¬¸ì„œ22ë²ˆ ë¬¸ì„œì— ìˆëŠ” ë°©ë²•ì„ í†µí•´ í™•ì¸í•©ë‹ˆë‹¤. GPUì˜ ê²½ìš° í•œ userê°€ í•˜ë‚˜ì˜ GPUë§Œì„ ì‚¬ìš©í•˜ë„ë¡ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ gpu-compute nodeëŠ” ìµœëŒ€ 2ëª…ì˜ userê°€ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. squeue ì»¤ë§¨ë“œë¥¼ í†µí•´ gpu-compute nodeì—ì„œ ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ì‹¤í–‰ ëŒ€ê¸° ì¤‘ì¸ jobì˜ ê°œìˆ˜ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.\n3. Slurm batch script ì‘ì„± ì•ì„  ë‹¨ê³„ì—ì„œ ë§Œë“  í•´ë‹¹ conda environmentë¥¼ activateí•˜ê³  ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” Slurm batch scriptë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° ì†Œê°œ í˜ì´ì§€ì˜ slurm job configuratorë¥¼ ì‚¬ìš©í•˜ë©´ scriptë¥¼ ì‰½ê²Œ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n Conda activateì— ì²´í¬í•©ë‹ˆë‹¤. Using GPUì— ì²´í¬í•©ë‹ˆë‹¤. ë¹ˆì¹¸ë“¤ì„ ì±„ì›ë‹ˆë‹¤. Scriptë€ì— python xxx.pyë¼ê³  ì‘ì„±í•©ë‹ˆë‹¤. ì´ëŠ” home directoryì— ìˆëŠ” xxx.py íŒŒì¼ì„ Pythonìœ¼ë¡œ ì‹¤í–‰í•˜ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. Print \u0026amp; Copy ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë‚´ìš©ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë©ë‹ˆë‹¤.  ì´ ë¬¸ì„œì—ì„œ ì‚¬ìš©í•œ Slurm batch scriptì˜ ë‚´ìš©ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/bin/bash # #SBATCH --job-name=tensor #SBATCH --partition=all #SBATCH --account=mjm #SBATCH --mem=16gb #SBATCH --ntasks=1 #SBATCH --cpus-per-task=8 #SBATCH --time=00:30:00 #SBATCH --output=/mnt/nas/users/mjm/tensor.log #SBATCH --error=/mnt/nas/users/mjm/tensor.err #SBATCH --gres=gpu:1 #SBATCH --nodelist=gpu-compute CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnvGPU ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME source $CONDA_BIN_PATH/activate $ENV_PATH python tensor.py   tensor.jobì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ì˜ user home directoryì— ì €ì¥í•©ë‹ˆë‹¤.\nsbatchì— ëŒ€í•œ ë” ìì„¸í•œ ì •ë³´ëŠ” Slurm ê³µì‹ ì›¹í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n4. Slurm batch script ì‹¤í–‰ Conda environmentë¥¼ ë§Œë“¤ ë•Œì²˜ëŸ¼, sbatch ì»¤ë§¨ë“œë¥¼ í†µí•´ jobì„ ì œì¶œí•©ë‹ˆë‹¤. í• ë‹¹ë˜ëŠ” job ë²ˆí˜¸ëŠ” ë‚˜ì¤‘ì— squeueë¥¼ í†µí•´ ì •ë³´ë¥¼ í™•ì¸í•˜ê±°ë‚˜ jobì„ ì·¨ì†Œí•  ë•Œ ì´ìš©ë˜ë¯€ë¡œ ê¸°ë¡í•´ ë†“ì•„ì•¼ í•©ë‹ˆë‹¤.\ní„°ë¯¸ë„ì„ ì—¬ëŸ¬ ê°œ ë„ìš´ ë‹¤ìŒ smap -ië¡œ ì‘ì—… í˜„í™©ì„ í™•ì¸í•˜ê³ , cat xxx.logì´ë‚˜ tail -f xxx.errìœ¼ë¡œ ì½˜ì†” ì¶œë ¥ì´ë‚˜ errorë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n1 2 3 4  sbatch tensor.job smap -i 1 # ì‘ì—… í˜„í™©ì„ 1ì´ˆë§ˆë‹¤ ê°±ì‹ í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. ctrl+cë¡œ escape í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. cat tensor.log tail -f tensor.err   ë¡œê·¸ íŒŒì¼ì— ì½˜ì†” ì•„ì›ƒí’‹ì´ ê¸°ë¡ë©ë‹ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  2022-03-15 14:27:34.877232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-03-15 14:27:34.887611: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. 2022-03-15 14:27:38.063857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2) Epoch 1/5 1875/1875 [==============================] - 36s 19ms/step - loss: 0.2993 - accuracy: 0.9140 Epoch 2/5 1875/1875 [==============================] - 18s 10ms/step - loss: 0.1436 - accuracy: 0.9575 Epoch 3/5 1875/1875 [==============================] - 17s 9ms/step - loss: 0.1080 - accuracy: 0.9675 Epoch 4/5 1875/1875 [==============================] - 19s 10ms/step - loss: 0.0866 - accuracy: 0.9739 Epoch 5/5 1875/1875 [==============================] - 52s 28ms/step - loss: 0.0750 - accuracy: 0.9762 313/313 - 4s - loss: 0.0782 - accuracy: 0.9779 [0.078231580555439, 0.9779000282287598]   ë” ì•Œì•„ë³´ê¸° Submitting a slurm job script\nSLRUM Job Examples\nTensorFlow on the HPC Clusters\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/04_how-to-use-gpu-node-for-slurm-copy/","summary":"4. GPU nodeì—ì„œ Python ì½”ë“œ ì‹¤í–‰í•˜ê¸° 2ë²ˆ ë¬¸ì„œë¥¼ ë¨¼ì € ìˆ™ì§€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” 2ë²ˆ ë¬¸ì„œì˜ Step 1, 2, 3 ì´í›„ì˜ ë‚´ìš©ë§Œì„ ë‹¤ë£¹ë‹ˆë‹¤.\ngpu-compute nodeì—ì„œëŠ” Pythonë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\nStep 4. Export your conda setting ë²„ì „ ê´€ë¦¬ ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ë•Œì—ëŠ” ë²„ì „ ê´€ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.\n GPU ë“œë¼ì´ë²„ ë²„ì „(418.67) Python ë²„ì „ CUDA ë²„ì „(í˜¸í™˜ì„± í‘œ) cuDNN, ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬(tensorflow, pytorch) ë²„ì „(í˜¸í™˜ì„± í‘œ: tensorflow, pytorch)  ì´ë“¤ì˜ ë²„ì „ ê°„ í˜¸í™˜ì´ ë˜ëŠ” ì¡°í•©ì„ ìˆ™ì§€í•˜ê³  ì´ì— ë”°ë¼ conda environmentë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.","title":"4. GPU node ì‚¬ìš©ë²•(Python)"},{"content":"3. CPU nodeì—ì„œ R ì½”ë“œ ì‹¤í–‰í•˜ê¸° 2ë²ˆ ë¬¸ì„œì˜ Step 1, 2, 3ì„ ë¨¼ì € ìˆ™ì§€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” ê·¸ ì´í›„ì˜ ë‚´ìš©ë§Œì„ ë‹¤ë£¹ë‹ˆë‹¤.\n1. R ì½”ë“œ ì‘ì„± í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰í•  R ì½”ë“œë¥¼ localì—ì„œ ì‘ì„±í•©ë‹ˆë‹¤. ì½”ë“œê°€ ë¬¸ì œ ì—†ì´ ì‹¤í–‰ë˜ëŠ”ì§€ ë¨¼ì € localì—ì„œ í™•ì¸í•©ë‹ˆë‹¤. ê·¸ í›„ ì‹¤ì œë¡œ ì‹¤í–‰í•  ì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ì˜ user home directoryì— ì˜®ê¸°ê±°ë‚˜, Visual Studio Codeë‚´ì—ì„œ ì‘ì„±í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\nRì€ cpu-computeì—ë§Œ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Rì€ conda environmentë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. R íŒ¨í‚¤ì§€ë“¤ì€ userë³„ directoryê°€ ì•„ë‹Œ NAS ë‚´ì˜ ê³µí†µ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤. ì‹¤í–‰í•  R ì½”ë“œë¥¼ scriptë¡œ ì‘ì„±í•œ ë‹¤ìŒ Slurm batch script ë‚´ì— í•´ë‹¹ scriptë¥¼ ì‹¤í–‰í•˜ë„ë¡ Rscript xxx.R commandë¥¼ ì ì–´ì£¼ë©´ ë©ë‹ˆë‹¤.\nì•„ë˜ì˜ ìƒ˜í”Œ ì½”ë“œëŠ” xgboostì™€ caretì„ ì„¤ì¹˜ ë° ë¡œë“œí•˜ê³  learningê³¼ predictionì„ ìˆ˜í–‰í•œ ë‹¤ìŒ prediction ê²°ê³¼ plotì„ jpegë¡œ ì €ì¥í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤. Batch scriptë¥¼ ì‘ì„±í•  ë•ŒëŠ” ì•Œê³ ë¦¬ì¦˜ì˜ outputì´ ìë™ìœ¼ë¡œ ì €ì¥ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ íŒŒì¼ë¡œ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì½”ë“œë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ R_test_cpu.Rë¡œ ì €ì¥í•˜ì—¬ user home directoryì— ë‘¡ë‹ˆë‹¤.\n**install.packages()**ì—ì„œ\n force = FALSE ì˜µì…˜ì€ ì´ë¯¸ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ë¥¼ ë˜ ì„¤ì¹˜í•˜ëŠ” ê²ƒì„ ë§‰ì•„ì¤ë‹ˆë‹¤1. INSTALL_opts = c('\u0026ndash;no-lock') ì˜µì…˜ì€ ì„¤ì¹˜ê°€ ì´ì „ì— ê°•ì œë¡œ ì¤‘ë‹¨ë˜ì–´ì„œ directoryì— ë½ì´ ê±¸ë ¸ì„ ë•Œ ë½ì„ ë¬´ì‹œí•˜ê³  ì„¤ì¹˜í•˜ê²Œ í•©ë‹ˆë‹¤2.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  install.packages(\u0026#34;xgboost\u0026#34;, force = FALSE, INSTALL_opts = c(\u0026#39;--no-lock\u0026#39;)) install.packages(\u0026#34;caret\u0026#34;, force = FALSE, INSTALL_opts = c(\u0026#39;--no-lock\u0026#39;)) library(xgboost) library(caret) boston = MASS::Boston str(boston) set.seed(12) indexes = createDataPartition(boston$medv, p = .85, list = F) train = boston[indexes, ] test = boston[-indexes, ] train_x = data.matrix(train[, -13]) train_y = train[,13] test_x = data.matrix(test[, -13]) test_y = test[, 13] xgb_train = xgb.DMatrix(data = train_x, label = train_y) xgb_test = xgb.DMatrix(data = test_x, label = test_y) xgbc = xgboost(data = xgb_train, max.depth = 2, nrounds = 50) print(xgbc) pred_y = predict(xgbc, xgb_test) mse = mean((test_y - pred_y)^2) mae = caret::MAE(test_y, pred_y) rmse = caret::RMSE(test_y, pred_y) cat(\u0026#34;MSE: \u0026#34;, mse, \u0026#34;MAE: \u0026#34;, mae, \u0026#34; RMSE: \u0026#34;, rmse) x = 1:length(test_y) jpeg(file=\u0026#34;R_plot.jpeg\u0026#34;) plot(x, test_y, col = \u0026#34;red\u0026#34;, type = \u0026#34;l\u0026#34;) lines(x, pred_y, col = \u0026#34;blue\u0026#34;, type = \u0026#34;l\u0026#34;) legend(x = 1, y = 38, legend = c(\u0026#34;original test_y\u0026#34;, \u0026#34;predicted test_y\u0026#34;), col = c(\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;), box.lty = 1, cex = 0.8, lty = c(1, 1)) dev.off()   3\n2. í˜„ì¬ í´ëŸ¬ìŠ¤í„° ìì› ì‚¬ìš©ëŸ‰ í™•ì¸ ì•„ë˜ ì»¤ë§¨ë“œë¥¼ í†µí•´ cpu-compute ë…¸ë“œì˜ cpuì™€ RAM ì‚¬ìš© í˜„í™©ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n1  sinfo -o \u0026#34;%n %e %m %a %c %C\u0026#34;   ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤.\n1 2 3  HOSTNAMES FREE_MEM MEMORY AVAIL CPUS CPUS(A/I/O/T) cpu-compute 105589 128916 up 32 0/32/0/32 gpu-compute 53318 80532 up 16 0/16/0/16    CPUSì˜ A/I/O/TëŠ” allocated/idle/other/totalì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ìì‹ ì˜ jobì´ ë°”ë¡œ ì‹¤í–‰ë˜ê¸°ë¥¼ ì›í•œë‹¤ë©´, Slurm batch scriptë¥¼ ì‘ì„±í•  ë•Œ  RAM ìš©ëŸ‰ì„ FREE_MEMë³´ë‹¤ ì ê²Œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. CPU ì½”ì–´ ê°œìˆ˜ë¥¼ CPUS idleë³´ë‹¤ ì ê²Œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.   í˜„ì¬ ê°€ìš© ìì›ë³´ë‹¤ ë” ë§ì€ ìì›ì„ ìš”êµ¬í•˜ëŠ” scriptë¥¼ ì‘ì„±í•˜ë©´, jobì´ ë°”ë¡œ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ê¸° ìƒíƒœì— ìˆë‹¤ê°€ ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì˜ jobì´ ëë‚˜ê³  ìì›ì´ ë°˜í™˜ë˜ë©´ jobì´ ì‹¤í–‰ë©ë‹ˆë‹¤.  3. Slurm batch script ì‘ì„± ì‘ì„±í•œ ì½”ë“œë¥¼ cpu-compute nodeì—ì„œ ì‹¤í–‰í•˜ëŠ” Slurm batch scriptë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° ì†Œê°œ í˜ì´ì§€ì˜ slurm job configuratorë¥¼ ì‚¬ìš©í•˜ë©´ scriptë¥¼ ì‰½ê²Œ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n Pythonê³¼ ë‹¬ë¦¬ conda environmentë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, conda activateì— ì²´í¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¹ˆì¹¸ë“¤ì„ ì±„ì›ë‹ˆë‹¤. Scriptë€ì— Rscript xxx.Rë¼ê³  ì‘ì„±í•©ë‹ˆë‹¤. ì´ëŠ” home directoryì— ìˆëŠ” xxx.R íŒŒì¼ì„ Rë¡œ ì‹¤í–‰í•˜ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. Print \u0026amp; Copy ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë‚´ìš©ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë©ë‹ˆë‹¤.  R_test_cpu.jobì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ì˜ user home directoryì— ì €ì¥í•©ë‹ˆë‹¤.\nConfiguratorë¡œ ìƒì„±í•œ Slurm batch scriptì˜ ë‚´ìš©ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #!/bin/bash # #SBATCH --job-name=R_test_cpu #SBATCH --partition=all #SBATCH --account=mjm #SBATCH --mem=16gb #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --time=00:50:00 #SBATCH --output=/mnt/nas/users/mjm/R_test_cpu.log #SBATCH --error=/mnt/nas/users/mjm/R_test_cpu.err #SBATCH --nodelist=cpu-compute Rscript R_test_cpu.R   Script ìœ—ë¶€ë¶„ì˜ #SBATCH ì˜µì…˜ë“¤ì˜ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n â€”job-name: ìˆ˜í–‰í•  ì‘ì—…ì˜ ì´ë¦„ â€”mem: memory limit â€”nodelist: ì‘ì—…í•  ë…¸ë“œì˜ ì´ë¦„ â€”ntasks: ì‘ì—…ì˜ ìˆ˜ â€”cpus-per-task: ê° ì‘ì—…ì—ì„œ ì‚¬ìš©í•  cpu ì½”ì–´ì˜ ìˆ˜ â€”time: ì‘ì—… ì œí•œì‹œê°„ â€”account: í•´ë‹¹ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê³„ì •ì˜ ì´ë¦„ â€”partition: group of nodes with specific characteristics \u0026ndash;nodelist: ì‚¬ìš©í•  nodeì˜ ì´ë¦„ â€”output: ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ log íŒŒì¼. í™•ì¥ìëŠ” outì´ë‚˜ logê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. â€”error: ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ log  sbatchì— ëŒ€í•œ ë” ìì„¸í•œ ì •ë³´ëŠ” Slurm ê³µì‹ ì›¹í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n4. Slurm batch script ì‹¤í–‰ sbatch ì»¤ë§¨ë“œë¥¼ í†µí•´ jobì„ ì œì¶œí•©ë‹ˆë‹¤. 2ë²ˆ ë¬¸ì„œì˜ Step 4ì—ì„œì²˜ëŸ¼, ctrl+shift+~ë¥¼ ëˆŒëŸ¬ í„°ë¯¸ë„ì„ ì—¬ëŸ¬ ê°œ ë„ìš°ê³  smap -ië¡œ ì‘ì—… í˜„í™©ì„ í™•ì¸í•˜ê³ , tail -f xxx.out, tail -f xxx.errìœ¼ë¡œ ì½˜ì†” ì¶œë ¥ì´ë‚˜ errorë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì‘ì—…ì€ 5ë¶„ ì´ë‚´ì— ëë‚©ë‹ˆë‹¤.\n1  sbatch R_test_cpu.job   ë” ì•Œì•„ë³´ê¸° Submitting a slurm job script\nSLRUM Job Examples\nReferences   https://stat.ethz.ch/pipermail/r-help/2010-May/239492.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://github.com/lumiamitie/TIL/blob/master/rstudy/package_lock.md\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.datatechnotes.com/2020/08/regression-example-with-xgboost-in-r.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/03_how-to-use-cpu-node_r/","summary":"3. CPU nodeì—ì„œ R ì½”ë“œ ì‹¤í–‰í•˜ê¸° 2ë²ˆ ë¬¸ì„œì˜ Step 1, 2, 3ì„ ë¨¼ì € ìˆ™ì§€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” ê·¸ ì´í›„ì˜ ë‚´ìš©ë§Œì„ ë‹¤ë£¹ë‹ˆë‹¤.\n1. R ì½”ë“œ ì‘ì„± í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰í•  R ì½”ë“œë¥¼ localì—ì„œ ì‘ì„±í•©ë‹ˆë‹¤. ì½”ë“œê°€ ë¬¸ì œ ì—†ì´ ì‹¤í–‰ë˜ëŠ”ì§€ ë¨¼ì € localì—ì„œ í™•ì¸í•©ë‹ˆë‹¤. ê·¸ í›„ ì‹¤ì œë¡œ ì‹¤í–‰í•  ì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ì˜ user home directoryì— ì˜®ê¸°ê±°ë‚˜, Visual Studio Codeë‚´ì—ì„œ ì‘ì„±í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\nRì€ cpu-computeì—ë§Œ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Rì€ conda environmentë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. R íŒ¨í‚¤ì§€ë“¤ì€ userë³„ directoryê°€ ì•„ë‹Œ NAS ë‚´ì˜ ê³µí†µ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.","title":"3. CPU node ì‚¬ìš©ë²•(R)"},{"content":"CPU nodeì—ì„œ Python ì½”ë“œ ì‹¤í–‰í•˜ê¸° Step 1 - terminal ì•± ê³ ë¥´ê¸° UserëŠ” SSHë¡œ proxy nodeì— ì ‘ì†í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í„°ë¯¸ë„ í™˜ê²½ê³¼ vi ì—ë””í„°ì— ìµìˆ™í•œ userëŠ” ìì‹ ì—ê²Œ ì¹œìˆ™í•œ ì•±ì„ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° Visual Studio Codeë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œëŠ” Visual Studio Codeë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì „ì œë¡œ í•©ë‹ˆë‹¤. ì¶”ì²œ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n Windows, MacOS, Linuxì—ì„œ ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. í„°ë¯¸ë„ê³¼ ì—ë””í„°, íŒŒì¼ ë¸Œë¼ìš°ì €ê°€ í†µí•©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ë¶ˆí¸í•˜ê²Œ vië‚˜ nanoë“±ì˜ CLIìš© í…ìŠ¤íŠ¸ ì—ë””í„°ë¥¼ ì‚¬ìš©í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì „ì†¡ì‹œ scpë“±ì˜ ë³µì¡í•œ í”„ë¡œí† ì½œì„ ì‚¬ìš©í•  í•„ìš” ì—†ì´ drag \u0026amp; dropìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    Visual Studio Codeì™¸ì— ë‹¤ë¥¸ ì•±ì„ ì‚¬ìš©í•˜ì‹¤ ê²½ìš° ì¶”ì²œí•˜ëŠ” ì•±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n Windows 10: WSL2(Windows Subsystem for Linux 2)ì™€ Windows Terminalì„ ì„¤ì¹˜í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤. MacOS: ê¸°ë³¸ í„°ë¯¸ë„ì„ ì‚¬ìš©í•´ë„ ë˜ì§€ë§Œ, iTerm2ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. iOS: 5ë²ˆ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. Android: Termux  proxy node  proxy nodeëŠ” userê°€ ë¡œê·¸ì¸í•˜ì—¬ íŒŒì¼ì„ ì •ë¦¬í•˜ê³  cpu-computeë‚˜ gpu-compute nodeì— jobì„ ì œì¶œí•˜ëŠ” ìš©ë„ë¡œë§Œ ì“°ëŠ” ì»´í“¨í„°ì…ë‹ˆë‹¤.  ë”°ë¼ì„œ proxy nodeëŠ” ì„±ëŠ¥ì´ ë‚®ìŠµë‹ˆë‹¤. proxy nodeì—ì„œëŠ” Python ì‘ì—… ë“±ì„ ì‹¤í–‰í•˜ì§€ ë§ˆì„¸ìš”.   í„°ë¯¸ë„ì—ì„œ SSH ì ‘ì†ë§Œ í•  ìˆ˜ ìˆë‹¤ë©´ ì–´ë–¤ ê¸°ê¸°ì—ì„œë„ proxy nodeì— ì ‘ì†í•˜ì—¬ jobì„ ì œì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë‹¨ jobì„ ì œì¶œí•˜ë©´, í„°ë¯¸ë„ì´ ì¢…ë£Œë˜ê³  userì™€ proxy node ê°„ì˜ ì—°ê²°ì´ ëŠê²¨ë„ jobì€ ê³„ì† cpu-computeë‚˜ gpu-compute nodeì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤. Standard output(Python, Rì—ì„œ consoleì— ì¶œë ¥ë˜ëŠ” ë©”ì‹œì§€)ì´ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡ë˜ë¯€ë¡œ, ë‚˜ì¤‘ì— ë‹¤ì‹œ í„°ë¯¸ë„ì— ì ‘ì†í•˜ì—¬ job ì‹¤í–‰ í˜„í™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Step 2 - proxy node SSH ì ‘ì† Visual Studio Codeë¥¼ ì„¤ì¹˜í•˜ê³  ì•„ë˜ ì•ˆë‚´ì— ë”°ë¼ ì„¤ì •í•©ë‹ˆë‹¤.\n1. Visual Studio Code extensionsì—ì„œ Remote Development ì„¤ì¹˜[fn^3] Microsoftê°€ ì œê³µí•˜ëŠ” Remote Development extension packì„ ì„¤ì¹˜í•©ë‹ˆë‹¤. Remote-WSL, Remote-Containers, Remote-SSHê°€ ìë™ì ìœ¼ë¡œ ê°™ì´ ì„¤ì¹˜ë©ë‹ˆë‹¤. 2. Remote Explorerì—ì„œ SSH Targetsë¥¼ ì„ íƒ í›„, Add New í´ë¦­ 3. ssh ì ‘ì† ì»¤ë§¨ë“œ ì…ë ¥ ì•„ë˜ì™€ ê°™ì€ ì°½ì´ ëœ¨ë©´ SSH ì»¤ë§¨ë“œë¥¼ ì…ë ¥í•˜ì—¬ proxy nodeì— ì ‘ì†í•©ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œì— Slackìœ¼ë¡œ ì•ˆë‚´ë°›ì€ port, usernameì„ ë„£ì–´ì„œ ìœ„ ì°½ì— ì…ë ¥í•˜ê³  Enterí‚¤ë¥¼ ëˆ„ë¥´ë©´ ë©ë‹ˆë‹¤. SSHì˜ default portëŠ” 22ì´ì§€ë§Œ, ì €í¬ëŠ” ë³´ì•ˆìƒ ì´ìœ ë¡œ ë‹¤ë¥¸ portë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n1  ssh -p [port] [username]@hpc.stat.yonsei.ac.kr   ë˜ëŠ” ì•ˆë‚´ë°›ì€ proxy nodeì˜ ipë¥¼ ì…ë ¥í•´ë„ ë©ë‹ˆë‹¤.\n1  ssh -p [port] [username]@[ip]   4. SSH configuration fileì„ ì €ì¥í•  ì¥ì†Œ ì„ íƒ Select SSH configuration file to updateê°€ ë‚˜ì˜¤ë©´ ë§¨ ìœ„ í•­ëª©ì„ ì„ íƒí•©ë‹ˆë‹¤. Host added! ë¼ëŠ” ë©”ì‹œì§€ê°€ ìš°ì¸¡ í•˜ë‹¨ì— ë‚˜ì˜µë‹ˆë‹¤. 5. Remote Exploreì—ì„œ Connect to Host in New Window ì„ íƒ 6. ì„œë²„ Platform ì„ íƒ Linuxë¥¼ ì„ íƒí•©ë‹ˆë‹¤. 7. Password ì…ë ¥ ì•ˆë‚´ë°›ì€ passwordë¥¼ ì…ë ¥í•˜ì—¬ ë¡œê·¸ì¸í•©ë‹ˆë‹¤. 8. íŒŒì¼ ì‹œìŠ¤í…œ ë§ˆìš´íŠ¸ ì¢Œì¸¡ íƒ­ì˜ íŒŒì¼ ëª¨ì–‘ ì•„ì´ì½˜ì„ í´ë¦­í•˜ê³  Open Folder ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ user home directory ê²½ë¡œê°€ ì…ë ¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤. OKë¥¼ ëˆ„ë¦…ë‹ˆë‹¤. 9. ë‘˜ëŸ¬ë³´ê¸°   ì¢Œì¸¡ file explorerì—ì„œ íŒŒì¼ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. Windows íƒìƒ‰ê¸°ë‚˜ MacOS Finderì—ì„œ drag\u0026amp;dropìœ¼ë¡œ íŒŒì¼ì„ ì˜®ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ì˜ íŒŒì¼ì„ userì˜ local ì»´í“¨í„°ë¡œ ê°€ì ¸ì˜¤ëŠ” ê²ƒë„ drag\u0026amp;dropìœ¼ë¡œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n  ctrl + shift + ~í‚¤ë¥¼ ëˆ„ë¥´ë©´ í„°ë¯¸ë„ì´ ì—´ë¦½ë‹ˆë‹¤. ì—¬ê¸°ì„œ ì„œë²„ ì‚¬ìš©ì— í•„ìš”í•œ ì»¤ë§¨ë“œë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. í„°ë¯¸ë„ì€ ì—¬ëŸ¬ ê°œ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n  text editorì—ì„œ ì½”ë“œì™€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•˜ê³  ì´ë¯¸ì§€ íŒŒì¼ ë“±ì„ ì—´ëŒí•©ë‹ˆë‹¤.\n  10. user password ë³€ê²½ ëª¨ë“  userì˜ ì´ˆê¸° passwordê°€ ë‹¤ ë™ì¼í•˜ê¸° ë•Œë¬¸ì—, ê° userëŠ” ì²« ì ‘ì† ì‹œ passwordë¥¼ ë³€ê²½í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ì»¤ë§¨ë“œë¥¼ ì…ë ¥í•˜ì—¬ passwordë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.\n1  passwd   Step 3. íŒŒì¼ ì‹œìŠ¤í…œ êµ¬ì¡° ì´í•´ NAS(Network Attached Storage)ì— ê° userì˜ home directoryê°€ ìˆìŠµë‹ˆë‹¤. NASëŠ” ëª¨ë“  nodeì— ë§ˆìš´íŠ¸ë˜ì–´ ìˆìœ¼ë©°, ëª¨ë“  nodeì—ì„œ userëª…ê³¼ groupëª… ë° ê´€ë ¨ ì„¤ì •ì´ ë™ì¼í•©ë‹ˆë‹¤. Userëª…ì€ ì»´í“¨íŒ… í´ëŸ¬ìŠ¤í„° ì‚¬ìš© ì‹ ì²­ì‹œ ì œì¶œí•˜ì‹  ì´ë©”ì¼ ì£¼ì†Œì˜ @ ì• ë¶€ë¶„ê³¼ ë™ì¼í•©ë‹ˆë‹¤.\nUser home directoryì˜ prefixëŠ” /mnt/nas/users/ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, dummyuserë¼ëŠ” userì˜ home directoryì˜ ê²½ë¡œëŠ” /mnt/nas/users/dummyuser/ì…ë‹ˆë‹¤. ë‹¤ë¥¸ userì˜ home directoryë¥¼ ì—´ëŒí•  ìˆ˜ ì—†ë„ë¡ ê¶Œí•œì„¤ì •ì´ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° userëŠ” ë°ì´í„°ì™€ ì½”ë“œ, ì„¤ì • íŒŒì¼ ë“±ì„ ìì‹ ì˜ home directory ë‚´ì— ì €ì¥í•©ë‹ˆë‹¤.\n Linuxì—ì„œ directoryë¥¼ ì´ë™í•˜ëŠ” ëª…ë ¹ì–´ëŠ” cdì…ë‹ˆë‹¤. home directoryë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê¸°í˜¸ëŠ” ~ì…ë‹ˆë‹¤. í˜„ì¬ directoryë¥¼ í™•ì¸í•˜ëŠ” ëª…ë ¹ì–´ëŠ” pwdì…ë‹ˆë‹¤ íŒŒì¼ ëª©ë¡ì„ í™•ì¸í•˜ëŠ” ëª…ë ¹ì–´ëŠ” lsì…ë‹ˆë‹¤.  ë”°ë¼ì„œ userëŠ” proxy nodeì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ ìì‹ ì˜ í™ˆ directoryë¡œ ì´ë™í•´ ê·¸ ì•ˆì— ìˆëŠ” íŒŒì¼ ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n1 2  cd ~ ls   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # with the tree command the home directory will typically look like this /mnt/nas/users/dummyuser/ â”œâ”€â”€ .bash_history â”œâ”€â”€ .bash_logout â”œâ”€â”€ .bashrc â”œâ”€â”€ .conda â”œâ”€â”€ .config â”œâ”€â”€ GettingStarted.md â”œâ”€â”€ .gnupg â”œâ”€â”€ .ipynb_checkpoints â”œâ”€â”€ .ipython â”œâ”€â”€ .jupyter â”œâ”€â”€ .local â”œâ”€â”€ logs â”œâ”€â”€ .npm â”œâ”€â”€ .profile â”œâ”€â”€ .python_history â”œâ”€â”€ some_script.sh â”œâ”€â”€ .ssh â””â”€â”€ .viminfo   Step 4. Conda environment ìƒì„±  cpu-compute nodeì—ëŠ” conda version 4.11.0ì´ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©° Python versionì„ 3.10ê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤1. gpu-compute nodeì—ëŠ” conda version 4.6.14ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©° Python versionì„ 3.8ê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤.  ì—¬ê¸°ì„œëŠ” cpu-compute nodeì—ì„œ conda environmentë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. localì—ì„œ ì‘ì„±í•œ ì½”ë“œê°€ cpu-compute nodeì—ì„œ ì˜¤ë¥˜ ì—†ì´ ì‘ë™í•˜ë„ë¡ í•˜ê¸° ìœ„í•´, localê³¼ cpu-compute nodeì—ì„œ ë™ì¼í•œ conda environmentë¥¼ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤.\n4.1. localì—ì„œ conda environment ìƒì„± ì´ ì„¹ì…˜ì˜ ì‘ì—…ì€ ëª¨ë‘ í´ëŸ¬ìŠ¤í„°ê°€ ì•„ë‹ˆë¼ userì˜ local ì»´í“¨í„°ì—ì„œ ì§„í–‰í•©ë‹ˆë‹¤.\nminicondaë¥¼ ì„¤ì¹˜í•œ ë‹¤ìŒ, local ì»´í“¨í„°ì˜ í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ì»¤ë§¨ë“œë¡œ virtual environmentë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. testEnv ìë¦¬ì— ì›í•˜ëŠ” ì´ë¦„ì„ ë„£ê³ , python= ë’¤ì— ì‚¬ìš©í•  Python versionì„ ëª…ì‹œí•©ë‹ˆë‹¤.\n1  conda create -n testEnv python=3.6   ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ë©´ ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11  Preparing transaction: done Verifying transaction: done Executing transaction: done # # To activate this environment, use # # $ conda activate testEnv # # To deactivate an active environment, use # # $ conda deactivate   ì•„ë˜ ì»¤ë§¨ë“œë¥¼ í†µí•´ virtual environmentê°€ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n1  conda info --env   1 2 3 4  # conda environments: # base * /opt/miniconda3 testEnv /opt/miniconda3/envs/testEnv   Virtual environmentì— ì§„ì…í•œ ë’¤ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n pipë¡œ ì„¤ì¹˜ë˜ëŠ” íŒ¨í‚¤ì§€ë“¤ì€ condaë¡œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ì— ëŒ€í•œ ì •ë³´ë¥¼ ëª¨ë¥´ê¸° ë•Œë¬¸ì— ì˜ì¡´ì„± ì¶©ëŒì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ condaë§Œì„ ì‚¬ìš©í•´ì„œ ì„¤ì¹˜í•˜ì‹¤ ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. anaconda ì›¹ì‚¬ì´íŠ¸ì—ì„œ íŒ¨í‚¤ì§€ëª…ì„ ê²€ìƒ‰í•´ì„œ linux-64ë¥¼ ì§€ì›í•˜ëŠ” ë²„ì „ì´ ì–´ë””ê¹Œì§€ì¸ì§€ë¥¼ í™•ì¸í•˜ê³  ì„¤ì¹˜í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤. ì´ ì‚¬ì´íŠ¸ëŠ” ì„¤ì¹˜ ì»¤ë§¨ë“œë„ ì œê³µí•©ë‹ˆë‹¤. ì—¬ëŸ¬ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•  ê²½ìš° í•œ ì»¤ë§¨ë“œ ë‚´ì— ëª…ì‹œí•˜ë©´ condaê°€ ìë™ìœ¼ë¡œ dependency ì¶©ëŒì„ ê²€ì‚¬í•´ ì¤ë‹ˆë‹¤. íŒ¨í‚¤ì§€ ë²„ì „ì„ ëª…ì‹œí•  ë•ŒëŠ” =ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  1 2 3 4  conda activate testEnv #For example, conda install -c conda-forge lightgbm=2.0.7 matplotlib scikit-learn pandas numpy   ì•„ë˜ ì»¤ë§¨ë“œë¡œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤.\n1  conda list   Environmentë¥¼ ì§€ìš°ë ¤ë©´ ì•„ë˜ ì»¤ë§¨ë“œë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.\n1  conda remove --name testEnv --all   2. cpu-compute nodeì— localê³¼ ë™ì¼í•œ conda environment êµ¬ì¶•í•˜ê¸°  conda env export ì»¤ë§¨ë“œë¥¼ ì´ìš©í•´ environment ì „ì²´ë¥¼ .yml íŒŒì¼ë¡œ ë§Œë“¤ê³  ì´ë¥¼ ì´ìš©í•´ cpu-compute ë…¸ë“œì—ì„œ environmentë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ ë™ì¼í•œ environmentë¥¼ ë§Œë“œëŠ” ê°€ì¥ ì´ìƒì ì¸ ë°©ë²•ì…ë‹ˆë‹¤. ë˜ëŠ” ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ê³¼ ë²„ì „ë§Œì„ requirements.txtë¡œ ì¶”ì¶œí•˜ì—¬ ë…¸ë“œì—ì„œ cpu-computeì—ì„œ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ë‘ ë°©ë²•ì€ userì˜ local ì»´í“¨í„°ê°€ linuxê°€ ì•„ë‹ˆë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•  í™•ë¥ ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ì´ëŠ” ìœ ì €ê°€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•  ë•Œ ìë™ìœ¼ë¡œ ì„¤ì¹˜ë˜ëŠ” dependencyë“¤ì˜ ë²„ì „ì´ OSë³„ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  ì˜ˆë¥¼ ë“¤ì–´ lightgbm 2.0.7ë²„ì „ì€ Python ë²„ì „ì´ 3.6ì¼ ë•Œ linuxì™€ MacOSì—ì„œ ë‘˜ ë‹¤ ì„¤ì¹˜ ê°€ëŠ¥í•˜ì§€ë§Œ, ì´ íŒ¨í‚¤ì§€ì˜ dependency ì¤‘ í•˜ë‚˜ì¸ libgfortranì€ MacOSì—ì„œëŠ” 4.0.0ë²„ì „ì´ ì„¤ì¹˜ë˜ì§€ë§Œ linuxì—ì„œëŠ” 3.0.0ë²„ì „ê¹Œì§€ë§Œ ì§€ì›ë˜ê¸° ë•Œë¬¸ì— MacOSì—ì„œ ë§Œë“  environmentì—ì„œ ì¶”ì¶œí•œ yml íŒŒì¼ì´ë‚˜ list txt íŒŒì¼ì„ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‚¬ìš©í•˜ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤2. ì´ ì˜¤ë¥˜ëŠ” ì ì ˆí•œ ì¡°ì¹˜ë¥¼ í†µí•´ í•´ê²°í•  ìˆ˜ ìˆì„ ë•Œë„ ìˆì§€ë§Œ í•´ê²°í•˜ê¸° í˜ë“¤ ë•Œë„ ìˆìŠµë‹ˆë‹¤.    ë”°ë¼ì„œ localì—ì„œ ë§Œë“  environmentë¥¼ clusterë¡œ ì˜®ê¸°ê¸°ë³´ë‹¤ëŠ”, localì˜ environmentì—ì„œ ì‚¬ìš©í•˜ëŠ” Python ë²„ì „ê³¼ ì¤‘ìš” íŒ¨í‚¤ì§€ë“¤ì˜ ë²„ì „ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ cluster ë‚´ì—ì„œ environmentë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•˜ë©°, ì´ ë¬¸ì„œì—ì„œëŠ” ê·¸ ì ˆì°¨ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤.\n  Conda environment ìƒì„± slurm batch scriptë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #!/bin/bash #SBATCH --job-name=testEnv #SBATCH --nodes=1 #SBATCH --mem=4gb #SBATCH --partition=all #SBATCH --nodelist=cpu-compute #SBATCH --output=testEnv.log #SBATCH --error=testEnv.err CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnv #localì—ì„œì™€ ê°™ì€ ì´ë¦„ìœ¼ë¡œ ì…ë ¥ ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH #envê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì‚­ì œ $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.6 source $CONDA_BIN_PATH/activate $ENV_PATH conda install -y lightgbm=2.0.7 scikit-learn pandas numpy   ìœ„ ë‚´ìš©ì—ì„œ\n 2ë²ˆ ë¼ì¸ì˜ #SBATCH \u0026ndash;job-name=testEnvì˜ job name 7ë²ˆ ë¼ì¸ì˜ #SBATCH \u0026ndash;output=testEnv.logì˜ output log íŒŒì¼ëª… 8ë²ˆ ë¼ì¸ì˜ #SBATCH \u0026ndash;error=testEnv.errì˜ error log íŒŒì¼ëª… 10ë²ˆ ë¼ì¸ì˜ environment name 13ë²ˆ ë¼ì¸ì˜ python version 14ë²ˆ ë¼ì¸ì˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì»¤ë§¨ë“œ ë¥¼ ì•Œë§ê²Œ ìˆ˜ì •í•˜ì—¬ Visual Studio Codeì—ì„œ ì‘ì„±í•œ ë’¤, í´ëŸ¬ìŠ¤í„° ë‚´ user home directoryì— [your_env_name].jobìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.    ì‘ì„±í•œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰í•˜ê¸°. Visual Studio Code í•˜ë‹¨ í„°ë¯¸ë„ì—\n1  sbatch [your_env_name].job   ë¥¼ ì…ë ¥í•´ slurm batch job submissionì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì‘ì—…ì´ ë…¸ë“œì—ì„œ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©´\n1  Submitted batch job 401   ì™€ ê°™ì€ ë©”ì‹œì§€ê°€ ëœ¨ê³  job ë²ˆí˜¸ê°€ í• ë‹¹ë©ë‹ˆë‹¤. í• ë‹¹ë˜ëŠ” job ë²ˆí˜¸ëŠ” ë‚˜ì¤‘ì— squeueë¥¼ í†µí•´ ì •ë³´ë¥¼ í™•ì¸í•˜ê±°ë‚˜ jobì„ ì·¨ì†Œí•  ë•Œ ì´ìš©ë˜ë¯€ë¡œ ê¸°ë¡í•´ ë†“ì•„ì•¼ í•©ë‹ˆë‹¤.\n1  squeue   ì»¤ë§¨ë“œë¥¼ í†µí•´ ì‘ì—… ì‹¤í–‰ í˜„í™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n1 2  JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 402 all testEnv mjm R 0:01 1 cpu-compute   ë˜ëŠ” ì•„ë˜ ì»¤ë§¨ë“œë¥¼ í†µí•´ ì‹¤ì‹œê°„(1ì´ˆ ë‹¨ìœ„)ìœ¼ë¡œ ì‘ì—… ì‹¤í–‰ í˜„í™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ctrl+cë¡œ escape í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n1  smap -i 1   ë‹¤ìŒ ì»¤ë§¨ë“œë¥¼ í†µí•´ output log, error logíŒŒì¼ì˜ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n1 2  cat [your_job-name].log cat [your_job-name].err   log íŒŒì¼ì˜ ë‚´ìš©ì„ ë‹¤ìŒ ì»¤ë§¨ë“œë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ctrl+cë¡œ escapeí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n1 2  tail -f [your_job_name].log tail -f [your_job_name].err   í„°ë¯¸ë„ì„ ì—¬ëŸ¬ ê°œ ë„ì›Œ ë†“ê³  ê°ê°ì— smapê³¼ tail ì»¤ë§¨ë“œë¥¼ ì…ë ¥í•˜ë©´ í¸ë¦¬í•˜ê²Œ ì‹¤í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nìœ„ ìƒ˜í”Œ ì½”ë“œëŠ” ì•½ 3ë¶„ ì•ˆì— ì‘ì—…ì´ ì™„ë£Œë©ë‹ˆë‹¤. smapì—ì„œ ì‘ì—… ëª©ë¡ì´ ì‚¬ë¼ì§„ í›„ catìœ¼ë¡œ ë¡œê·¸ íŒŒì¼ì„ ì—´ì–´ì„œ\n1 2 3 4 5 6  pandas-1.1.3 | 10.5 MB | | 0% pandas-1.1.3 | 10.5 MB | #######1 | 71% pandas-1.1.3 | 10.5 MB | ########## | 100% Preparing transaction: ...working... done Verifying transaction: ...working... done Executing transaction: ...working... done   ì™€ ê°™ì€ ê¸°ë¡ì´ ë‚¨ì•„ ìˆìœ¼ë©´ conda environment ìƒì„±ì´ ì™„ë£Œëœ ê²ƒì…ë‹ˆë‹¤.\nì‘ì—…ì´ ëë‚˜ê¸° ì „ì— ì·¨ì†Œí•˜ë ¤ë©´ scancel ì»¤ë§¨ë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n1  scancel [job_number]     Step 5. Slrum batch script ì‘ì„±í•˜ì—¬ ì„œë²„ì— ì œì¶œí•˜ê¸° 5.1. Python ì½”ë“œ ì‘ì„± ì´ì œ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰í•  Python ì½”ë“œë¥¼ localì—ì„œ ì‘ì„±í•©ë‹ˆë‹¤. ì½”ë“œê°€ ì˜¤ë¥˜ ì—†ì´ ì‘ë™í•˜ëŠ”ì§€ localì—ì„œ í™•ì¸í•©ë‹ˆë‹¤. ê·¸ í›„ ì½”ë“œ íŒŒì¼ì„ user home directoryì— ì˜®ê¸°ê±°ë‚˜, Visual Studio Codeë‚´ì—ì„œ ì‘ì„±í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\nì•„ë˜ëŠ” tree ê¸°ë°˜ boosting ì•Œê³ ë¦¬ì¦˜ì¸ LightGBMìœ¼ë¡œ mnist datasetì„ ë¶„ë¥˜í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤. Boosting roundë¥¼ 10íšŒ ìˆ˜í–‰í•˜ê³  í•™ìŠµ ê²°ê³¼ë¥¼ csvíŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤3. Batch scriptë¥¼ ì‘ì„±í•  ë•ŒëŠ” ì•Œê³ ë¦¬ì¦˜ì˜ outputì´ ìë™ìœ¼ë¡œ ì €ì¥ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ íŒŒì¼ë¡œ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì½”ë“œë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë‹¨, ì½˜ì†”ì— ì¶œë ¥ë˜ëŠ” ë‚´ìš©ì€ output logì— ìë™ìœ¼ë¡œ ê¸°ë¡ë©ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ python_test_cpu.pyë¡œ ì €ì¥í•˜ì—¬ user home directoryì— ë‘¡ë‹ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  import numpy as np from time import process_time from lightgbm import LGBMClassifier from sklearn.metrics import accuracy_score, log_loss from sklearn.datasets import fetch_openml from sklearn.model_selection import train_test_split def lgb(n=10, c=0, sequence=1): mnist = fetch_openml(\u0026#39;mnist_784\u0026#39;) x_train, x_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.33, random_state=42) proba_test = np.zeros((n, y_test.shape[0], len(np.unique(y_test)))) proba_train = np.zeros((n, y_train.shape[0], len(np.unique(y_train)))) test_score = [] train_score = [] tr_time = [] seq = [] while(n): model = LGBMClassifier(n_estimators=sequence) t0 = process_time() model.fit(x_train, y_train) tr_time.append(process_time() - t0) test_score.append(accuracy_score(y_test, model.predict(x_test))) train_score.append(accuracy_score(y_train, model.predict(x_train))) proba_test[c, ] = model.predict_proba(x_test) proba_train[c, ] = model.predict_proba(x_train) seq.append(sequence) sequence *= 2 n -= 1 c += 1 ce_train = [] ce_test = [] for i in range(10): ce_test.append(log_loss(y_test, proba_test[i])) ce_train.append(log_loss(y_train, proba_train[i])) np.savetxt(\u0026#39;round\u0026#39;+ str(i) + \u0026#39;proba_test.csv\u0026#39;, proba_test[i]) np.savetxt(\u0026#39;round\u0026#39;+ str(i) + \u0026#39;proba_train.csv\u0026#39;, proba_train[i]) np.savetxt(\u0026#39;test_score.csv\u0026#39;, test_score, delimiter=\u0026#39;,\u0026#39;) np.savetxt(\u0026#39;train_score.csv\u0026#39;, train_score, delimiter=\u0026#39;,\u0026#39;) np.savetxt(\u0026#39;ce_test.csv\u0026#39;, ce_test, delimiter=\u0026#39;,\u0026#39;) np.savetxt(\u0026#39;ce_train.csv\u0026#39;, ce_train, delimiter=\u0026#39;,\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: lgb()   5.2. í˜„ì¬ í´ëŸ¬ìŠ¤í„° ìì› ì‚¬ìš©ëŸ‰ í™•ì¸ ì•„ë˜ ì»¤ë§¨ë“œë¥¼ í†µí•´ cpu-compute ë…¸ë“œì˜ cpuì™€ RAM ì‚¬ìš© í˜„í™©ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n1  sinfo -o \u0026#34;%n %e %m %a %c %C\u0026#34;   ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤.\n1 2 3  HOSTNAMES FREE_MEM MEMORY AVAIL CPUS CPUS(A/I/O/T) cpu-compute 105589 128916 up 32 0/32/0/32 gpu-compute 53318 80532 up 16 0/16/0/16    CPUSì˜ A/I/O/TëŠ” allocated/idle/other/totalì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ìì‹ ì˜ jobì´ ë°”ë¡œ ì‹¤í–‰ë˜ê¸°ë¥¼ ì›í•œë‹¤ë©´, Slurm batch scriptë¥¼ ì‘ì„±í•  ë•Œ  RAM ìš©ëŸ‰ì„ FREE_MEMë³´ë‹¤ ì ê²Œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. CPU ì½”ì–´ ê°œìˆ˜ë¥¼ CPUS idleë³´ë‹¤ ì ê²Œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.   í˜„ì¬ ê°€ìš© ìì›ë³´ë‹¤ ë” ë§ì€ ìì›ì„ ìš”êµ¬í•˜ëŠ” scriptë¥¼ ì‘ì„±í•˜ë©´, jobì´ ë°”ë¡œ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ê¸° ìƒíƒœì— ìˆë‹¤ê°€ ë‹¤ë¥¸ userë“¤ì˜ jobì´ ëë‚˜ê³  ìì›ì´ ë°˜í™˜ë˜ë©´ jobì´ ì‹¤í–‰ë©ë‹ˆë‹¤.  5.3. Slurm batch script ì‘ì„± ì•ì„  ë‹¨ê³„ì—ì„œ ë§Œë“  í•´ë‹¹ conda environmentë¥¼ activateí•˜ê³  ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” Slurm batch scriptë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° ì†Œê°œ í˜ì´ì§€ì˜ slurm job configuratorë¥¼ ì‚¬ìš©í•˜ë©´ scriptë¥¼ ì‰½ê²Œ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n Conda activateì— ì²´í¬í•©ë‹ˆë‹¤. ë¹ˆì¹¸ë“¤ì„ ì±„ì›ë‹ˆë‹¤. Scriptë€ì— python xxx.pyë¼ê³  ì‘ì„±í•©ë‹ˆë‹¤. ì´ëŠ” home directoryì— ìˆëŠ” xxx.py íŒŒì¼ì„ Pythonìœ¼ë¡œ ì‹¤í–‰í•˜ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. Print \u0026amp; Copy ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë‚´ìš©ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë©ë‹ˆë‹¤.  Slurm batch scriptì˜ ë‚´ìš©ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #!/bin/bash # #SBATCH --job-name=python_test_cpu #SBATCH --partition=all #SBATCH --account=mjm #SBATCH --mem=4gb #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --time=01:00:00 #SBATCH --output=/mnt/nas/users/mjm/python_test_cpu.log #SBATCH --error=/mnt/nas/users/mjm/python_test_cpu.err #SBATCH --nodelist=cpu-compute CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=testEnv ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME source $CONDA_BIN_PATH/activate $ENV_PATH python python_test_cpu.py   python_test_cpu.jobì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ì˜ user home directoryì— ì €ì¥í•©ë‹ˆë‹¤.\nScript ìœ—ë¶€ë¶„ì˜ #SBATCH ì˜µì…˜ë“¤ì˜ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n â€”job-name: ìˆ˜í–‰í•  ì‘ì—…ì˜ ì´ë¦„ â€”mem: memory limit â€”nodelist: ì‘ì—…í•  ë…¸ë“œì˜ ì´ë¦„ â€”ntasks: ì‘ì—…ì˜ ìˆ˜ â€”cpus-per-task: ê° ì‘ì—…ì—ì„œ ì‚¬ìš©í•  cpu ì½”ì–´ì˜ ìˆ˜ â€”time: ì‘ì—… ì œí•œì‹œê°„ â€”account: í•´ë‹¹ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê³„ì •ì˜ ì´ë¦„ â€”partition: group of nodes with specific characteristics \u0026ndash;nodelist: ì‚¬ìš©í•  nodeì˜ ì´ë¦„ â€”output: ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ log íŒŒì¼. í™•ì¥ìëŠ” outì´ë‚˜ logê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. â€”error: ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ log  sbatchì— ëŒ€í•œ ë” ìì„¸í•œ ì •ë³´ëŠ” Slurm ê³µì‹ ì›¹í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n5.4. Slurm batch script ì‹¤í–‰ Conda environmentë¥¼ ë§Œë“¤ ë•Œì²˜ëŸ¼, sbatch ì»¤ë§¨ë“œë¥¼ í†µí•´ jobì„ ì œì¶œí•©ë‹ˆë‹¤. í• ë‹¹ë˜ëŠ” job ë²ˆí˜¸ëŠ” ë‚˜ì¤‘ì— squeueë¥¼ í†µí•´ ì •ë³´ë¥¼ í™•ì¸í•˜ê±°ë‚˜ jobì„ ì·¨ì†Œí•  ë•Œ ì´ìš©ë˜ë¯€ë¡œ ê¸°ë¡í•´ ë†“ì•„ì•¼ í•©ë‹ˆë‹¤.\nStep 4ì—ì„œì²˜ëŸ¼, ctrl+shift+~ë¥¼ ëˆŒëŸ¬ í„°ë¯¸ë„ì„ ì—¬ëŸ¬ ê°œ ë„ìš°ê³  smap -ië¡œ ì‘ì—… í˜„í™©ì„ í™•ì¸í•˜ê³ , tail -f xxx.out, tail -f xxx.errìœ¼ë¡œ ì½˜ì†” ì¶œë ¥ì´ë‚˜ errorë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì‘ì—…ì€ 4ë¶„ ì •ë„ ê±¸ë¦½ë‹ˆë‹¤.\n1  sbatch python_test_cpu.job   í˜„ì¬ ì‘ì—…ì´ ìì›ì„ ì–¼ë§ˆë‚˜ í• ë‹¹ë°›ì•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ì»¤ë§¨ë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. NumCPUs=4ê°€ ì½”ì–´ë¥¼ 4ê°œ í• ë‹¹ë°›ì•˜ë‹¤ëŠ” ëœ»ì´ê³ , mem=4Gê°€ RAMì„ 4gb í• ë‹¹ë°›ì•˜ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤. ì´ ì»¤ë§¨ë“œëŠ” ë‹¤ë¥¸ userê°€ ì œì¶œí•œ jobì— ëŒ€í•´ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n1  scontrol show job [job number]   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  UserId=mjm(1003) GroupId=mjm(1003) MCS_label=N/A Priority=4294901694 Nice=0 Account=mjm QOS=(null) JobState=RUNNING Reason=None Dependency=(null) Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:00:05 TimeLimit=01:00:00 TimeMin=N/A SubmitTime=2022-03-17T15:31:01 EligibleTime=2022-03-17T15:31:01 StartTime=2022-03-17T15:31:01 EndTime=2022-03-17T16:31:01 Deadline=N/A PreemptTime=None SuspendTime=None SecsPreSuspend=0 LastSchedEval=2022-03-17T15:31:01 Partition=all AllocNode:Sid=proxy:30897 ReqNodeList=cpu-compute ExcNodeList=(null) NodeList=cpu-compute BatchHost=cpu-compute NumNodes=1 NumCPUs=4 NumTasks=1 CPUs/Task=4 ReqB:S:C:T=0:0:*:* TRES=cpu=4,mem=4G,node=1,billing=4 Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=* MinCPUsNode=4 MinMemoryNode=4G MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 Gres=(null) Reservation=(null) OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) Command=/mnt/nas/users/mjm/python_test_cpu.job WorkDir=/mnt/nas/users/mjm StdErr=/mnt/nas/users/mjm/python_test_cpu.err StdIn=/dev/null StdOut=/mnt/nas/users/mjm/python_test_cpu.log Power=   Visual Stuio Codeì˜ file explorerëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€í™”ê°€ ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì£¼ë©´ ë³€í™”ê°€ ë°˜ì˜ë˜ê³  output íŒŒì¼ì´ explorerì— ë³´ì…ë‹ˆë‹¤.\në” ì•Œì•„ë³´ê¸° Submitting a slurm job script\nSLRUM Job Examples\nReferences   https://docs.conda.io/projects/conda/en/latest/release-notes.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://github.com/conda/conda/issues/9399\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.kaggle.com/samanemami/script-lightgbm-mnist\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/02_how-to-use-cpu-node_python/","summary":"CPU nodeì—ì„œ Python ì½”ë“œ ì‹¤í–‰í•˜ê¸° Step 1 - terminal ì•± ê³ ë¥´ê¸° UserëŠ” SSHë¡œ proxy nodeì— ì ‘ì†í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í„°ë¯¸ë„ í™˜ê²½ê³¼ vi ì—ë””í„°ì— ìµìˆ™í•œ userëŠ” ìì‹ ì—ê²Œ ì¹œìˆ™í•œ ì•±ì„ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° Visual Studio Codeë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œëŠ” Visual Studio Codeë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì „ì œë¡œ í•©ë‹ˆë‹¤. ì¶”ì²œ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n Windows, MacOS, Linuxì—ì„œ ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. í„°ë¯¸ë„ê³¼ ì—ë””í„°, íŒŒì¼ ë¸Œë¼ìš°ì €ê°€ í†µí•©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ë¶ˆí¸í•˜ê²Œ vië‚˜ nanoë“±ì˜ CLIìš© í…ìŠ¤íŠ¸ ì—ë””í„°ë¥¼ ì‚¬ìš©í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.","title":"2. CPU node ì‚¬ìš©ë²•(Python)"},{"content":"ìš”ì•½ Chili PepperëŠ”\n ì´ ì„¸ ê°œì˜ ì»´í“¨í„°ë¡œ êµ¬ì„±ëœ ì»´í“¨íŒ… í´ëŸ¬ìŠ¤í„°ì…ë‹ˆë‹¤. CPU node í•˜ë‚˜, GPU node í•˜ë‚˜, ê·¸ë¦¬ê³  ì´ ë‘˜ì„ ê´€ë¦¬í•˜ëŠ” proxy nodeë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Slurmì´ë¼ëŠ” job schedulerë¡œ ì—¬ëŸ¬ userì˜ ì‘ì—…ì„ ê° nodeì— íš¨ìœ¨ì ìœ¼ë¡œ í• ë‹¹í•©ë‹ˆë‹¤. ê° userëŠ” ìì‹ ë§Œì˜ conda environmentë¥¼ ìŠ¤ìŠ¤ë¡œ ìƒì„±í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ non-interactiveì…ë‹ˆë‹¤. Userê°€ ìì‹ ì˜ ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ì‘ì„± ë° í…ŒìŠ¤íŠ¸í•œ ì½”ë“œë¥¼ ì„œë²„ì— ì œì¶œí•˜ë©´ ì„œë²„ê°€ í•´ë‹¹ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ì£¼í”¼í„° ë…¸íŠ¸ë¶ í™˜ê²½ì€ ì‹¤í–‰ ê°€ëŠ¥í•˜ì§€ë§Œ, ê¼­ í•„ìš”í•œ ê²½ìš°ì— í•œí•˜ì—¬ ìš”ì²­ ì‹œ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ë…¸íŠ¸ë¶ í™˜ê²½ì€ ì‘ì—… ë‹¨ìœ„ê°€ ì•„ë‹Œ ì‹œê°„ ë‹¨ìœ„ë¡œ ì‹¤í–‰ë˜ê¸° ë•Œë¬¸ì— ì„œë²„ì˜ RAM ìì›ì„ ì§€ë‚˜ì¹˜ê²Œ ë§ì´ ì ìœ í•˜ê³  ë‹¤ë¥¸ ì‘ì—…ì˜ ì‹¤í–‰ì„ ë°©í•´í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. íŒŒì¼ì€ ìœ„ ì„¸ ì»´í“¨í„°ì™€ ë³„ê°œì˜ NAS(Network Attached Storage)ì— ì €ì¥ë˜ë©°, ëª¨ë“  ì»´í“¨í„°ì— ë§ˆìš´íŠ¸ë˜ì–´ ìˆìœ¼ë¯€ë¡œ í•œë²ˆ í´ëŸ¬ìŠ¤í„° ë‚´ë¡œ ì˜®ê¸´ íŒŒì¼ì€ í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ì—ì„œ ë‹¤ì‹œ ì˜®ê¸¸ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.  1. í´ëŸ¬ìŠ¤í„° êµ¬ì„± 1. CPU node  Name: cpu-compute CPU: IntelÂ® XeonÂ® Gold 5220 CPU @ 2.20GHz 32 cores RAM: 128GB OS: ubuntu 18.04.6 LTS conda version: 4.11.0  2. GPU node  Name: gpu-compute CPU: IntelÂ® XeonÂ® Gold 5220 CPU @ 2.20GHz 16 cores GPU: NVIDIAÂ® TeslaÂ® T4 16GB x 2 RAM: 80GB OS: ubuntu 18.04.6 LTS conda version: 4.6.14 GPU driver version: 418.67  3. proxy node  Name: proxy CPU: IntelÂ® XeonÂ® Gold 5220 CPU @ 2.20GHz 2 cores RAM: 4GB OS: ubuntu 18.04.6 LTS  íŠ¹ì´ì‚¬í•­   IntelÂ® XeonÂ® Gold 5220 CPU @ 2.20GHzê°€ 18ì½”ì–´ ì œí’ˆì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ì„¸ ì»´í“¨í„°ì— ê°ê° 32ì½”ì–´, 16ì½”ì–´, 2ì½”ì–´ë¡œ ì¥ì°©ë˜ì–´ ìˆëŠ” ê²ƒì€ ì´ ì„¸ ì»´í“¨í„°ê°€ ë„¤ì´ë²„ í´ë¼ìš°ë“œ í”Œë«í¼ì—ì„œ í˜¸ìŠ¤íŒ…ë˜ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë„¤ì´ë²„ í´ë¼ìš°ë“œ í”Œë«í¼ì—ì„œ ê° ì»´í“¨í„°ì— ì •í•´ì§„ ì½”ì–´ ìˆ˜ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.\n  proxy nodeëŠ” userê°€ ë¡œê·¸ì¸í•˜ì—¬ jobì„ ì œì¶œí•˜ê¸° ìœ„í•œ ìš©ë„ë¡œë§Œ ì“°ì´ëŠ” ì»´í“¨í„°ì´ë¯€ë¡œ ì„±ëŠ¥ì´ ë‚®ìŠµë‹ˆë‹¤.\n  UserëŠ” proxyì—ë§Œ ì ‘ì†í•  ìˆ˜ ìˆìœ¼ë©°, cpu-computeì™€ gpu-computeì—ëŠ” ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n  2. Slurm job scheduler Job scheduler HPC(High performance computing) ì‹œìŠ¤í…œì€ ê°œì¸ìš© ì»´í“¨í„°ì™€ ë‹¬ë¦¬ ì—¬ëŸ¬ userê°€ ì—¬ëŸ¬ nodeë¥¼ ê³µìœ í•˜ë©° ì‚¬ìš©í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ëˆ„êµ¬ì˜ ì‘ì—…ì´ ì–¸ì œ ì–´ëŠ nodeì—ì„œ ì‹¤í–‰ë ì§€ ê²°ì •í•´ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ job schedulerì…ë‹ˆë‹¤.\nJob schedulerë¥¼ ì‹ë‹¹ì˜ ì›¨ì´í„°ì— ë¹„ìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹ë‹¹ì— ì‚¬ëŒì´ ë§ìœ¼ë©´ ì¤„ì„ ì„œì„œ ê¸°ë‹¤ë ¤ì•¼ í•©ë‹ˆë‹¤. ì›¨ì´í„°ëŠ” ê° ì†ë‹˜ ê·¸ë£¹ì˜ ìˆ˜ì— ë§ëŠ” ìë¦¬ê°€ ë‚˜ë©´ ê·¸ ê·¸ë£¹ì„ í…Œì´ë¸”ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤1. ìš©ì–´   Job: userê°€ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰í•˜ê³ ì í•˜ëŠ” ì½”ë“œ(bash, python, R ë“±ì„ ëª¨ë‘ í¬í•¨)\n  Batch job submission: userê°€ ë¯¸ë¦¬ ì‘ì„±í•œ ì½”ë“œ(outputì„ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë‚´ìš© í¬í•¨)ë¥¼ schedulerì—ê²Œ ì œì¶œí•˜ì—¬ non-interactiveí•˜ê²Œ ì„œë²„ì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²ƒ\n  Slurm Slurm(Simple Linux Utility for Resource Management)ì€ HPCì—ì„œ ë§ì´ ì±„ìš©í•˜ëŠ” job schedulerì…ë‹ˆë‹¤. ì „ ì„¸ê³„ TOP 500 ìŠˆí¼ì»´í“¨í„° ì¤‘ 60%ê°€ slurmì„ ì‚¬ìš©í•©ë‹ˆë‹¤2.\nSlurmì€ ê° userì˜ cpuì‚¬ìš©ëŸ‰ ë“± ë‹¤ì–‘í•œ í†µê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—…ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, University of Torontoì˜ Computer Science Departmentì˜ HPCëŠ” ì‚¬ìš© CPU ì½”ì–´ ìˆ˜ * ì‚¬ìš© ì‹œê°„(ì´ˆ) ê°’ì´ ë‚®ì€ userì˜ jobì„ ë¨¼ì € ì‹¤í–‰í•©ë‹ˆë‹¤. RAM ì‚¬ìš©ëŸ‰ì€ 0.25GBë‹¹ CPU 1ì½”ì–´ ì‚¬ìš©ìœ¼ë¡œ, GPU ì‚¬ìš©ëŸ‰ì€ GPU 1ê°œë‹¹ CPU 16ì½”ì–´ ì‚¬ìš©ìœ¼ë¡œ í™˜ì‚°í•©ë‹ˆë‹¤3.\ní˜„ì¬ Chili PepperëŠ” ìœ„ì™€ ê°™ì€ ì ìˆ˜ì œê°€ ì•„ë‹Œ FIFO(First In, First Out) ê·œì¹™ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¼ì • ê¸°ê°„ ìš´ì˜í•´ë³¸ ë’¤ ìƒí™©ì— ë§ì¶”ì–´ ê·œì¹™ì„ ë³€ê²½í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n3. Conda environment Virtual environment Virtual environmentë¥¼ ì‚¬ìš©í•˜ë©´ í•œ ì»´í“¨í„° ë‚´ì—ì„œ ê° userê°€ ë…ë¦½ì ìœ¼ë¡œ Python íŒ¨í‚¤ì§€ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì—¬ëŸ¬ ì»´í“¨í„°ì—ì„œ ë™ì¼í•œ í™˜ê²½ì„ êµ¬ì¶•í•˜ì—¬ íŒ¨í‚¤ì§€ ë²„ì „ ì°¨ì´ë¡œ ì¸í•œ ë¬¸ì œ ë°œìƒì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤4. ì´ëŠ” íŠ¹íˆ GPU driver, CUDA, cuDNN, ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë²„ì „ ê°„ í˜¸í™˜ì„±ì´ ì¤‘ìš”í•œ ë”¥ëŸ¬ë‹ jobì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤.\nì—¬ëŸ¬ userê°€ nodeë¥¼ ê³µìœ í•˜ëŠ” HPCì—ì„œ virtual environmentì˜ ì‚¬ìš©ì€ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê° userëŠ” ìì‹ ì˜ ë¡œì»¬ ì»´í“¨í„°ì™€ ë™ì¼í•œ Python í™˜ê²½ì„ node ë‚´ì— êµ¬ì¶•í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ìƒ ì—†ì´ ì‹¤í–‰ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ë¬¸ì œ ì—†ì´ ì‹¤í–‰ë˜ëŠ” ê²ƒì´ í™•ì¸ëœ ì½”ë“œë¥¼ slurmì„ í†µí•´ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤. Virtual environmentëŠ” ë¡œì»¬ì—ì„œ ì‘ì„±í•œ ì½”ë“œê°€ í´ëŸ¬ìŠ¤í„°ì—ì„œ ë¬¸ì œ ì—†ì´ ì‘ë™í•˜ëŠ” ê²ƒì„ ë³´ì¥í•©ë‹ˆë‹¤.\nConda environment Chili PepperëŠ” condaë¥¼ ì´ìš©í•´ virtual environmentë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. condaëŠ” Windows, MacOS, Linuxë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤5.\nChili Pepperì—ì„œ Python jobì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ conda environmentë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\nReferences   https://epcced.github.io/hpc-intro/13-scheduler/index.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://wiki.hpc.odu.edu/en/slurm\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://support.cs.toronto.edu/systems/slurmresource.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://www.marquette.edu/high-performance-computing/py-venv.php\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://docs.conda.io/en/latest/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/01_intro/","summary":"ìš”ì•½ Chili PepperëŠ”\n ì´ ì„¸ ê°œì˜ ì»´í“¨í„°ë¡œ êµ¬ì„±ëœ ì»´í“¨íŒ… í´ëŸ¬ìŠ¤í„°ì…ë‹ˆë‹¤. CPU node í•˜ë‚˜, GPU node í•˜ë‚˜, ê·¸ë¦¬ê³  ì´ ë‘˜ì„ ê´€ë¦¬í•˜ëŠ” proxy nodeë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Slurmì´ë¼ëŠ” job schedulerë¡œ ì—¬ëŸ¬ userì˜ ì‘ì—…ì„ ê° nodeì— íš¨ìœ¨ì ìœ¼ë¡œ í• ë‹¹í•©ë‹ˆë‹¤. ê° userëŠ” ìì‹ ë§Œì˜ conda environmentë¥¼ ìŠ¤ìŠ¤ë¡œ ìƒì„±í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ non-interactiveì…ë‹ˆë‹¤. Userê°€ ìì‹ ì˜ ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ì‘ì„± ë° í…ŒìŠ¤íŠ¸í•œ ì½”ë“œë¥¼ ì„œë²„ì— ì œì¶œí•˜ë©´ ì„œë²„ê°€ í•´ë‹¹ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ì£¼í”¼í„° ë…¸íŠ¸ë¶ í™˜ê²½ì€ ì‹¤í–‰ ê°€ëŠ¥í•˜ì§€ë§Œ, ê¼­ í•„ìš”í•œ ê²½ìš°ì— í•œí•˜ì—¬ ìš”ì²­ ì‹œ ì œê³µí•©ë‹ˆë‹¤.","title":"1. Introduction"},{"content":"1. What is SLURM? Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for its operation and is relatively self-contained.\nIf you need more information, Please Visit https://slurm.schedmd.com/overview.html\n2. Basic SLURM Command   sbatch\n Submit a batch script to SLURM  1 2 3 4  $ sbatch [YOUR_SCRIPT] # output \u0026gt; Submitted batch job 210 # job_id: 210     squeue\n View the queue  1 2 3 4 5  $ squeue # output \u0026gt; JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 210 all test1 ghk R 0:29 1 cpu-compute     scancel\n Cancel a SLURM job  1  $ scancel [YOUR_JOBID]     sinfo\n See the state of system  1 2 3 4 5  $ sinfo # output \u0026gt; PARTITION AVAIL TIMELIMIT NODES STATE NODELIST all* up infinite 2 idle cpu-compute,gpu-compute     smap\n graphically view information about SLURM job    For more information about SLURM command, please visit website below.\n  SLURM Workload Manager\n  SLURM Command Cheatsheet\n  SLURM Reference Sheet(NeSI)\n  Submit your first job(NeSI)\n  3. How to make SLURM batch script? \u0026lsquo;Job submission file\u0026rsquo; is the official SLURM name for the file you use to submit your program and ask for resources from the job scheduler. In this document, we will be using it â€˜batch scriptâ€™ or â€˜scriptâ€™.\nBasic example 1 2 3 4 5 6 7  #!/bin/bash #  # SBATCH --job-name=basic # SBATCH --mem=1gb # SBATCH --ntasks=1 # SBATCH --time=01:00 # SBATCH --output=/mnt/nas/users/testuser/basic.log   Asking 1 tasks, running for no more than 1 minutes limit memory less than 1gb. If any problem with your job, log file(in this case, \u0026lsquo;basic.log\u0026rsquo;) have information to help troubleshoot the issue.\nYou can also use gpu-nodes by using \u0026lsquo;â€”gres\u0026rsquo; option. Here is an example.\n1 2 3 4 5 6 7 8 9 10 11  #!/bin/bash #  #SBATCH --job-name=basic #SBATCH --nodes=1 #SBATCH --gres=gpu:2 # max : 2 #SBATCH --time=01:00 #SBATCH --account=testuser #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/testuser/torch.log source activate /opt/miniconda/envs/pytorch \u0026amp;\u0026amp; python /mnt/nas/users/testuser/main.py   1 2 3 4 5 6 7 8 9 10  # main.py import torch print(\u0026#39;is cuda avaiable? \u0026#39;, torch.cuda.is_available()) print(\u0026#39;how many cuda devices? \u0026#39;,torch.cuda.device_count()) print(\u0026#39;get first cuda device name =\u0026gt; \u0026#39;, torch.cuda.get_device_name(0)) print(\u0026#39;*** MEMORY INFO ***\u0026#39;) t = torch.cuda.get_device_properties(0).total_memory print(\u0026#39;total memory =\u0026gt; \u0026#39;, t) print(\u0026#39;total memory: \u0026#39;, t)   The job can then be submitted through sbatch\n1 2 3 4 5 6 7  $ sbatch basic.sh $ cat torch.log \u0026gt; is cuda avaiable? True \u0026gt; how many cuda devices? 2 \u0026gt; get first cuda device name =\u0026gt; Tesla T4 \u0026gt; ***MEMORY INFO*** \u0026gt; total memory =\u0026gt; 16879583232   Beacuse we only have 2 gpu machine, this option canâ€™t be set more than 2\nFor the convenience of users, we provide SLURM job configurator page in our website. Please visit SLURM job configurator and make your own SLURM batch script!\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/slurm-documentation/","summary":"1. What is SLURM? Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. Slurm requires no kernel modifications for its operation and is relatively self-contained.\nIf you need more information, Please Visit https://slurm.schedmd.com/overview.html\n2. Basic SLURM Command   sbatch\n Submit a batch script to SLURM  1 2 3 4  $ sbatch [YOUR_SCRIPT] # output \u0026gt; Submitted batch job 210 # job_id: 210     squeue","title":"SLURM Documentation"},{"content":"Intro This documentation will go over the basics of using the Chili Pepper cluster. Please go through this documentation step-by-step. Contact the server administrator via email or use the Q\u0026amp;A channel in the Slack Group.\nStep 1 - Understanding the Cluster Structure Chili Pepper cluster has a NAS which contains user home directories and other shared files. All users and groups are consistent across all nodes. The prefix for the user directory is /mnt/nas/users/. For example, the home directory for the user dummyuser will be /mnt/nas/users/dummyuser/. The home directory is the recommended directory for users to store scripts, data and configuration files for using the Chili Pepper cluster.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  # with the tree command the home directory will typically look like this /mnt/nas/users/dummyuser/ â”œâ”€â”€ .bash_history â”œâ”€â”€ .bash_logout â”œâ”€â”€ .bashrc â”œâ”€â”€ .conda â”œâ”€â”€ .config â”œâ”€â”€ GettingStarted.md â”œâ”€â”€ .gnupg â”œâ”€â”€ .ipynb_checkpoints â”œâ”€â”€ .ipython â”œâ”€â”€ .jupyter â”œâ”€â”€ .local â”œâ”€â”€ logs â”œâ”€â”€ .npm â”œâ”€â”€ .profile â”œâ”€â”€ .python_history â”œâ”€â”€ some_script.sh â”œâ”€â”€ .ssh â””â”€â”€ .viminfo   Step 2 - Data Transfer With cluster access information(SSH) provided by the administrator, you can send and recieve files from and to the cluster with scp. The dummyuser can send various local files to the cluster in the following fashion. Note that for security purposes the default port for SSH is not 22. The administrator will inform you of this information upon providing access information to the cluster.\nSending a local file(some_file.txt) to the remote home directory 1  scp some_file.txt dummyuser@hpc.stat.yonsei.ac.kr:~/   Sending a local directory(some_files/) to the remote home directory 1 2  scp -r some_files dummyuser@hpc.stat.yonsei.ac.kr:~/ # /mnt/nas/users/dummyuser/some_files/ will be created   Recieving a remote file(some_file.txt) in the home directory to the current local directory 1  scp dummyuser@hpc.stat.yonsei.ac.kr:~/some_file.txt   Recieving a remote directory(/mnt/nas/users/dummyuser/some_files) in the home directory to the current local directory 1  scp -r dummyuser@hpc.stat.yonsei.ac.kr:~/some_files ./   Other various options for scp exist. More information on this topic can be found in this article. Also users can use GitHub or GitLab to upload and download source code to the cluster. This will be handled in a seperate article.\nStep 3 - Writing a SBATCH script for SLURM. From the homepage the SLURM batch scripting tool is available. Let\u0026rsquo;s look at the sample script(/mnt/nas/users/dummyuser/test_script.sh) created by using the tool. The first-half(line 1 ~ 11) of the script consists of directives and parameters for the slurm job. Each user can set the number of nodes, the time for the job to occupy the number of nodes, the location for the output logfile. There are more options available for submitting a job. Additional resources for SBATCH arguments can be found here.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/bin/bash # The interpreter used to execute the script #â€œ#SBATCHâ€ directives that convey submission options: #SBATCH --job-name=conda-env-create #SBATCH --nodes=1 #SBATCH --time=15:00 #SBATCH --account=dummyuser #SBATCH --partition=all #SBATCH --output=/mnt/nas/users/dummyuser/conda.log # The application(s) to execute along with its input arguments and options: CONDA_BIN_PATH=/opt/miniconda/bin ENV_NAME=myenv ENV_PATH=/mnt/nas/users/$(whoami)/.conda/envs/$ENV_NAME $CONDA_BIN_PATH/conda env remove --prefix $ENV_PATH $CONDA_BIN_PATH/conda create -y --prefix $ENV_PATH python=3.8 pandas numpy scikit-learn source $CONDA_BIN_PATH/activate $ENV_PATH \u0026amp;\u0026amp; pip freeze   From line 15 to the end of the script are actual bash commands for the node to execute.\n Line 15~16 creates two local variables(ENV_NAME and ENV_PATH). In the above script a conda environment named myenv will be created under /mnt/nas/users/dummyuser/.conda/envs/myenv. Line 18 will remove the environment in ENV_PATH if it is present. Line 19 will create a conda environment in ENV_PATH thanks to the -y(--yes) flag. This environment will have a Python interpreter of version 3.8 along with listed packages(pandas, numpy and scikit-learn). Line 20 will activate the conda environment in ENV_PATH and then sequentially run a pip freeze to the stdout. Note that the stdout is saved in the log file from line 11(/mnt/nas/users/dummyuser/conda.log).  To actually run a data science job, the only thing you have to do is to change the required packages for your environment, modify the pip freeze into python your_script_to_run.py.\nStep 4 - Submitting the script The submission of the script from the above is very simple.\n1  sbatch test_script.sh   You can check the current job queue with the following command.\n1  squeue   When you want to cancel the job you have submitted, get the JOBID from the squeue command and use the scancel command in the following fashion. Suppose the JOBID is 23.\n1  scancel 23   Note that ordinary users cannot cancel jobs that belong to other users, but the administrator can.\n","permalink":"https://hpc.stat.yonsei.ac.kr/docs/using-slurm-copy/","summary":"Intro This documentation will go over the basics of using the Chili Pepper cluster. Please go through this documentation step-by-step. Contact the server administrator via email or use the Q\u0026amp;A channel in the Slack Group.\nStep 1 - Understanding the Cluster Structure Chili Pepper cluster has a NAS which contains user home directories and other shared files. All users and groups are consistent across all nodes. The prefix for the user directory is /mnt/nas/users/.","title":"How do I use the Chili Pepper Cluster?"},{"content":"Creating a Python Kernel Admin Prerequisite Admin must enable conda for all users by creating a symlink. This will let users create their own virtual environment by using the conda create command.\n1  ln -s /opt/conda/bin/conda /usr/local/bin/conda   User Instructions Python  Users can launch a terminal session with either JupyterHub or SSH connections. Launch a bash session.  1  bash   Users then can create a virtual environment in the following way. Note that specifying ipykernel package will make the user easily create jupyter kernels from that environment. Also users can create virtual environments with various python versions(3.6 ~ 3.9). Activate the environment. If any warnings occur, read the warning and do the recommended procedure. Most of the time you will need to refresh your shell with bash.  1 2 3 4 5 6 7 8  # create environemnt conda create -n NAME_OF_VIRTUAL_ENV python=3.8 ipykernel # refresh your shell bash # activate environemnt conda activate NAME_OF_VIRTUAL_ENV   Install packages via pip.  1 2 3 4 5  # directly pip install PACKAGE_NAME # requirements.txt pip install -r YOUR_REQUIREMENTS.txt   Add the virtual environment as a kernel. This will be only available to each user.  1  python -m ipykernel install --user --name NAME_OF_VIRTUAL_ENV --display-name \u0026#34;[displayKenrelName]\u0026#34;   R  Launch a bash session via JupyterHub or SSH.  1  bash   Users then can create a virtual environment in the following way.  1 2 3 4 5 6 7 8  # create environemnt conda create -n NAME_OF_VIRTUAL_ENV r-essentials r-base r-irkernel # refresh your shell bash # activate environemnt conda activate NAME_OF_VIRTUAL_ENV   Install packages via install.packages().  1 2  # directly Rscript -e \u0026#39;install.packages(c(\u0026#34;dplyr\u0026#34;))\u0026#39;   Add the virtual environment as a kernel. This will be only available to each user.  1  Rscript -e \u0026#34;IRkernel::installspec(name=\u0026#39;myRkernel\u0026#39;, displayname=\u0026#39;My R Kernel\u0026#39;)\u0026#34;   Removing Kernels To remove kernels use the jupyter command in terminal.\nView your current kernel list with the following command from a bash terminal.\n1  jupyter kernelspec list   Remove kernel with the following command.\n1  jupyter kernelspec remove KERNELNAME   ","permalink":"https://hpc.stat.yonsei.ac.kr/docs/configuring-jupyter-kernel/","summary":"Creating a Python Kernel Admin Prerequisite Admin must enable conda for all users by creating a symlink. This will let users create their own virtual environment by using the conda create command.\n1  ln -s /opt/conda/bin/conda /usr/local/bin/conda   User Instructions Python  Users can launch a terminal session with either JupyterHub or SSH connections. Launch a bash session.  1  bash   Users then can create a virtual environment in the following way.","title":"Creating Your Custom Jupyter Kernel from a Virtual Environment"}]